---
layout: post
title: "Deep Residual Shrinkage Network: Көслө шау-шыулы мәғлүмәт өсөн яһалма интеллект ысулы"
subtitle: "An Artificial Intelligence Method for Highly Noisy Data"
date: 2025-12-13
tags: [Deep Learning, AI]
mathjax: true
description: "Deep Residual Shrinkage Network — ул Deep Residual Network-тың яҡшыртылған төрө. Асылда, Deep Residual Shrinkage Network үҙ эсенә Deep Residual Network, attention mechanisms һәм soft thresholding функцияларын берләштерә."
---

**`Deep Residual Shrinkage Network` — ул `Deep Residual Network`-тың яҡшыртылған төрө. Асылда, `Deep Residual Shrinkage Network` үҙ эсенә `Deep Residual Network`, `attention mechanisms` һәм `soft thresholding` функцияларын берләштерә.**

**Беҙ `Deep Residual Shrinkage Network` эшләү принцибын түбәндәгесә аңлай алабыҙ. Беренсенән, селтәр мөһим булмаған үҙенсәлектәрҙе асыҡлау өсөн `attention mechanisms` ҡуллана. Шунан һуң, селтәр был мөһим булмаған үҙенсәлектәрҙе нулгә тиңләштереү өсөн `soft thresholding` функцияларын ҡуллана. Киреһенсә, селтәр мөһим үҙенсәлектәрҙе таба һәм һаҡлап ҡала. Был процесс тәрән нейрон селтәрҙең һәләтен көсәйтә. Был процесс селтәргә `noise` булған сигналдарҙан файҙалы үҙенсәлектәрҙе айырып алырға ярҙам итә.**

## 1. Тикшеренеү мотивацияһы (Research Motivation)

**Беренсенән, алгоритм өлгөләрҙе классификациялағанда, `noise` ҡотолғоһоҙ була. Был шау-шыуҙың миҫалдарына `Gaussian noise`, `pink noise` һәм `Laplacian noise` керә.** Ҡағиҙә булараҡ, өлгөләрҙә йыш ҡына хәҙерге классификация бурысына ҡағылышы булмаған мәғлүмәт бар. Беҙ был бәйле булмаған мәғлүмәтте `noise` тип аңлай алабыҙ. Был `noise` классификация һөҙөмтәһен кәметергә мөмкин. (`Soft thresholding` — күп кенә сигналдарҙы таҙартыу алгоритмдарында төп аҙым булып тора.)

Мәҫәлән, юл ситендәге һөйләшеүҙе ҡарайыҡ. Аудиола машина сигналдары һәм тәгәрмәс тауыштары булырға мөмкин. Беҙ был сигналдарға `speech recognition` яһарға мөмкинбеҙ. Фон тауыштары һөҙөмтәләргә мотлаҡ йоғонто яһаясаҡ. `Deep learning` күҙлегенән ҡарағанда, тәрән нейрон селтәр сигнал һәм тәгәрмәс тауыштарына тура килгән үҙенсәлектәрҙе юҡҡа сығарырға тейеш. Был юҡҡа сығарыу үҙенсәлектәрҙең `speech recognition` һөҙөмтәләренә тәьҫир итеүенә юл ҡуймай.

**Икенсенән, `noise` күләме йыш ҡына өлгөләр араһында төрлөсә була. Был үҙгәреш хатта бер үк датасет эсендә лә осрай.** (Был үҙгәреш `attention mechanisms` менән оҡшашлыҡҡа эйә. Мәҫәлән, рәсемдәр датасетын алайыҡ. Маҡсатлы объекттың урыны төрлө рәсемдәрҙә төрлөсә булырға мөмкин. `Attention mechanisms` һәр рәсемдәге маҡсатлы объекттың конкрет урынына иғтибарҙы йүнәлтә ала.)

Мәҫәлән, "эт" тип билдәләнгән биш рәсем менән бесәй-эт классификаторын өйрәтеүҙе ҡарайыҡ. 1-се рәсемдә эт һәм сысҡан булырға мөмкин. 2-се рәсемдә эт һәм ҡаҙ булырға мөмкин. 3-сө рәсемдә эт һәм тауыҡ булырға мөмкин. 4-се рәсемдә эт һәм ишәк булырға мөмкин. 5-се рәсемдә эт һәм өйрәк булырға мөмкин. Өйрәтеү ваҡытында, бәйле булмаған объекттар классификаторға ҡамасаулаясаҡ. Был объекттарға сысҡандар, ҡаҙҙар, тауыҡтар, ишәктәр һәм өйрәктәр керә. Был ҡамасаулау классификацияның теүәллеге кәмеүенә килтерә. Әгәр беҙ был бәйле булмаған объекттарҙы асыҡлай алһаҡ, беҙ уларға тура килгән үҙенсәлектәрҙе юҡ итә алабыҙ. Шулай итеп, беҙ бесәй-эт классификаторының теүәллеген яҡшырта алабыҙ.

## 2. Йомшаҡ сикләү (Soft Thresholding)

**`Soft thresholding` — ул күп кенә сигналдарҙы таҙартыу алгоритмдарының төп аҙымы. Әгәр үҙенсәлектәрҙең абсолют ҡиммәттәре билдәле бер тупһанан (threshold) түбән булһа, алгоритм уларҙы юҡ итә. Әгәр абсолют ҡиммәттәр был тупһанан юғары булһа, алгоритм уларҙы нулгә табан "ҡыҫа" (shrinks).** Тикшеренеүселәр `soft thresholding` ысулын түбәндәге формула ярҙамында тормошҡа ашыра ала:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

`Soft thresholding` сығарылмаһы инеүгә ҡарата түбәндәгесә:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

Юғарылағы формула `soft thresholding` сығарылмаһының йә 1, йә 0 булыуын күрһәтә. Был үҙенсәлек `ReLU` активация функцияһының үҙенсәлеге менән бер үк. Шуға күрә, `soft thresholding` тәрән өйрәнеү алгоритмдарында `gradient vanishing` һәм `gradient exploding` хәүефен кәметә ала.

**`Soft thresholding` функцияһында тупһаны (threshold) көйләү ике шартты үтәргә тейеш. Беренсенән, тупһа ыңғай һан булырға тейеш. Икенсенән, тупһа инеү сигналының максималь ҡиммәтенән ҙурыраҡ була алмай. Юғиһә, сығыу тулыһынса нуль буласаҡ.**

**Бынан тыш, тупһа өсөнсө шартты ла үтәһә яҡшыраҡ. Һәр өлгө, үҙенең `noise` йөкмәткеһенә нигеҙләнеп, үҙенең шәхси, бойондороҡһоҙ тупһаһына эйә булырға тейеш.**

Сәбәбе шунда: `noise` йөкмәткеһе йыш ҡына өлгөләр араһында төрлөсә була. Мәҫәлән, бер үк датасет эсендә А өлгөһөндә аҙыраҡ `noise` булырға мөмкин, ә В өлгөһөндә күберәк `noise` булырға мөмкин. Был осраҡта, `soft thresholding` ҡулланғанда А өлгөһө бәләкәйерәк тупһа ҡулланырға тейеш. В өлгөһө ҙурыраҡ тупһа ҡулланырға тейеш. Тәрән нейрон селтәрҙәрҙә был үҙенсәлектәр һәм тупһалар үҙҙәренең аныҡ физик билдәләмәләрен юғалта. Ләкин төп логика үҙгәрешһеҙ ҡала. Йәғни, һәр өлгө бойондороҡһоҙ тупһаға эйә булырға тейеш. Конкрет `noise` йөкмәткеһе был тупһаны билдәләй.

## 3. Иғтибар механизмы (Attention Mechanism)

Тикшеренеүселәр `computer vision` өлкәһендә `attention mechanisms` төшөнсәһен еңел аңлай ала. Хайуандарҙың күреү системалары маҡсатты айырыу өсөн тиҙ генә бөтә өлкәне сканерлай ала. Шунан һуң, күреү системалары иғтибарҙы маҡсатлы объектҡа йүнәлтә. Был хәрәкәт системаларға күберәк деталдәрҙе айырып алырға мөмкинлек бирә. Шул уҡ ваҡытта, системалар бәйле булмаған мәғлүмәтте баҫтыра. Ентеклерәк мәғлүмәт өсөн `attention mechanisms` буйынса әҙәбиәткә мөрәжәғәт итегеҙ.

`Squeeze-and-Excitation Network (SENet)` — `attention mechanisms` ҡулланған сағыштырмаса яңы `deep learning` ысулы. Төрлө өлгөләрҙә төрлө үҙенсәлек каналдары классификация бурысына төрлөсә өлөш индерә. `SENet` бәләкәй ярҙамсы селтәр (sub-network) ҡулланып, бер төркөм ауырлыҡтарҙы (`Learn a set of weights`) ала. Шунан һуң `SENet` был ауырлыҡтарҙы тейешле каналдарҙың үҙенсәлектәренә ҡабатлай. Был операция һәр каналдағы үҙенсәлектәрҙең ҙурлығын көйләй (`Apply weighting to each feature channel`). Беҙ был процесты төрлө үҙенсәлек каналдарына төрлө кимәлдәге иғтибарҙы йүнәлтеү тип ҡарай алабыҙ.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

Был ысулда һәр өлгө бойондороҡһоҙ ауырлыҡтар йыйылмаһына эйә. Йәғни, теләһә ниндәй ике өлгө өсөн ауырлыҡтар төрлөсә. `SENet`-та ауырлыҡтарҙы алыуҙың конкрет юлы: "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function".

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Тәрән иғтибар механизмы менән йомшаҡ сикләү (Soft Thresholding with Deep Attention Mechanism)

`Deep Residual Shrinkage Network` `SENet` ярҙамсы селтәренең структураһын ҡуллана. Селтәр был структураны тәрән `attention mechanism` шарттарында `soft thresholding` тормошҡа ашырыу өсөн файҙалана. Ярҙамсы селтәр (ҡыҙыл рамка эсендә күрһәтелгән) бер төркөм тупһаларҙы өйрәнә (`Learn a set of thresholds`). Шунан һуң, селтәр был тупһаларҙы ҡулланып, һәр үҙенсәлек каналына `soft thresholding` ҡуллана.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

Был ярҙамсы селтәрҙә система башта инеү үҙенсәлеге картаһындағы бөтә үҙенсәлектәрҙең абсолют ҡиммәттәрен иҫәпләй. Шунан һуң, система `global average pooling` һәм уртасалау ярҙамында A тип билдәләнгән үҙенсәлекте ала. Икенсе юлда, система `global average pooling` үткәргәндән һуң, үҙенсәлек картаһын бәләкәй тулы бәйләнешле селтәргә (`fully connected network`) индерә. Был селтәр һуңғы ҡатлам булараҡ `Sigmoid` функцияһын ҡуллана. Был функция сығыуҙы 0 һәм 1 араһында нормалләштерә. Был процесс α тип билдәләнгән коэффициентты бирә. Беҙ һуңғы тупһаны α × A тип күрһәтә алабыҙ. Шулай итеп, тупһа — ике һандың ҡабатландығы. Бер һан — 0 менән 1 араһында. Икенсе һан — үҙенсәлек картаһының абсолют ҡиммәттәренең уртасаһы. **Был ысул тупһаның ыңғай булыуын тәьмин итә. Был ысул шулай уҡ тупһаның артыҡ ҙур булмауын гарантиялай.**

**Өҫтәүенә, төрлө өлгөләр төрлө тупһаларға килтерә. Шуға күрә, беҙ был ысулды махсус `attention mechanism` тип аңлай алабыҙ. Был механизм хәҙерге бурысҡа ҡағылышы булмаған үҙенсәлектәрҙе асыҡлай. Механизм ике `convolutional layer` аша был үҙенсәлектәрҙе 0-гә яҡын ҡиммәттәргә әйләндерә. Шунан һуң механизм `soft thresholding` ҡулланып был үҙенсәлектәрҙе нулгә тиңләштерә. Йәки, механизм хәҙерге бурысҡа ҡағылышы булған үҙенсәлектәрҙе асыҡлай. Механизм ике `convolutional layer` аша был үҙенсәлектәрҙе 0-дән алыҫ ҡиммәттәргә әйләндерә. Ахырҙа, механизм был үҙенсәлектәрҙе һаҡлап ҡала (`Identity path` аша).**

Ахырҙа, беҙ билдәле бер һандағы төп модулдәрҙе өйәбеҙ (`Stack many basic modules`). Беҙ шулай уҡ `convolutional layers`, `batch normalization`, активация функциялары, `global average pooling` һәм тулы бәйләнешле сығыу ҡатламдарын өҫтәйбеҙ. Был процесс тулы `Deep Residual Shrinkage Network` төҙөй.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Дөйөмләштереү һәләте (Generalization Capability)

`Deep Residual Shrinkage Network` — ул үҙенсәлектәрҙе өйрәнеү (`feature learning`) өсөн дөйөм ысул. Сәбәбе шунда: күп кенә `feature learning` бурыстарында өлгөләр йыш ҡына `noise` үҙ эсенә ала. Өлгөләр шулай уҡ бәйле булмаған мәғлүмәтте үҙ эсенә ала. Был `noise` һәм бәйле булмаған мәғлүмәт `feature learning` һөҙөмтәлелегенә тәьҫир итергә мөмкин. Мәҫәлән:

Рәсемдәрҙе классификациялауҙы ҡарайыҡ. Бер рәсем бер үк ваҡытта башҡа күп кенә объекттарҙы үҙ эсенә алырға мөмкин. Беҙ был объекттарҙы "noise" тип аңлай алабыҙ. `Deep Residual Shrinkage Network` бәлки `attention mechanism` ҡуллана алыр. Селтәр был "noise"-ды һиҙә. Шунан һуң, селтәр `soft thresholding` ҡулланып, был "noise"-ға тура килгән үҙенсәлектәрҙе нулгә тиңләштерә. Был хәрәкәт рәсем классификацияһының теүәллеген яҡшыртырға мөмкин.

`Speech recognition` тураһында уйлап ҡарайыҡ. Атап әйткәндә, юл ситендә йәки завод цехы эсендәге һөйләшеү кеүек шау-шыулы мөхитте ҡарайыҡ. `Deep Residual Shrinkage Network` `speech recognition` теүәллеген яҡшыртырға мөмкин. Йәки кәм тигәндә, селтәр методология тәҡдим итә. Был методология `speech recognition` теүәллеген яҡшыртырға һәләтле.

## Reference

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

[https://ieeexplore.ieee.org/document/8850096](https://ieeexplore.ieee.org/document/8850096)

## BibTeX
```bibtex
@article{Zhao2020,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}
```

## Академик йоғонтоһо (Academic Impact)

Был мәҡәлә `Google Scholar`-ҙа 1400-ҙән ашыу өҙөмтә алды.

Тулы булмаған статистикаға ярашлы, тикшеренеүселәр `Deep Residual Shrinkage Network (DRSN)` ысулын 1000-дән ашыу баҫмала/тикшеренеүҙә ҡулланған. Был ҡулланмалар киң өлкәләрҙе үҙ эсенә ала. Был өлкәләргә машиналар төҙөү, электр энергетикаһы, `vision`, һаулыҡ һаҡлау, телмәр, текст, радар һәм дистанцион зондлау (remote sensing) керә.
