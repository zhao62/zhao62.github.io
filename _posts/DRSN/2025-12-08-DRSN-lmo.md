---
layout: post
title: "Deep Residual Shrinkage Network: On Metod de Artificial Intelligence per i Highly Noisy Data"
date: 2025-12-08
tags: [Deep Learning, AI]
mathjax: true
---

**El Deep Residual Shrinkage Network l'è ona variant migliorada del Deep Residual Network. In sostanza, el Deep Residual Shrinkage Network el mett insemma el Deep Residual Network, i attention mechanisms, e i soft thresholding functions.**

**Podom capì el principi de funzionament del Deep Residual Shrinkage Network in sta manera chì. Prima de tutt, el network el drova i attention mechanisms per identificà i features che importen pocch. Dopo, el network el drova i soft thresholding functions per settà sti features che importen pocch a zero. Al contrari, el network el identifica i features important e 'l tegn sti features important. Sto process chì el rinforza la capacità del deep neural network. Sto process chì el jutta el network a tirà foeura i features util dai segnai che gh'hann denter del noise.**

## 1. Research Motivation

**Prima roba, el noise l'è inevitabil quand che l'algoritm el classifega i campion. Esempi de sto noise includen el Gaussian noise, el pink noise, e 'l Laplacian noise.** Pussee in general, i campion despess gh'hann denter informazion che gh'entren nagott con la **classification task** del moment. Num podom interpretà sta informazion inutil come **noise**. Sto **noise** el pò sbassà i **classification performance**. (El **Soft thresholding** l'è on pass ciav in tanti **signal denoising algorithms**.)

Fasemm on esempi: pensee a ona conversazion visin a la strada. L'audio el potrebbe avègh denter i son di clacson e di roeu de la machina. Magari num vorom fà **speech recognition** su sti segnai chì. I son de **background** per forza de cosse influenzerann i resultad. De on pont de vista del **deep learning**, el **deep neural network** el gh'avaria de eliminà i **features** che corisponden ai clacson e ai roeu. Sta eliminazion la serviss per evità che sti **features** vadenn a toccà i resultad del **speech recognition**.

**Seconda roba, la quantità de noise despess la cambia tra on campion e l'alter. Sta variazion la succed anca denter in del istess dataset.** (Sta variazion la gh'ha di somiglianz coi **attention mechanisms**. Ciappem on **image dataset** come esempi. La posizion del **target object** la pò vess diversa in ogni imagin. I **attention mechanisms** poden focalizzàss su la posizion specifica del **target object** in ogni imagin.)

Per esempi, provom a allenà on **classifier** per gatti e can con cinch imagin etichettade come "can". L'imagin 1 la potrebbe avègh denter on can e on ratt. L'imagin 2 on can e on'oca. L'imagin 3 on can e on pollaster. L'imagin 4 on can e on asen. L'imagin 5 on can e on anatra. Durante el **training**, i oggett che c'entren no darann fastidi al **classifier**. Sti oggett includen ratt, oche, pollaster, asen e anatre. Sto fastidi el porta a on cal de la **classification accuracy**. Se num fussom bon de identificà sti oggett che c'entren no, allora podariom eliminà i **features** che corisponden a sti oggett. In sta manera, podom alzà la **accuracy** del **classifier** gatti-e-can.

## 2. Soft Thresholding

**El Soft thresholding l'è on pass fondamental in tanti signal denoising algorithms. L'algoritm el elimina i features se i absolute values di features hinn pussee bass de ona certa threshold. L'algoritm el shrinks (el strenz) i features vers zero se i absolute values di features hinn pussee volt de sta threshold.** I ricercator poden implementà el **soft thresholding** cont la formula chì sota:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

La derivad del **soft thresholding output** rispetto al **input** l'è:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

La formula de sora la fa vedè che la derivad del **soft thresholding** l'è o 1 o 0. Sta proprietà l'è identica a la proprietà de la **ReLU activation function**. Donca, el **soft thresholding** el pò sbassà el ris'c de **gradient vanishing** e **gradient exploding** in di **deep learning algorithms**.

**In la soft thresholding function, el setting de la threshold el gh'ha de sodisfà dò condizion. Prima, la threshold la gh'ha de vess on numer positiv. Seconda, la threshold la pò minga vess pussee granda del maximum value del input signal. Se no, l'output el saria tutt zero.**

**Inoltra, la threshold la saria mej se la sodisfass ona terza condizion. Ogni campion el gh'avaria de avègh la soa threshold indipendent basada sul contegnud de noise del campion istess.**

La reson l'è che el contegnud de **noise** despess el cambia tra i campion. Per esempi, el Campion A el potrebbe avègh men **noise** menter el Campion B el gh'ha pussee **noise** denter nel istess **dataset**. In sto caso chì, el Campion A el gh'avaria de drovà ona **threshold** pussee picinina durante el **soft thresholding**. El Campion B el gh'avaria de drovà ona **threshold** pussee granda. In di **deep neural networks**, sti **features** e **thresholds** perden i so definizion fisich esplicit. Però, la logica de bas la resta istessa. Voeuri dì che ogni campion el gh'avaria de avègh ona **threshold** indipendent. El contegnud specifich de **noise** el decid sta **threshold**.

## 3. Attention Mechanism

I ricercator poden capì facilment i **attention mechanisms** in del camp de la **computer vision**. I sistema visiv di animai poden distingu i **targets** scansionando a la svelta tutta l'area. Dopo, i sistema visiv focalizzen la **attention** sul **target object**. St'azzion la permett ai sistema de tirà foeura pussee detali. In del istess temp, i sistema sca'scen via l'informazion inutil. Per i detali specifich, per piasè guardee la letteratura riguardant i **attention mechanisms**.

El **Squeeze-and-Excitation Network** (SENet) el rapresenta on **deep learning method** relativament noeuv che 'l drova i **attention mechanisms**. Tra campion diversi, **feature channels** diversi contribuiscen in manera diversa a la **classification task**. El **SENet** el drova on **sub-network** picinin per ottegnì on **set of weights** (on insemma de pes). Dopo, el **SENet** el moltiplica sti **weights** cont i **features** di **channels** corispondent. St'operazion la regola la grandezza di **features** in ogni **channel**. Num podom vedè sto process come **Apply weighting to each feature channel** (applicà on pes a ogni canal di feature) con diversi livej de **attention**.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

In sto approcc, ogni campion el possied on **set of weights** indipendent. Voeuri dì, i **weights** per duu campion a caso hinn diversi. In del **SENet**, el percors specifich per ottegnì i **weights** l'è "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function."

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding with Deep Attention Mechanism

El **Deep Residual Shrinkage Network** el drova la struttura del **sub-network** del **SENet**. El **network** el drova sta struttura per implementà el **soft thresholding** sota on **deep attention mechanism**. El **sub-network** (segnad denter in del box ross) l'è bon de **Learn a set of thresholds**. Dopo, el **network** el applica el **soft thresholding** a ogni **feature channel** drovando sti **thresholds**.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

In sto **sub-network**, el sistema prima de tutt el calcola i **absolute values** de tucc i **features** in la **input feature map**. Dopo, el sistema el fa el **global average pooling** e la media per ottegnì on **feature**, ciamad A. In l'alter percors (l'**Identity path**), el sistema el manda la **feature map** denter in on picol **fully connected network** dopo del **global average pooling**. Sto **fully connected network** el drova la **Sigmoid function** come **final layer**. Sta funzion la normalizza l'**output** tra 0 e 1. Sto process el da on coefficient, ciamad α. Num podom scriv la **threshold** final come α × A. Donca, la **threshold** l'è el prodott de duu numer. On numer l'è tra 0 e 1. L'alter numer l'è la media di **absolute values** de la **feature map**. **Sto metod el garantiss che la threshold la sia positiva. Sto metod el garantiss anca che la threshold la sia minga esageratament granda.**

**Inoltra, campion diversi dann come resultad thresholds diversi. De conseguenza, num podom interpretà sto metod come on attention mechanism specializzad. El mechanism el identifica i features che c'entren no con la task del moment. El mechanism el trasforma sti features in valor vesin a zero travers duu convolutional layers. Dopo, el mechanism el settà sti features a zero drovando el soft thresholding. Oltrament, el mechanism el identifica i features che c'entren con la task del moment. El mechanism el trasforma sti features in valor lontan de zero travers duu convolutional layers. A la fin, el mechanism el preserva sti features.**

Finalment, num femm el **Stack many basic modules** (impilom tanti modui de bas). Num giontom anca i **convolutional layers**, **batch normalization**, **activation functions**, **global average pooling**, e **fully connected output layers**. Sto process el costruiss el **Deep Residual Shrinkage Network** complet.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generalization Capability

El **Deep Residual Shrinkage Network** l'è on metod general per el **feature learning**. La reson l'è che i campion despess gh'hann denter **noise** in tanti **feature learning tasks**. I campion gh'hann denter anca informazion che c'entren no. Sto **noise** e sta informazion inutil poden influenzà i performance del **feature learning**. Per esempi:

Pensee a la **image classification**. On'imagin la potrebbe avègh denter contemporaniament tanti alter oggett. Num podom capì sti oggett come "noise". El **Deep Residual Shrinkage Network** magari l'è bon de drovà l'**attention mechanism**. El **network** el nota sto "noise". Dopo, el **network** el drova el **soft thresholding** per settà i **features** che corisponden a sto "noise" a zero. St'azzion la gh'ha la possibilità de migliorà la **image classification accuracy**.

Pensee al **speech recognition**. Specialment, pensee a ambient relativament rumoros (o pien de **noise**) come i conversazion visin a la strada o denter in de l'officina de ona fabrica. El **Deep Residual Shrinkage Network** el potrebbe migliorà la **speech recognition accuracy**. O almanch, el **network** el offriss ona metodologia. Sta metodologia l'è bona de migliorà la **speech recognition accuracy**.

## Reference

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

[https://ieeexplore.ieee.org/document/8850096](https://ieeexplore.ieee.org/document/8850096)

## BibTeX
```bibtex
@article{Zhao2020,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}
```

## Academic Impact

Sto paper l'ha ricevud pussee de 1400 citazion su Google Scholar.

Basandes su statistich minga complet, i ricercator hann applicad el **Deep Residual Shrinkage Network** (DRSN) in pussee de 1000 publicazion/studi. Sti applicazion quatten ona gran varietà de camp. Sti camp includen l'ingegneria mecanica, l'energia elettrica (**electrical power**), la vision (**vision**), la sanità (**healthcare**), el parlad (**speech**), el test (**text**), el radar e 'l **remote sensing**.
