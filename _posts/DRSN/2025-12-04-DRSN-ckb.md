---
layout: post
title: "<div style='text-align: center; direction: rtl;'>میتۆدێکی Artificial Intelligence بۆ Dataـی Highly Noisy :Deep Residual Shrinkage Network</div>"
subtitle: "<div style='text-align: center; direction: ltr;'>Deep Residual Shrinkage Network: An Artificial Intelligence Method for Highly Noisy Data</div>"
date: 2025-12-04
tags: [Deep Learning, AI, Fault Diagnosis]
mathjax: true
lang: ckb
dir: rtl
---

<!-- CSS Styling -->
<style>
  /* 1. Force Headers Right */
  h1, h2, h3, h4, h5, h6 { text-align: right !important; direction: rtl !important; unicode-bidi: embed; }
  
  /* 2. Force Lists Right */
  ul, ol { text-align: right !important; direction: rtl !important; padding-right: 40px; padding-left: 0; }

  /* 3. Force Code LTR */
  pre, code { text-align: left !important; direction: ltr !important; }
  
  /* 4. Force References LTR */
  .references-ltr { text-align: left !important; direction: ltr !important; }
  
  /* 5. Improve Font for Kurdish */
  body, p, div, li { font-family: 'Unikurd Jiyaw', 'NRT Reg', 'Sakkal Majalla', 'Traditional Arabic', sans-serif; }
</style>

<!-- Main Content Wrapper -->
<div dir="rtl" markdown="1" style="text-align: right; direction: rtl; font-family: 'Sakkal Majalla', 'Traditional Arabic', serif; font-size: 1.1em; line-height: 1.8;">

<strong>Deep Residual Shrinkage Network جۆرێکی باشترکراوی Deep Residual Network ە. بە بنەڕەت، ئەمە integration ی Deep Residual Network، attention mechanisms، و soft thresholding functions ە.</strong>

<strong>تا ڕادەیەک، کارکردنی Deep Residual Shrinkage Network دەتوانرێت ئاوا تێبگیرێت: ئەم network ە attention mechanisms بەکاردەهێنێت بۆ ناسینەوەی ئەو feature انەی کە گرنگ نین (unimportant features)، و پاشان soft thresholding functions بەکاردەهێنێت بۆ سفرکردنەوەیان (setting them to zero)؛ بە پێچەوانەوە، feature ە گرنگەکان دەناسێتەوە و دەیانپارێزێت. ئەم process ە توانای deep neural network زیاد دەکات بۆ دەرهێنانی useful features لەو signal انەی کە noise یان تێدایە.</strong>

## 1. هاندەری توێژینەوە (Research Motivation)

<strong>یەکەم، کاتێک sample ەکان classify دەکەین، بوونی noise — وەک Gaussian noise, pink noise, و Laplacian noise — شتێکی نەخوازراوە (inevitable).</strong> بە شێوەیەکی گشتیتر، زۆرجار sample ەکان زانیاری (information) وایان تێدایە کە پەیوەندی نییە بە current classification task ەکەوە، کە ئەمە دەکرێت وەک noise سەیر بکرێت. ئەم noise انە دەتوانن کاریگەری خراپیان هەبێت لەسەر performance ی classification. (<strong>Soft thresholding</strong> هەنگاوێکی سەرەکییە لە زۆربەی ئەلگۆریزمەکانی <strong>signal denoising</strong>.)

بە نموونە، کاتێک لە قەراغ شەقام قسە دەکەیت، دەنگی قسەکردنەکە ڕەنگە تێکەڵ بێت لەگەڵ دەنگی horn ی سەیارە و تایەی سەیارە. کاتێک <strong>speech recognition</strong> (ناسینەوەی دەنگ) ئەنجام دەدەین لەسەر ئەم signal انە، ئەنجامەکە (results) بێگومان کاریگەری دەنگی horn و تایەکانی لەسەر دەبێت. لە ڕوانگەی <strong>deep learning</strong> ەوە، پێویستە ئەو feature انەی پەیوەندییان بە horn و تایەکانەوە هەیە لاببرێن (eliminated) لە ناو <strong>deep neural network</strong> ەکەدا، بۆ ئەوەی کاریگەری خراپیان نەبێت لەسەر ئەنجامی speech recognition ەکە.

<strong>دووەم، تەنانەت لە ناو هەمان dataset یشدا، بڕی noise زۆرجار لە sample ێک بۆ sample ێکی تر جیاوازە.</strong> (ئەمە هاوشێوەیە لەگەڵ <strong>attention mechanisms</strong>؛ ئەگەر dataset ێکی image وەربگرین وەک نموونە، شوێنی ئەو object ەی مەبەستمانە لایان ممکنە لە هەر وێنەیەکدا جیاواز بێت، و attention mechanisms دەتوانێت focus بخاتە سەر شوێنی تایبەتی object ەکە لە هەر وێنەیەکدا.)

بۆ نموونە، کاتێک <strong>classifier</strong> ی سەگ و پشیلە (cat-and-dog) train دەکەین، با وا دابنێین ٥ وێنەمان هەیە کە وەک "dog" label کراون. وێنەی یەکەم ممکنە سەگ و مشکی تێدا بێت، وێنەی دووەم سەگ و قاز، وێنەی سێیەم سەگ و مریشک، وێنەی چوارەم سەگ و کەر (donkey)، و وێنەی پێنجەم سەگ و وردەکە (duck). لە کاتی training دا، classifier ەکە بێگومان تووشی دەستێوەردان (interference) دەبێت لەلایەن object ە ناپەیوەندیدارەکان وەک مشک، قاز، مریشک، کەر، و وردەکە، کە ئەمە دەبێتە هۆی کەمبوونەوەی <strong>classification accuracy</strong>. ئەگەر بتوانین ئەم object ە ناپەیوەندیدارە بناسین — واتە مشک، قاز، مریشک، کەر، و وردەکە — و ئەو feature انەی پەیوەندییان پێیانەوە هەیە لایان ببەین (eliminate)، ئەوا ممکنە بتوانین accuracy ی cat-and-dog classifier ەکە بەرز بکەینەوە.

## 2. دەربارەی Soft Thresholding

<strong>Soft thresholding هەنگاوێکی سەرەکییە (core step) لە زۆربەی ئەلگۆریزمەکانی signal denoising. ئەمە ئەو feature انەی کە absolute value ەکەیان کەمترە لە threshold ێکی دیاریکراو لادەبات (eliminate)، و ئەو feature انەی کە absolute value ەکەیان گەورەترە لەو threshold ە "shrink" دەکات (کەم دەکاتەوە) بەرەو سفر.</strong> ئەمە دەتوانرێت جێبەجێ بکرێت بە بەکارهێنانی ئەم formula یە:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

Derivative ی output ی soft thresholding بەرامبەر بە input ەکە بریتییە لە:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

وەک لە سەرەوە دیارە، derivative ی soft thresholding یا ١ە یا ٠. ئەم تایبەتمەندییە هاوشێوەی <strong>ReLU activation function</strong> ە. بۆیە، soft thresholding دەتوانێت مەترسی (risk) تووشبوونی <strong>deep learning algorithms</strong> بە <strong>gradient vanishing</strong> و <strong>gradient exploding</strong> کەم بکاتەوە.

<strong>لە soft thresholding function دا، دانانی threshold ەکە پێویستە دوو مەرج (conditions) جێبەجێ بکات: یەکەم، threshold ەکە دەبێت positive بێت (ژمارەیەکی موجەب بێت)؛ دووەم، threshold ەکە نابێت لە بەهای هەرە گەورەی (maximum value) input signal ەکە زیاتر بێت، ئەگەر نا output ەکە بە تەواوەتی دەبێت بە سفر.</strong>

<strong>هەروەها، باشترە کە threshold ەکە مەرجی سێیەمیش جێبەجێ بکات: هەر sample ێک دەبێت threshold ی تایبەت بە خۆی (independent threshold) هەبێت بەپێی بڕی ئەو noise ەی کە تێیدایەتی.</strong>

هۆکارەکە ئەوەیە کە ناوەڕۆکی noise زۆرجار جیاوازە لە ناو sample ەکاندا. بۆ نموونە، شتێکی باوە کە لە ناو هەمان dataset دا، Sample A noise ی کەمتری تێدا بێت بەڵام Sample B noise ی زیاتری تێدا بێت. لە کاتێکی ئاوادا، کاتێک soft thresholding ئەنجام دەدەین لە ناو ئەلگۆریزمێکی denoising دا، Sample A پێویستە threshold ێکی بچووکتر بەکار بهێنێت، لە کاتێکدا Sample B پێویستە threshold ێکی گەورەتر بەکار بهێنێت. ئەگەرچی ئەم feature و threshold انە مانای فیزیكی ئاشکرایان نامێنێت لە ناو deep neural networks، بەڵام مەنتقە بنچینەییەکە هەر هەمان شتە. واتە، هەر sample ێک دەبێت threshold ی سەربەخۆی هەبێت کە دیاریکراو بێت بەپێی ناوەڕۆکی noise ەکەی.

## 3. میکانیزمی سەرنج (Attention Mechanism)

تێگەیشتن لە <strong>Attention mechanisms</strong> ئاسانترە لە بواری <strong>computer vision</strong>. سیستەمی بینینی ئاژەڵان دەتوانێت target ەکان جیا بکاتەوە بە خێرا scan کردنی هەموو ناوچەکە، و پاشان focus خستنە سەر target object ەکە بۆ دەرهێنانی وردەکاری زیاتر (extract more details) لەگەڵ سەرکوتکردنی زانیاری ناپەیوەندیدار (suppressing irrelevant information). بۆ زانیاری ورد، تکایە سەیری ئەدەبیاتی پەیوەندیدار بە attention mechanisms بکە.

<strong>Squeeze-and-Excitation Network (SENet)</strong> ڕێگایەکی نیسبەتەن نوێی deep learning ە کە attention mechanisms بەکاردەهێنێت. لە ناو sample ە جیاوازەکاندا، بەشداری (contribution) channel ە جیاوازەکانی feature بۆ classification task ەکە زۆرجار جیاوازە. SENet <strong>sub-network</strong> ێکی بچووک بەکاردەهێنێت بۆ بەدەستهێنانی کۆمەڵێک weight (<strong>Learn a set of weights</strong>)، و پاشان ئەم weight انە لێکدەدات (zarb) لە feature ی channel ە پەیوەندیدارەکان بۆ گۆڕین (adjust) ی قەبارەی feature ەکان لە هەر channel ێکدا (<strong>Apply weighting to each feature channel</strong>). ئەم process ە دەتوانرێت ببینرێت وەک ئەنجامدانی ئاستی جیاوازی attention بۆ سەر feature channel ە جیاوازەکان.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

لە ئەم ڕێگەیەدا، هەر sample ێک خاوەنی set ێکی سەربەخۆیە لە weight. بە واتایەکی تر، weight ەکان بۆ هەر دوو sample ێکی جیاواز، جیاوازن. لە ناو SENet دا، ئەو ڕێڕەوە (path) ی تایبەتەی بۆ بەدەستهێنانی weight ەکان بەکاردێت بریتییە لە "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function."

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding لەژێر Deep Attention Mechanism

<strong>Deep Residual Shrinkage Network</strong> سوود (inspiration) لەو structure ی sub-network ەی SENet وەردەگرێت بۆ جێبەجێکردنی soft thresholding لەژێر <strong>deep attention mechanism</strong>. لە ڕێگەی sub-network ەکەوە (کە لە ناو سندوقە سوورەکەدا نیشان دراوە)، network ەکە فێر دەبێت کە set ێک لە threshold دابنێت (<strong>Learn a set of thresholds</strong>) بۆ ئەنجامدانی soft thresholding بۆ هەر feature channel ێک.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

لە ناو ئەم sub-network ەدا، سەرەتا absolute value ی هەموو feature ەکانی input feature map حساب دەکرێت. پاشان، لە ڕێگەی <strong>global average pooling</strong> و average-کردنەوە، feature ێک بەدەست دێت، کە بە A ئاماژەی بۆ دەکرێت. لە ڕێڕەوەکەی تردا (path ەکەی تر)، feature map ەکە پاش global average pooling دەچێتە ناو <strong>fully connected network</strong> ێکی بچووک. ئەم fully connected network ە <strong>Sigmoid function</strong> بەکاردەهێنێت وەک لایەی کۆتایی (final layer) بۆ normalize کردنی output ەکە بۆ نێوان ٠ و ١، کە coefficient ێک بەدەست دەهێنێت بە ناوی α. Threshold ی کۆتایی دەتوانرێت دیاری بکرێت بە α×A. کەواتە، threshold ەکە بریتییە لە حاسڵی زەربی ژمارەیەک لە نێوان ٠ و ١ لەگەڵ average ی absolute values ی feature map ەکە. <strong>ئەم ڕێگەیە زامین (ensure) دەکات کە threshold ەکە تەنها positive نییە، بەڵکو زۆر گەورەش نابێت.</strong>

<strong>زیاد لەوە، sample ە جیاوازەکان دەبنە هۆی threshold ی جیاواز. لە ئەنجامدا، تا ڕادەیەک، ئەمە دەتوانرێت لێکدانەوەی بۆ بکرێت وەک attention mechanism ێکی تایبەتمەند: feature ە ناپەیوەندیدارەکان بە task ی ئێستا دەناسێتەوە، و لە ڕێگەی دوو convolutional layers دەیگۆڕێت بۆ بەهایەکی نزیک لە سفر، و پاشان بە بەکارهێنانی soft thresholding سفریان دەکات؛ یان بە پێچەوانەوە، feature ە پەیوەندیدارەکان بە task ی ئێستا دەناسێتەوە، و لە ڕێگەی دوو convolutional layers دەیگۆڕێت بۆ بەهایەکی دوور لە سفر، و دەیانپارێزێت (preserves them).</strong>

لە کۆتاییدا، بە کەڵەکە-کردنی (stacking) ژمارەیەک لە <strong>basic modules</strong> (<strong>Stack many basic modules</strong>) لەگەڵ convolutional layers, batch normalization, activation functions, global average pooling, و fully connected output layers, <strong>Deep Residual Shrinkage Network</strong> ی تەواو بونیاد دەنرێت.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. توانای گشتگیرکردن (Generalization Capability)

<strong>Deep Residual Shrinkage Network</strong>، لە ڕاستیدا، میتۆدێکی گشتییە بۆ <strong>feature learning</strong>. ئەمە هۆکارەکەی ئەوەیە کە لە زۆر task ی feature learning دا، sample ەکان کەم تا زۆر noise و زانیاری ناپەیوەندیدار (irrelevant information) یان تێدایە. ئەم noise و زانیارییە ناپەیوەندیدارانە ممکنە کاریگەرییان هەبێت لەسەر performance ی feature learning. بۆ نموونە:

لە <strong>Image classification</strong>، ئەگەر وێنەیەک هاوکات چەندین object ی تری تێدا بێت، ئەم object انە دەتوانرێت وەک "noise" تێبگیرێن. Deep Residual Shrinkage Network ڕەنگە بتوانێت attention mechanism بەکاربهێنێت بۆ سەرنجدان (notice) بە ئەم "noise" انە، و پاشان <strong>soft thresholding</strong> بەکاربهێنێت بۆ سفرکردنی ئەو feature انەی کە پەیوەندییان بە ئەم "noise" انەوە هەیە، بەمەش ئیحتمالی بەرزبوونەوەی image classification accuracy هەیە.

لە <strong>Speech recognition</strong>، بە تایبەتی لە ژینگەیەکی (environment) noisy وەک قسەکردن لە قەراغ شەقام یان لە ناو کارگەیەکی پیشەسازی، Deep Residual Shrinkage Network ڕەنگە accuracy ی speech recognition باشتر بکات، یان لانی کەم، میتۆدێک پێشکەش دەکات کە توانای باشترکردنی accuracy ی speech recognition ی هەبێت.

## سەرچاوەکان (Reference)

<div class="references-ltr" dir="ltr" style="text-align: left; direction: ltr;">

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

<a href="https://ieeexplore.ieee.org/document/8850096">
https://ieeexplore.ieee.org/document/8850096</a>

</div>

## کاریگەری ئەکادیمی (Academic Impact)

ئەم paper ە زیاتر لە ١٤٠٠ جار <strong>citation</strong> ی بۆ کراوە لە <strong>Google Scholar</strong>.

بەپێی ئامارە ناسەرەکییەکان (incomplete statistics)، <strong>Deep Residual Shrinkage Network (DRSN)</strong> ڕاستەوخۆ تەتبیق کراوە یان بە دەستکارییەوە تەتبیق کراوە لە زیاتر لە ١٠٠٠ publications/studies لە بوارە جیاوازەکاندا، وەک mechanical engineering, electrical power, vision, healthcare, speech, text, radar, و remote sensing.

## BibTeX

```bibtex
@article{zhao2020deep,
  title={Deep residual shrinkage networks for fault diagnosis},
  author={Zhao, Minghang and Zhong, Shisheng and Fu, Xuyun and Tang, Baoping and Pecht, Michael},
  journal={IEEE Transactions on Industrial Informatics},
  volume={16},
  number={7},
  pages={4681--4690},
  year={2020},
  publisher={IEEE}
}
```
