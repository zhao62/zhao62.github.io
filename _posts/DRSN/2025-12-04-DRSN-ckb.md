---
layout: post
title: "<div style='text-align: center; direction: rtl;'>Deep Residual Shrinkage Network: میتۆدێکی Artificial Intelligence بۆ Dataـی Highly Noisy</div>"
subtitle: "<div style='text-align: center; direction: ltr;'>Deep Residual Shrinkage Network: An Artificial Intelligence Method for Highly Noisy Data</div>"
date: 2025-12-04
tags: [Deep Learning, AI, Fault Diagnosis]
mathjax: true
lang: ckb
dir: rtl
---

<!-- CSS Styling -->
<style>
  /* 1. Force Headers Right */
  h1, h2, h3, h4, h5, h6 { text-align: right !important; direction: rtl !important; unicode-bidi: embed; }
  
  /* 2. Force Lists Right */
  ul, ol { text-align: right !important; direction: rtl !important; padding-right: 40px; padding-left: 0; }

  /* 3. Force Code LTR */
  pre, code { text-align: left !important; direction: ltr !important; }
  
  /* 4. Force References LTR */
  .references-ltr { text-align: left !important; direction: ltr !important; }
  
  /* 5. Improve Font for Kurdish */
  body, p, div { font-family: 'Unikurd Jiyaw', 'NRT Reg', 'Sakkal Majalla', 'Traditional Arabic', sans-serif; }
</style>

<!-- Main Content Wrapper -->
<div dir="rtl" markdown="1" style="text-align: right; direction: rtl; font-family: 'Sakkal Majalla', 'Traditional Arabic', serif; font-size: 1.1em; line-height: 1.8;">

<strong>Deep Residual Shrinkage Network جۆرێکی باشترکراوی Deep Residual Networkـە. بە بنەڕەت، ئەمە integrationـی Deep Residual Network، attention mechanisms، و soft thresholding functionsـە.</strong>

<strong>تا ڕادەیەک، کارکردنی Deep Residual Shrinkage Network دەتوانرێت ئاوا تێبگیرێت: ئەم networkـە attention mechanisms بەکاردەهێنێت بۆ ناسینەوەی ئەو featureـانەی کە گرنگ نین (unimportant features)، و پاشان soft thresholding functions بەکاردەهێنێت بۆ سفرکردنەوەیان (setting them to zero)؛ بە پێچەوانەوە، featureـە گرنگەکان دەناسێتەوە و دەیانپارێزێت. ئەم processـە توانای deep neural network زیاد دەکات بۆ دەرهێنانی useful features لەو signalـانەی کە noiseـیان تێدایە.</strong>

## 1. Research Motivation

<strong>یەکەم، کاتێک sampleـەکان classify دەکەین، بوونی noise — وەک Gaussian noise, pink noise, و Laplacian noise — شتێکی نەخوازراوە (inevitable).</strong> بە شێوەیەکی گشتیتر، زۆرجار sampleـەکان زانیاری (information) وایان تێدایە کە پەیوەندی نییە بە current classification taskـەکەوە، کە ئەمە دەکرێت وەک noise سەیر بکرێت. ئەم noiseـانە دەتوانن کاریگەری خراپیان هەبێت لەسەر performanceـی classification. (<strong>Soft thresholding</strong> هەنگاوێکی سەرەکییە لە زۆربەی ئەلگۆریزمەکانی <strong>signal denoising</strong>.)

بە نموونە، کاتێک لە قەراغ شەقام قسە دەکەیت، دەنگی قسەکردنەکە ڕەنگە تێکەڵ بێت لەگەڵ دەنگی hornـی سەیارە و تایەی سەیارە. کاتێک <strong>speech recognition</strong> (ناسینەوەی دەنگ) ئەنجام دەدەین لەسەر ئەم signalـانە، ئەنجامەکە (results) بێگومان کاریگەری دەنگی horn و تایەکانی لەسەر دەبێت. لە ڕوانگەی <strong>deep learning</strong>ـەوە، پێویستە ئەو featureـانەی پەیوەندییان بە horn و تایەکانەوە هەیە لاببرێن (eliminated) لە ناو <strong>deep neural network</strong>ـەکەدا، بۆ ئەوەی کاریگەری خراپیان نەبێت لەسەر ئەنجامی speech recognitionـەکە.

<strong>دووەم، تەنانەت لە ناو هەمان datasetـیشدا، بڕی noise زۆرجار لە sampleـێک بۆ sampleـێکی تر جیاوازە.</strong> (ئەمە هاوشێوەیە لەگەڵ <strong>attention mechanisms</strong>؛ ئەگەر datasetـێکی image وەربگرین وەک نموونە، شوێنی ئەو objectـەی مەبەستمانە لایان ممکنە لە هەر وێنەیەکدا جیاواز بێت، و attention mechanisms دەتوانێت focus بخاتە سەر شوێنی تایبەتی objectـەکە لە هەر وێنەیەکدا.)

بۆ نموونە، کاتێک <strong>classifier</strong>ـی سەگ و پشیلە (cat-and-dog) train دەکەین، با وا دابنێین ٥ وێنەمان هەیە کە وەک "dog" label کراون. وێنەی یەکەم ممکنە سەگ و مشکی تێدا بێت، وێنەی دووەم سەگ و قاز، وێنەی سێیەم سەگ و مریشک، وێنەی چوارەم سەگ و کەر (donkey)، و وێنەی پێنجەم سەگ و وردەکە (duck). لە کاتی trainingـدا، classifierـەکە بێگومان تووشی دەستێوەردان (interference) دەبێت لەلایەن objectـە ناپەیوەندیدارەکان وەک مشک، قاز، مریشک، کەر، و وردەکە، کە ئەمە دەبێتە هۆی کەمبوونەوەی <strong>classification accuracy</strong>. ئەگەر بتوانین ئەم objectـە ناپەیوەندیدارە بناسین — واتە مشک، قاز، مریشک، کەر، و وردەکە — و ئەو featureـانەی پەیوەندییان پێیانەوە هەیە لایان ببەین (eliminate)، ئەوا ممکنە بتوانین accuracyـی cat-and-dog classifierـەکە بەرز بکەینەوە.

## 2. Soft Thresholding

<strong>Soft thresholding هەنگاوێکی سەرەکییە (core step) لە زۆربەی ئەلگۆریزمەکانی signal denoising. ئەمە ئەو featureـانەی کە absolute valueـەکەیان کەمترە لە thresholdـێکی دیاریکراو لادەبات (eliminate)، و ئەو featureـانەی کە absolute valueـەکەیان گەورەترە لەو thresholdـە "shrink" دەکات (کەم دەکاتەوە) بەرەو سفر.</strong> ئەمە دەتوانرێت جێبەجێ بکرێت بە بەکارهێنانی ئەم formulaـیە:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

Derivativeـی outputـی soft thresholding بەرامبەر بە inputـەکە بریتییە لە:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

وەک لە سەرەوە دیارە، derivativeـی soft thresholding یا ١ـە یا ٠. ئەم تایبەتمەندییە هاوشێوەی <strong>ReLU activation function</strong>ـە. بۆیە، soft thresholding دەتوانێت مەترسی (risk) تووشبوونی <strong>deep learning algorithms</strong> بە <strong>gradient vanishing</strong> و <strong>gradient exploding</strong> کەم بکاتەوە.

<strong>لە soft thresholding functionـدا، دانانی thresholdـەکە پێویستە دوو مەرج (conditions) جێبەجێ بکات: یەکەم، thresholdـەکە دەبێت positive بێت (ژمارەیەکی موجەب بێت)؛ دووەم، thresholdـەکە نابێت لە بەهای هەرە گەورەی (maximum value) input signalـەکە زیاتر بێت، ئەگەر نا outputـەکە بە تەواوەتی دەبێت بە سفر.</strong>

<strong>هەروەها، باشترە کە thresholdـەکە مەرجی سێیەمیش جێبەجێ بکات: هەر sampleـێک دەبێت thresholdـی تایبەت بە خۆی (independent threshold) هەبێت بەپێی بڕی ئەو noiseـەی کە تێیدایەتی.</strong>

هۆکارەکە ئەوەیە کە ناوەڕۆکی noise زۆرجار جیاوازە لە ناو sampleـەکاندا. بۆ نموونە، شتێکی باوە کە لە ناو هەمان datasetـدا، Sample A noiseـی کەمتری تێدا بێت بەڵام Sample B noiseـی زیاتری تێدا بێت. لە کاتێکی ئاوادا، کاتێک soft thresholding ئەنجام دەدەین لە ناو ئەلگۆریزمێکی denoisingـدا، Sample A پێویستە thresholdـێکی بچووکتر بەکار بهێنێت، لە کاتێکدا Sample B پێویستە thresholdـێکی گەورەتر بەکار بهێنێت. ئەگەرچی ئەم feature و thresholdـانە مانای فیزیكی ئاشکرایان نامێنێت لە ناو deep neural networks، بەڵام مەنتقە بنچینەییەکە هەر هەمان شتە. واتە، هەر sampleـێک دەبێت thresholdـی سەربەخۆی هەبێت کە دیاریکراو بێت بەپێی ناوەڕۆکی noiseـەکەی.

## 3. Attention Mechanism

تێگەیشتن لە <strong>Attention mechanisms</strong> ئاسانترە لە بواری <strong>computer vision</strong>. سیستەمی بینینی ئاژەڵان دەتوانێت targetـەکان جیا بکاتەوە بە خێرا scan کردنی هەموو ناوچەکە، و پاشان focus خستنە سەر target objectـەکە بۆ دەرهێنانی وردەکاری زیاتر (extract more details) لەگەڵ سەرکوتکردنی زانیاری ناپەیوەندیدار (suppressing irrelevant information). بۆ زانیاری ورد، تکایە سەیری ئەدەبیاتی پەیوەندیدار بە attention mechanisms بکە.

<strong>Squeeze-and-Excitation Network (SENet)</strong> ڕێگایەکی نیسبەتەن نوێی deep learningـە کە attention mechanisms بەکاردەهێنێت. لە ناو sampleـە جیاوازەکاندا، بەشداری (contribution) channelـە جیاوازەکانی feature بۆ classification taskـەکە زۆرجار جیاوازە. SENet <strong>sub-network</strong>ـێکی بچووک بەکاردەهێنێت بۆ بەدەستهێنانی کۆمەڵێک weight (<strong>Learn a set of weights</strong>)، و پاشان ئەم weightـانە لێکدەدات (zarb) لە featureـی channelـە پەیوەندیدارەکان بۆ گۆڕین (adjust)ـی قەبارەی featureـەکان لە هەر channelـێکدا (<strong>Apply weighting to each feature channel</strong>). ئەم processـە دەتوانرێت ببینرێت وەک ئەنجامدانی ئاستی جیاوازی attention بۆ سەر feature channelـە جیاوازەکان.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

لە ئەم ڕێگەیەدا، هەر sampleـێک خاوەنی setـێکی سەربەخۆیە لە weight. بە واتایەکی تر، weightـەکان بۆ هەر دوو sampleـێکی جیاواز، جیاوازن. لە ناو SENetـدا، ئەو ڕێڕەوە (path)ـی تایبەتەی بۆ بەدەستهێنانی weightـەکان بەکاردێت بریتییە لە "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function."

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding with Deep Attention Mechanism

<strong>Deep Residual Shrinkage Network</strong> سوود (inspiration) لەو structureـی sub-networkـەی SENet وەردەگرێت بۆ جێبەجێکردنی soft thresholding لەژێر <strong>deep attention mechanism</strong>. لە ڕێگەی sub-networkـەکەوە (کە لە ناو سندوقە سوورەکەدا نیشان دراوە)، networkـەکە فێر دەبێت کە setـێک لە threshold دابنێت (<strong>Learn a set of thresholds</strong>) بۆ ئەنجامدانی soft thresholding بۆ هەر feature channelـێک.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

لە ناو ئەم sub-networkـەدا، سەرەتا absolute valueـی هەموو featureـەکانی input feature map حساب دەکرێت. پاشان، لە ڕێگەی <strong>global average pooling</strong> و average-کردنەوە، featureـێک بەدەست دێت، کە بە A ئاماژەی بۆ دەکرێت. لە ڕێڕەوەکەی تردا (pathـەکەی تر)، feature mapـەکە پاش global average pooling دەچێتە ناو <strong>fully connected network</strong>ـێکی بچووک. ئەم fully connected networkـە <strong>Sigmoid function</strong> بەکاردەهێنێت وەک لایەی کۆتایی (final layer) بۆ normalize کردنی outputـەکە بۆ نێوان ٠ و ١، کە coefficientـێک بەدەست دەهێنێت بە ناوی α. Thresholdـی کۆتایی دەتوانرێت دیاری بکرێت بە α×A. کەواتە، thresholdـەکە بریتییە لە حاسڵی زەربی ژمارەیەک لە نێوان ٠ و ١ لەگەڵ averageـی absolute valuesـی feature mapـەکە. <strong>ئەم ڕێگەیە زامین (ensure) دەکات کە thresholdـەکە تەنها positive نییە، بەڵکو زۆر گەورەش نابێت.</strong>

<strong>زیاد لەوە، sampleـە جیاوازەکان دەبنە هۆی thresholdـی جیاواز. لە ئەنجامدا، تا ڕادەیەک، ئەمە دەتوانرێت لێکدانەوەی بۆ بکرێت وەک attention mechanismـێکی تایبەتمەند: featureـە ناپەیوەندیدارەکان بە taskـی ئێستا دەناسێتەوە، و لە ڕێگەی دوو convolutional layers دەیگۆڕێت بۆ بەهایەکی نزیک لە سفر، و پاشان بە بەکارهێنانی soft thresholding سفریان دەکات؛ یان بە پێچەوانەوە، featureـە پەیوەندیدارەکان بە taskـی ئێستا دەناسێتەوە، و لە ڕێگەی دوو convolutional layers دەیگۆڕێت بۆ بەهایەکی دوور لە سفر، و دەیانپارێزێت (preserves them).</strong>

لە کۆتاییدا، بە کەڵەکە-کردنی (stacking) ژمارەیەک لە <strong>basic modules</strong> (<strong>Stack many basic modules</strong>) لەگەڵ convolutional layers, batch normalization, activation functions, global average pooling, و fully connected output layers, <strong>Deep Residual Shrinkage Network</strong>ـی تەواو بونیاد دەنرێت.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generalization Capability

<strong>Deep Residual Shrinkage Network</strong>، لە ڕاستیدا، میتۆدێکی گشتییە بۆ <strong>feature learning</strong>. ئەمە هۆکارەکەی ئەوەیە کە لە زۆر taskـی feature learningـدا، sampleـەکان کەم تا زۆر noise و زانیاری ناپەیوەندیدار (irrelevant information) یان تێدایە. ئەم noise و زانیارییە ناپەیوەندیدارانە ممکنە کاریگەرییان هەبێت لەسەر performanceـی feature learning. بۆ نموونە:

لە <strong>Image classification</strong>، ئەگەر وێنەیەک هاوکات چەندین objectـی تری تێدا بێت، ئەم objectـانە دەتوانرێت وەک "noise" تێبگیرێن. Deep Residual Shrinkage Network ڕەنگە بتوانێت attention mechanism بەکاربهێنێت بۆ سەرنجدان (notice) بە ئەم "noise"ـانە، و پاشان <strong>soft thresholding</strong> بەکاربهێنێت بۆ سفرکردنی ئەو featureـانەی کە پەیوەندییان بە ئەم "noise"ـانەوە هەیە، بەمەش ئیحتمالی بەرزبوونەوەی image classification accuracy هەیە.

لە <strong>Speech recognition</strong>، بە تایبەتی لە ژینگەیەکی (environment) noisy وەک قسەکردن لە قەراغ شەقام یان لە ناو کارگەیەکی پیشەسازی، Deep Residual Shrinkage Network ڕەنگە accuracyـی speech recognition باشتر بکات، یان لانی کەم، میتۆدێک پێشکەش دەکات کە توانای باشترکردنی accuracyـی speech recognitionـی هەبێت.

## Reference

<div class="references-ltr" dir="ltr" style="text-align: left; direction: ltr;">

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

<a href="https://ieeexplore.ieee.org/document/8850096">
https://ieeexplore.ieee.org/document/8850096</a>

</div>

## Academic Impact

ئەم paperـە زیاتر لە ١٤٠٠ جار <strong>citation</strong>ـی بۆ کراوە لە <strong>Google Scholar</strong>.

بەپێی ئامارە ناسەرەکییەکان (incomplete statistics)، <strong>Deep Residual Shrinkage Network (DRSN)</strong> ڕاستەوخۆ تەتبیق کراوە یان بە دەستکارییەوە تەتبیق کراوە لە زیاتر لە ١٠٠٠ publications/studies لە بوارە جیاوازەکاندا، وەک mechanical engineering, electrical power, vision, healthcare, speech, text, radar, و remote sensing.

## BibTeX

```bibtex
@article{zhao2020deep,
  title={Deep residual shrinkage networks for fault diagnosis},
  author={Zhao, Minghang and Zhong, Shisheng and Fu, Xuyun and Tang, Baoping and Pecht, Michael},
  journal={IEEE Transactions on Industrial Informatics},
  volume={16},
  number={7},
  pages={4681--4690},
  year={2020},
  publisher={IEEE}
}
```
