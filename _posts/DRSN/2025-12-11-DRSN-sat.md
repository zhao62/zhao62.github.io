---
layout: post
title: "Deep Residual Shrinkage Network: Highly Noisy Data ᱞᱟᱹᱜᱤᱫ ᱢᱤᱫᱴᱟᱹᱝ Artificial Intelligence Method"
subtitle: "An Artificial Intelligence Method for Highly Noisy Data"
date: 2025-12-11
tags: [Deep Learning, AI]
mathjax: true
---

<!-- 添加桑塔利语字体支持 -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Ol+Chiki:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
  /* 基础字体设置 */
  body, p, li, a, span, div, blockquote {
    font-family: 'Noto Sans Ol Chiki', "Helvetica Neue", Helvetica, Arial, sans-serif !important;
    line-height: 1.8; /* 正文保持宽松的行距，易于阅读 */
  }
  
  /* 专门针对标题的设置：收紧行距 */
  h1, h2, h3, h4, h5, h6, .post-title, .title {
    font-family: 'Noto Sans Ol Chiki', "Helvetica Neue", Helvetica, Arial, sans-serif !important;
    line-height: 1.3 !important; /* 标题行距收紧，看起来更紧凑 */
    margin-bottom: 20px; /* 标题下方留出一点空间 */
  }
</style>

**Deep Residual Shrinkage Network ᱫᱚ Deep Residual Network ᱨᱮᱭᱟᱜ ᱢᱤᱫᱴᱟᱹᱝ improved variant ᱠᱟᱱᱟ ᱾ ᱢᱩᱞ ᱞᱮᱠᱟᱛᱮ ᱢᱮᱱ ᱞᱮᱠᱷᱟᱱ, Deep Residual Shrinkage Network ᱫᱚ Deep Residual Network, attention mechanisms ᱟᱨ soft thresholding functions ᱠᱚᱭ integrate-ᱟ ᱾**

**ᱟᱵᱚ Deep Residual Shrinkage Network ᱨᱮᱭᱟᱜ ᱠᱟᱹᱢᱤ ᱦᱚᱨᱟ (working principle) ᱱᱚᱝᱠᱟ ᱛᱮᱵᱚ ᱵᱩᱡᱷᱟᱹᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱯᱩᱭᱞᱩ ᱨᱮ, network ᱫᱚ attention mechanisms ᱵᱮᱵᱷᱟᱨ ᱠᱟᱛᱮ ᱵᱟᱝ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ features (unimportant features) ᱠᱚᱭ ᱪᱤᱱᱦᱟᱹᱣ ᱚᱰᱚᱠᱟ ᱾ ᱤᱱᱟᱹ ᱛᱟᱭᱚᱢ, network ᱫᱚ soft thresholding functions ᱵᱮᱵᱷᱟᱨ ᱠᱟᱛᱮ ᱱᱚᱣᱟ ᱠᱚ ᱵᱟᱝ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ features ᱫᱚ zero ᱨᱮᱭ ᱥᱮᱴ (set) ᱠᱟᱜᱼᱟ ᱾ ᱟᱨ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ features ᱠᱚᱫᱚᱭ ᱫᱚᱦᱚ ᱠᱟᱜᱼᱟ ᱾ ᱱᱚᱣᱟ ᱯᱨᱚᱥᱮᱥ ᱫᱚ deep neural network ᱨᱮᱭᱟᱜ ᱫᱟᱲᱮᱭ ᱵᱟᱹᱲᱛᱤ ᱦᱚᱪᱚᱭᱟ ᱾ ᱱᱚᱣᱟ ᱫᱚ network ᱠᱮ noise ᱢᱮᱱᱟᱜ signals ᱠᱷᱚᱱ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ features ᱚᱰᱚᱠ ᱨᱮ ᱜᱚᱲᱚᱭ ᱮᱢᱟᱜᱼᱟ ᱾**

## 1. Research Motivation

**ᱯᱩᱭᱞᱩ ᱨᱮ, ᱡᱚᱠᱷᱚᱱ algorithm ᱫᱚ samples ᱮ classify-ᱟ, ᱩᱱ ᱡᱚᱦᱚᱜ noise ᱛᱟᱦᱮᱸᱱ ᱫᱚ ᱵᱟᱝ ᱮᱲᱟᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱱᱚᱣᱟ noise ᱨᱮᱭᱟᱜ ᱫᱟᱹᱭᱠᱟᱹ ᱠᱚᱫᱚ ᱦᱩᱭᱩᱜ ᱠᱟᱱᱟ Gaussian noise, pink noise, ᱟᱨ Laplacian noise ᱾** ᱟᱨᱦᱚᱸ ᱯᱩᱥᱴᱟᱹᱣ ᱥᱟᱺᱦᱤᱡ ᱢᱮᱱ ᱞᱮᱠᱷᱟᱱ, **samples** ᱨᱮ ᱟᱭᱢᱟ ᱫᱷᱟᱣ ᱱᱚᱝᱠᱟᱱ ᱠᱷᱚᱵᱚᱨ ᱛᱟᱦᱮᱸᱱᱟ ᱡᱟᱦᱟᱸ ᱫᱚ ᱱᱤᱛᱟᱜ **classification task** ᱞᱟᱹᱜᱤᱫ ᱡᱚᱲᱟᱣ ᱵᱟᱹᱱᱩᱜᱼᱟ ᱾ ᱱᱚᱣᱟ ᱠᱚ ᱵᱟᱝ ᱡᱚᱲᱟᱣ ᱠᱷᱚᱵᱚᱨ ᱫᱚ ᱟᱵᱚ **noise** ᱢᱮᱱᱛᱮ ᱵᱚ ᱢᱟᱱᱟᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱱᱚᱣᱟ **noise** ᱫᱚ **classification performance** ᱮ ᱠᱚᱢ ᱦᱚᱪᱚ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ (**Soft thresholding** ᱫᱚ ᱟᱭᱢᱟ **signal denoising algorithms** ᱨᱮ ᱢᱤᱫᱴᱟᱹᱝ ᱟᱹᱰᱤ ᱢᱩᱞ ᱫᱷᱟᱯ ᱠᱟᱱᱟ ᱾)

ᱫᱟᱹᱭᱠᱟᱹ ᱞᱮᱠᱟᱛᱮ, ᱢᱚᱱᱮ ᱠᱟᱜ ᱢᱮ ᱦᱚᱨ ᱟᱲᱮ ᱨᱮ ᱜᱟᱞᱢᱟᱨᱟᱣ ᱦᱩᱭᱩᱜ ᱠᱟᱱᱟ ᱾ ᱚᱸᱰᱮᱱᱟᱜ **audio** ᱨᱮ ᱜᱟᱹᱰᱤ ᱨᱮᱭᱟᱜ ᱥᱟᱰᱮ (car horns) ᱟᱨ ᱪᱟᱠᱟ ᱨᱮᱭᱟᱜ ᱥᱟᱰᱮ ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱟᱵᱚ ᱱᱚᱣᱟ **signals** ᱪᱮᱛᱟᱱ ᱨᱮ **speech recognition** ᱵᱚ ᱠᱚᱨᱟᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱱᱚᱣᱟ ᱛᱟᱭᱚᱢ ᱨᱮᱭᱟᱜ ᱥᱟᱰᱮ (background sounds) ᱫᱚ **results** ᱮ ᱵᱟᱹᱲᱤᱡ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ **Deep learning** ᱱᱚᱡᱚᱨ ᱛᱮ ᱧᱮᱞ ᱞᱮᱠᱷᱟᱱ, **deep neural network** ᱫᱚ ᱱᱚᱣᱟ **horns** ᱟᱨ **wheels** ᱥᱟᱞᱟᱜ ᱡᱚᱲᱟᱣ ᱢᱮᱱᱟᱜ **features** ᱠᱚ ᱚᱰᱚᱠ ᱜᱤᱰᱤ (eliminate) ᱠᱟᱜ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱾ ᱱᱚᱝᱠᱟ ᱞᱮᱠᱷᱟᱱ ᱱᱚᱣᱟ **features** ᱫᱚ **speech recognition results** ᱪᱮᱛᱟᱱ ᱨᱮ ᱵᱟᱹᱲᱤᱡ ᱚᱨᱥᱚᱝ ᱵᱟᱭ ᱯᱟᱲᱟᱣ ᱦᱚᱪᱚᱭᱟ ᱾

**ᱫᱚᱥᱟᱨ ᱠᱟᱛᱷᱟ, noise ᱨᱮᱭᱟᱜ ᱯᱚᱨᱤᱢᱟᱱ (amount) ᱫᱚ samples ᱵᱷᱤᱛᱨᱤ ᱨᱮ ᱵᱷᱮᱜᱟᱨ ᱵᱷᱮᱜᱟᱨ ᱦᱩᱭ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱱᱚᱣᱟ ᱵᱷᱮᱜᱟᱨ ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ dataset ᱨᱮᱦᱚᱸ ᱦᱩᱭᱩᱜ ᱜᱮᱭᱟ ᱾** (ᱱᱚᱣᱟ ᱵᱷᱮᱜᱟᱨ ᱫᱚ **attention mechanisms** ᱥᱟᱞᱟᱜ ᱢᱤᱞ ᱢᱮᱱᱟᱜᱼᱟ ᱾ ᱢᱤᱫᱴᱟᱹᱝ **image dataset** ᱨᱮᱭᱟᱜ ᱫᱟᱹᱭᱠᱟᱹ ᱵᱚ ᱦᱟᱛᱟᱣ ᱞᱮᱜᱮ ᱾ ᱜᱚᱴᱟ **image** ᱨᱮ **target object** ᱨᱮᱭᱟᱜ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱷᱮᱜᱟᱨ ᱦᱩᱭ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ **Attention mechanisms** ᱫᱚ ᱡᱚᱛᱚ **image** ᱨᱮ **target object** ᱨᱮᱭᱟᱜ ᱴᱷᱟᱹᱣᱠᱟᱹ ᱡᱟᱭᱜᱟ ᱨᱮ ᱫᱷᱮᱭᱟᱱ ᱮ ᱮᱢ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾)

ᱫᱟᱹᱭᱠᱟᱹ ᱞᱮᱠᱟᱛᱮ, ᱢᱤᱫᱴᱟᱹᱝ **cat-and-dog classifier** ᱴᱨᱮᱱᱤᱝ (training) ᱞᱟᱹᱜᱤᱫ ᱢᱚᱱᱮ ᱠᱟᱜ ᱢᱮ ᱕ ᱜᱚᱴᱟᱝ **images** ᱢᱮᱱᱟᱜᱼᱟ ᱡᱟᱦᱟᱸ ᱨᱮ "dog" ᱞᱮᱵᱮᱞ (label) ᱢᱮᱱᱟᱜᱼᱟ ᱾ Image 1 ᱨᱮ ᱢᱤᱫᱴᱟᱹᱝ ᱥᱮᱛᱟ ᱟᱨ ᱢᱤᱫᱴᱟᱹᱝ ᱧᱩᱛ ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ Image 2 ᱨᱮ ᱢᱤᱫᱴᱟᱹᱝ ᱥᱮᱛᱟ ᱟᱨ ᱢᱤᱫᱴᱟᱹᱝ ᱨᱟᱡᱽ ᱦᱟᱸᱥ ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ Image 3 ᱨᱮ ᱢᱤᱫᱴᱟᱹᱝ ᱥᱮᱛᱟ ᱟᱨ ᱢᱤᱫᱴᱟᱹᱝ ᱥᱤᱢ ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ Image 4 ᱨᱮ ᱢᱤᱫᱴᱟᱹᱝ ᱥᱮᱛᱟ ᱟᱨ ᱢᱤᱫᱴᱟᱹᱝ ᱜᱟᱫᱷᱟ ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ Image 5 ᱨᱮ ᱢᱤᱫᱴᱟᱹᱝ ᱥᱮᱛᱟ ᱟᱨ ᱢᱤᱫᱴᱟᱹᱝ ᱜᱮᱰᱮ ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ **Training** ᱚᱠᱛᱚ ᱨᱮ, ᱱᱚᱣᱟ ᱠᱚ ᱵᱟᱝ ᱡᱚᱲᱟᱣ ᱡᱤᱱᱤᱥ (irrelevant objects) ᱫᱚ **classifier** ᱠᱮ ᱟᱞᱮᱭᱟ (interfere) ᱾ ᱱᱚᱣᱟ ᱡᱤᱱᱤᱥ ᱠᱚᱫᱚ ᱦᱩᱭᱩᱜ ᱠᱟᱱᱟ ᱧᱩᱛ, ᱨᱟᱡᱽ ᱦᱟᱸᱥ, ᱥᱤᱢ, ᱜᱟᱫᱷᱟ ᱟᱨ ᱜᱮᱰᱮ ᱾ ᱱᱚᱣᱟ ᱠᱷᱟᱹᱛᱤᱨ **classification accuracy** ᱠᱚᱢ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱡᱩᱫᱤ ᱟᱵᱚ ᱱᱚᱣᱟ ᱠᱚ ᱵᱟᱝ ᱡᱚᱲᱟᱣ ᱡᱤᱱᱤᱥ ᱵᱚ ᱪᱤᱱᱦᱟᱹᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ, ᱛᱚᱵᱮ ᱟᱵᱚ ᱱᱚᱣᱟ ᱠᱚ ᱥᱟᱞᱟᱜ ᱡᱚᱲᱟᱣ **features** ᱵᱚ ᱚᱰᱚᱠ ᱜᱤᱰᱤ (eliminate) ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱱᱚᱝᱠᱟ ᱛᱮ, ᱟᱵᱚ **cat-and-dog classifier** ᱨᱮᱭᱟᱜ **accuracy** ᱵᱚ ᱵᱟᱹᱲᱛᱤ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾

## 2. Soft Thresholding

**Soft thresholding ᱫᱚ ᱟᱭᱢᱟ signal denoising algorithms ᱨᱮ core step ᱠᱟᱱᱟ ᱾ Algorithm ᱫᱚ features ᱮ eliminate-ᱟ ᱡᱩᱫᱤ ᱚᱱᱟ features ᱨᱮᱭᱟᱜ absolute values ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ threshold ᱠᱷᱚᱱ ᱠᱚᱢ ᱜᱮᱭᱟ ᱾ ᱟᱨ ᱡᱩᱫᱤ features ᱨᱮᱭᱟᱜ absolute values ᱫᱚ ᱱᱚᱣᱟ threshold ᱠᱷᱚᱱ ᱵᱟᱹᱲᱛᱤ ᱜᱮᱭᱟ, ᱛᱚᱵᱮ algorithm ᱫᱚ ᱱᱚᱣᱟ features ᱠᱚ zero ᱥᱮᱫ ᱮ shrink (ᱦᱩᱰᱤᱧ) ᱠᱟᱜᱼᱟ ᱾** **Researchers** ᱠᱚ ᱞᱟᱛᱟᱨ ᱨᱮ ᱮᱢ ᱟᱠᱟᱱ ᱯᱷᱚᱨᱢᱩᱞᱟ ᱛᱮ **soft thresholding** ᱠᱚ ᱵᱮᱵᱷᱟᱨ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

**Input** ᱞᱟᱹᱜᱤᱫ **Soft thresholding output** ᱨᱮᱭᱟᱜ **derivative** ᱫᱚ ᱦᱩᱭᱩᱜ ᱠᱟᱱᱟ:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

ᱪᱮᱛᱟᱱ ᱨᱮᱭᱟᱜ ᱯᱷᱚᱨᱢᱩᱞᱟ ᱫᱚ ᱩᱫᱩᱜ ᱮᱫᱟᱭ ᱡᱮ **soft thresholding** ᱨᱮᱭᱟᱜ **derivative** ᱫᱚ 1 ᱵᱟᱝᱠᱷᱟᱱ 0 ᱦᱩᱭᱩᱜᱼᱟ ᱾ ᱱᱚᱣᱟ ᱜᱩᱱ (property) ᱫᱚ **ReLU activation function** ᱨᱮᱭᱟᱜ ᱜᱩᱱ ᱥᱟᱞᱟᱜ ᱥᱚᱢᱟᱱ ᱜᱮᱭᱟ ᱾ ᱚᱱᱟᱛᱮ, **soft thresholding** ᱫᱚ **deep learning algorithms** ᱨᱮ **gradient vanishing** ᱟᱨ **gradient exploding** ᱨᱮᱭᱟᱜ ᱵᱚᱛᱚᱨ ᱮ ᱠᱚᱢ ᱦᱚᱪᱚᱭᱟ ᱾

**Soft thresholding function ᱨᱮ, threshold ᱨᱮᱭᱟᱜ setting ᱫᱚ ᱵᱟᱨᱭᱟ ᱥᱚᱨᱛᱚ (conditions) ᱢᱟᱱᱟᱣ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱾ ᱯᱩᱭᱞᱩ, threshold ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ positive number ᱦᱩᱭᱩᱜ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱾ ᱫᱚᱥᱟᱨ, threshold ᱫᱚ input signal ᱨᱮᱭᱟᱜ maximum value ᱠᱷᱚᱱ ᱵᱟᱹᱲᱛᱤ ᱵᱟᱝ ᱦᱩᱭᱩᱜ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱾ ᱵᱟᱝᱠᱷᱟᱱ, output ᱫᱚ ᱯᱩᱨᱟᱹ zero ᱦᱩᱭᱩᱜᱼᱟ ᱾**

**ᱤᱱᱟᱹ ᱥᱟᱶᱛᱮ, threshold ᱫᱚ ᱛᱮᱥᱟᱨ ᱥᱚᱨᱛᱚ ᱦᱚᱸᱭ ᱢᱟᱱᱟᱣ ᱞᱮᱠᱷᱟᱱ ᱱᱟᱯᱟᱭᱚᱜᱼᱟ ᱾ ᱡᱚᱛᱚ sample ᱨᱮᱭᱟᱜ noise content ᱞᱮᱠᱟᱛᱮ, ᱟᱯᱱᱟᱨᱟᱜ independent threshold ᱛᱟᱦᱮᱸᱱ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱾**

ᱚᱱᱟ ᱨᱮᱭᱟᱜ ᱠᱟᱨᱚᱱ ᱫᱚ, **noise content** ᱫᱚ ᱟᱭᱢᱟ ᱫᱷᱟᱣ **samples** ᱛᱟᱞᱟ ᱨᱮ ᱵᱷᱮᱜᱟᱨ ᱵᱷᱮᱜᱟᱨ ᱛᱟᱦᱮᱸᱱᱟ ᱾ ᱫᱟᱹᱭᱠᱟᱹ ᱞᱮᱠᱟᱛᱮ, ᱢᱤᱫᱴᱟᱹᱝ **dataset** ᱨᱮ **Sample A** ᱨᱮ ᱠᱚᱢ **noise** ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱟᱨ **Sample B** ᱨᱮ ᱵᱟᱹᱲᱛᱤ **noise** ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱱᱚᱝᱠᱟᱱ ᱚᱠᱛᱚ ᱨᱮ, **Sample A** ᱫᱚ **soft thresholding** ᱡᱚᱦᱚᱜ ᱦᱩᱰᱤᱧ **threshold** ᱮ ᱵᱮᱵᱷᱟᱨ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱾ ᱟᱨ **Sample B** ᱫᱚ ᱢᱟᱨᱟᱝ **threshold** ᱮ ᱵᱮᱵᱷᱟᱨ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱾ **Deep neural networks** ᱨᱮ ᱱᱚᱣᱟ **features** ᱟᱨ **thresholds** ᱨᱮᱭᱟᱜ ᱡᱟᱦᱟᱸᱱ ᱯᱩᱥᱴᱟᱹᱣ **physical definitions** ᱵᱟᱹᱱᱩᱜ ᱨᱮᱦᱚᱸ, ᱢᱩᱞ ᱠᱟᱛᱷᱟ (underlying logic) ᱫᱚ ᱢᱤᱫ ᱜᱮ ᱛᱟᱦᱮᱸᱱᱟ ᱾ ᱢᱮᱱ ᱨᱮᱭᱟᱜ ᱠᱟᱛᱷᱟ ᱫᱚ, ᱡᱚᱛᱚ **sample** ᱞᱟᱹᱜᱤᱫ ᱢᱤᱫᱴᱟᱹᱝ **independent threshold** ᱛᱟᱦᱮᱸᱱ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱾ ᱱᱚᱣᱟ **threshold** ᱫᱚ **noise content** ᱪᱮᱛᱟᱱ ᱨᱮ ᱱᱤᱨᱵᱷᱚᱨᱟ ᱾

## 3. Attention Mechanism

**Computer vision** ᱨᱮᱭᱟᱜ **field** ᱨᱮ **researchers** ᱠᱚᱫᱚ **attention mechanisms** ᱟᱹᱰᱤ ᱟᱞᱜᱟ ᱛᱮᱠᱚ ᱵᱩᱡᱷᱟᱹᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱡᱤᱭᱟᱹᱞᱤ ᱠᱚᱣᱟᱜ ᱧᱮᱞ ᱫᱟᱲᱮ (visual systems) ᱫᱚ ᱜᱚᱴᱟ ᱡᱟᱭᱜᱟ ᱨᱮ ᱞᱚᱜᱚᱱ ᱧᱮᱞ ᱟᱹᱪᱩᱨ ᱠᱟᱛᱮ **targets** ᱠᱚ ᱪᱤᱱᱦᱟᱹᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱤᱱᱟᱹ ᱛᱟᱭᱚᱢ, ᱩᱱᱠᱩᱣᱟᱜ **visual systems** ᱫᱚ **target object** ᱪᱮᱛᱟᱱ ᱨᱮ **attention** ᱠᱚ ᱯᱷᱚᱠᱚᱥ (focus)-ᱟ ᱾ ᱱᱚᱣᱟ ᱠᱟᱹᱢᱤ ᱦᱚᱨᱟ ᱫᱚ **systems** ᱠᱚ ᱵᱟᱹᱲᱛᱤ **details** ᱚᱰᱚᱠ (extract) ᱨᱮ ᱜᱚᱲᱚᱭ ᱮᱢᱟᱜᱼᱟ ᱾ ᱥᱟᱶ ᱥᱟᱶᱛᱮ, **systems** ᱫᱚ ᱵᱟᱝ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ ᱠᱷᱚᱵᱚᱨ (irrelevant information) ᱮ ᱫᱟᱵᱟᱣ (suppress) ᱠᱟᱜᱼᱟ ᱾ ᱵᱟᱹᱲᱛᱤ ᱵᱟᱰᱟᱭ ᱞᱟᱹᱜᱤᱫ, ᱫᱟᱭᱟᱠᱟᱛᱮ **attention mechanisms** ᱨᱮᱭᱟᱜ ᱯᱚᱛᱚᱵ ᱠᱚ ᱯᱟᱲᱦᱟᱣ ᱯᱮ ᱾

**Squeeze-and-Excitation Network (SENet)** ᱫᱚ **attention mechanisms** ᱵᱮᱵᱷᱟᱨ ᱠᱟᱛᱮ ᱢᱤᱫᱴᱟᱹᱝ ᱱᱟᱣᱟ **deep learning method** ᱠᱟᱱᱟ ᱾ ᱵᱷᱮᱜᱟᱨ ᱵᱷᱮᱜᱟᱨ **samples** ᱨᱮ, **classification task** ᱞᱟᱹᱜᱤᱫ ᱵᱷᱮᱜᱟᱨ ᱵᱷᱮᱜᱟᱨ **feature channels** ᱨᱮᱭᱟᱜ ᱮᱱᱮᱢ (contribution) ᱵᱷᱮᱜᱟᱨ ᱜᱮᱭᱟ ᱾ **SENet** ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ ᱦᱩᱰᱤᱧ **sub-network** ᱮ ᱵᱮᱵᱷᱟᱨᱟ ᱢᱤᱫᱴᱟᱹᱝ **set of weights** ᱧᱟᱢ ᱞᱟᱹᱜᱤᱫ ᱾ ᱤᱱᱟᱹ ᱛᱟᱭᱚᱢ, **SENet** ᱫᱚ ᱱᱚᱣᱟ **weights** ᱠᱚ ᱚᱱᱟ ᱨᱮᱭᱟᱜ **features** ᱥᱟᱞᱟᱜ ᱮ ᱜᱟᱵᱟᱬ (multiply)-ᱟ ᱾ ᱱᱚᱣᱟ ᱠᱟᱹᱢᱤ ᱫᱚ ᱡᱚᱛᱚ **channel** ᱨᱮ **features** ᱨᱮᱭᱟᱜ ᱢᱟᱨᱟᱝ-ᱦᱩᱰᱤᱧ ᱮ ᱴᱷᱤᱠᱟ ᱾ ᱟᱵᱚ ᱱᱚᱣᱟ ᱯᱨᱚᱥᱮᱥ ᱫᱚ ᱵᱷᱮᱜᱟᱨ ᱵᱷᱮᱜᱟᱨ **feature channels** ᱨᱮ ᱵᱷᱮᱜᱟᱨ ᱞᱮᱵᱮᱞ ᱨᱮᱭᱟᱜ **attention** ᱮᱢ ᱞᱮᱠᱟ ᱵᱚ ᱧᱮᱞ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

ᱱᱚᱣᱟ ᱦᱚᱨᱟ (approach) ᱨᱮ, ᱡᱚᱛᱚ **sample** ᱨᱮᱭᱟᱜ ᱢᱤᱫᱴᱟᱹᱝ **independent set of weights** ᱛᱟᱦᱮᱸᱱᱟ ᱾ ᱮᱴᱟᱜ ᱞᱮᱠᱟᱛᱮ ᱢᱮᱱ ᱞᱮᱠᱷᱟᱱ, ᱡᱟᱦᱟᱸ ᱵᱟᱨᱭᱟ **samples** ᱨᱮᱭᱟᱜ **weights** ᱫᱚ ᱵᱷᱮᱜᱟᱨ ᱜᱮᱭᱟ ᱾ **SENet** ᱨᱮ, **weights** ᱧᱟᱢ ᱨᱮᱭᱟᱜ ᱦᱚᱨᱟ ᱫᱚ ᱦᱩᱭᱩᱜ ᱠᱟᱱᱟ: "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function" ᱾

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding with Deep Attention Mechanism

**Deep Residual Shrinkage Network** ᱫᱚ **SENet sub-network** ᱨᱮᱭᱟᱜ ᱜᱚᱲᱦᱚᱱ (structure) ᱮ ᱵᱮᱵᱷᱟᱨᱟ ᱾ **Network** ᱫᱚ ᱱᱚᱣᱟ ᱜᱚᱲᱦᱚᱱ ᱮ ᱵᱮᱵᱷᱟᱨᱟ **deep attention mechanism** ᱨᱮ **soft thresholding** ᱞᱟᱹᱜᱩ (implement) ᱞᱟᱹᱜᱤᱫ ᱾ **Sub-network** (ᱡᱟᱦᱟᱸ ᱫᱚ ᱟᱨᱟᱜ ᱵᱟᱠᱥᱟ ᱵᱷᱤᱛᱨᱤ ᱨᱮ ᱢᱮᱱᱟᱜᱼᱟ) ᱫᱚ **Learn a set of thresholds** ᱨᱮᱭᱟᱜ ᱠᱟᱹᱢᱤᱭᱟᱭ ᱾ ᱤᱱᱟᱹ ᱛᱟᱭᱚᱢ, **network** ᱫᱚ ᱱᱚᱣᱟ **thresholds** ᱵᱮᱵᱷᱟᱨ ᱠᱟᱛᱮ ᱡᱚᱛᱚ **feature channel** ᱨᱮ **soft thresholding** ᱮ **apply**-ᱭᱟ ᱾

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

ᱱᱚᱣᱟ **sub-network** ᱨᱮ, **system** ᱫᱚ ᱯᱩᱭᱞᱩ **input feature map** ᱨᱮᱭᱟᱜ ᱡᱚᱛᱚ **features** ᱨᱮᱭᱟᱜ **absolute values** ᱮ **calculate**-ᱟ ᱾ ᱤᱱᱟᱹ ᱛᱟᱭᱚᱢ, **system** ᱫᱚ **global average pooling** ᱟᱨ **averaging** ᱠᱚᱨᱟᱣ ᱠᱟᱛᱮ ᱢᱤᱫᱴᱟᱹᱝ **feature** ᱮ ᱧᱟᱢᱟ, ᱡᱟᱦᱟᱸ ᱫᱚ A ᱢᱮᱱᱛᱮ ᱵᱚ ᱩᱫᱩᱜᱟ ᱾ ᱮᱴᱟᱜ ᱦᱚᱨᱟ (path) ᱨᱮ, **system** ᱫᱚ **global average pooling** ᱛᱟᱭᱚᱢ **feature map** ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ ᱦᱩᱰᱤᱧ **fully connected network** ᱨᱮᱭ ᱵᱚᱞᱚ ᱦᱚᱪᱚᱭᱟ ᱾ ᱱᱚᱣᱟ **fully connected network** ᱫᱚ **Sigmoid function** ᱮ ᱵᱮᱵᱷᱟᱨᱟ ᱢᱩᱪᱟᱹᱫ **layer** ᱞᱮᱠᱟᱛᱮ ᱾ ᱱᱚᱣᱟ **function** ᱫᱚ **output** ᱠᱮ 0 ᱟᱨ 1 ᱛᱟᱞᱟ ᱨᱮᱭ **normalize**-ᱟ ᱾ ᱱᱚᱣᱟ ᱯᱨᱚᱥᱮᱥ ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ **coefficient** ᱮ ᱮᱢᱚᱜᱼᱟ, ᱡᱟᱦᱟᱸ ᱫᱚ α ᱢᱮᱱᱛᱮ ᱵᱚ ᱩᱫᱩᱜᱟ ᱾ ᱟᱵᱚ ᱢᱩᱪᱟᱹᱫ **threshold** ᱫᱚ α × A ᱢᱮᱱᱛᱮ ᱵᱚ ᱩᱫᱩᱜ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱚᱱᱟᱛᱮ, **threshold** ᱫᱚ ᱵᱟᱨᱭᱟ ᱱᱚᱢᱵᱚᱨ ᱨᱮᱭᱟᱜ ᱜᱟᱵᱟᱬ (product) ᱠᱟᱱᱟ ᱾ ᱢᱤᱫᱴᱟᱹᱝ ᱱᱚᱢᱵᱚᱨ ᱫᱚ 0 ᱟᱨ 1 ᱛᱟᱞᱟ ᱨᱮ ᱢᱮᱱᱟᱜᱼᱟ ᱾ ᱫᱚᱥᱟᱨ ᱱᱚᱢᱵᱚᱨ ᱫᱚ **feature map** ᱨᱮᱭᱟᱜ **absolute values** ᱨᱮᱭᱟᱜ **average** ᱠᱟᱱᱟ ᱾ **ᱱᱚᱣᱟ ᱦᱚᱨᱟ (method) ᱫᱚ threshold ᱡᱮᱢᱚᱱ positive ᱛᱟᱦᱮᱸᱱᱟ ᱚᱱᱟᱭ ᱜᱟᱨᱮᱱᱴᱤ (ensure) ᱭᱟ ᱾ ᱱᱚᱣᱟ ᱦᱚᱨᱟ ᱫᱚ threshold ᱡᱮᱢᱚᱱ ᱟᱹᱰᱤ ᱢᱟᱨᱟᱝ ᱵᱟᱝ ᱦᱩᱭᱩᱜᱼᱟ, ᱚᱱᱟ ᱦᱚᱸᱭ ᱧᱮᱞᱟ ᱾**

**ᱟᱨᱦᱚᱸ, ᱵᱷᱮᱜᱟᱨ ᱵᱷᱮᱜᱟᱨ samples ᱫᱚ ᱵᱷᱮᱜᱟᱨ ᱵᱷᱮᱜᱟᱨ thresholds ᱮ ᱵᱮᱱᱟᱣᱟ ᱾ ᱚᱱᱟ ᱠᱷᱟᱹᱛᱤᱨ, ᱟᱵᱚ ᱱᱚᱣᱟ ᱦᱚᱨᱟ ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ ᱵᱷᱮᱜᱟᱨ (specialized) attention mechanism ᱢᱮᱱᱛᱮ ᱵᱚ ᱵᱩᱡᱷᱟᱹᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱱᱚᱣᱟ mechanism ᱫᱚ ᱱᱤᱛᱟᱜ task ᱞᱟᱹᱜᱤᱫ ᱵᱟᱝ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ features ᱮ ᱪᱤᱱᱦᱟᱹᱣᱟ ᱾ ᱱᱚᱣᱟ mechanism ᱫᱚ ᱵᱟᱨᱭᱟ convolutional layers ᱵᱮᱵᱷᱟᱨ ᱠᱟᱛᱮ ᱱᱚᱣᱟ features ᱠᱚ 0 ᱥᱩᱨ ᱨᱮᱭᱟᱜ values ᱨᱮᱭ ᱵᱚᱫᱚᱞᱟ ᱾ ᱤᱱᱟᱹ ᱛᱟᱭᱚᱢ, mechanism ᱫᱚ soft thresholding ᱵᱮᱵᱷᱟᱨ ᱠᱟᱛᱮ ᱱᱚᱣᱟ features ᱫᱚ zero ᱨᱮᱭ ᱥᱮᱴ (set) ᱠᱟᱜᱼᱟ ᱾ ᱟᱨ ᱵᱟᱝᱠᱷᱟᱱ, mechanism ᱫᱚ ᱱᱤᱛᱟᱜ task ᱞᱟᱹᱜᱤᱫ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ features ᱮ ᱪᱤᱱᱦᱟᱹᱣᱟ ᱾ mechanism ᱫᱚ ᱵᱟᱨᱭᱟ convolutional layers ᱵᱮᱵᱷᱟᱨ ᱠᱟᱛᱮ ᱱᱚᱣᱟ features ᱠᱚ 0 ᱠᱷᱚᱱ ᱥᱟᱦᱟ ᱨᱮᱭᱟᱜ values ᱨᱮᱭ ᱵᱚᱫᱚᱞᱟ ᱾ ᱢᱩᱪᱟᱹᱫ ᱨᱮ, mechanism ᱫᱚ ᱱᱚᱣᱟ features ᱮ ᱫᱚᱦᱚ (preserve) ᱠᱟᱜᱼᱟ ᱾**

ᱢᱩᱪᱟᱹᱫ ᱨᱮ, ᱟᱵᱚ **Stack many basic modules** ᱨᱮᱭᱟᱜ ᱠᱟᱹᱢᱤ ᱵᱚ ᱠᱚᱨᱟᱣᱟ ᱾ ᱟᱵᱚ **convolutional layers**, **batch normalization**, **activation functions**, **global average pooling**, ᱟᱨ **fully connected output layers** ᱦᱚᱸ ᱵᱚ ᱢᱮᱥᱟᱭᱟ ᱾ ᱱᱚᱣᱟ ᱯᱨᱚᱥᱮᱥ ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ ᱯᱩᱨᱟᱹ **Deep Residual Shrinkage Network** ᱮ ᱵᱮᱱᱟᱣ ᱨᱟᱠᱟᱵᱟ ᱾

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generalization Capability

**Deep Residual Shrinkage Network** ᱫᱚ **feature learning** ᱞᱟᱹᱜᱤᱫ ᱢᱤᱫᱴᱟᱹᱝ **general method** ᱠᱟᱱᱟ ᱾ ᱚᱱᱟ ᱨᱮᱭᱟᱜ ᱠᱟᱨᱚᱱ ᱫᱚ, ᱟᱭᱢᱟ **feature learning tasks** ᱨᱮ **samples** ᱨᱮ ᱟᱭᱢᱟ **noise** ᱛᱟᱦᱮᱸᱱᱟ ᱾ **Samples** ᱨᱮ ᱵᱟᱝ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ ᱠᱷᱚᱵᱚᱨ (irrelevant information) ᱦᱚᱸ ᱛᱟᱦᱮᱸᱱᱟ ᱾ ᱱᱚᱣᱟ **noise** ᱟᱨ ᱵᱟᱝ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ ᱠᱷᱚᱵᱚᱨ ᱫᱚ **feature learning** ᱨᱮᱭᱟᱜ ᱠᱟᱹᱢᱤ ᱨᱮ ᱵᱟᱹᱲᱤᱡ ᱚᱨᱥᱚᱝ ᱮ ᱯᱟᱠᱟᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱫᱟᱹᱭᱠᱟᱹ ᱞᱮᱠᱟᱛᱮ:

**Image classification** ᱨᱮᱭᱟᱜ ᱠᱟᱛᱷᱟ ᱵᱚ ᱜᱟᱞᱢᱟᱨᱟᱣ ᱞᱮᱜᱮ ᱾ ᱢᱤᱫᱴᱟᱹᱝ **image** ᱨᱮ ᱟᱭᱢᱟ ᱮᱴᱟᱜ ᱡᱤᱱᱤᱥ (objects) ᱛᱟᱦᱮᱸ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱟᱵᱚ ᱱᱚᱣᱟ ᱡᱤᱱᱤᱥ ᱠᱚᱫᱚ "noise" ᱢᱮᱱᱛᱮ ᱵᱚ ᱵᱩᱡᱷᱟᱹᱣ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ **Deep Residual Shrinkage Network** ᱫᱚ ᱯᱟᱞᱮ ᱱᱚᱣᱟ **attention mechanism** ᱮ ᱵᱮᱵᱷᱟᱨ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ **Network** ᱫᱚ ᱱᱚᱣᱟ "noise" ᱮ ᱧᱮᱞ ᱧᱟᱢᱟ ᱾ ᱤᱱᱟᱹ ᱛᱟᱭᱚᱢ, **network** ᱫᱚ **soft thresholding** ᱵᱮᱵᱷᱟᱨ ᱠᱟᱛᱮ ᱱᱚᱣᱟ "noise" ᱥᱟᱞᱟᱜ ᱡᱚᱲᱟᱣ **features** ᱫᱚ **zero** ᱨᱮᱭ ᱥᱮᱴ (set) ᱠᱟᱜᱼᱟ ᱾ ᱱᱚᱣᱟ ᱠᱟᱹᱢᱤ ᱫᱚ **image classification accuracy** ᱵᱟᱹᱲᱛᱤ ᱨᱮ ᱜᱚᱲᱚᱭ ᱮᱢ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾

**Speech recognition** ᱨᱮᱭᱟᱜ ᱠᱟᱛᱷᱟ ᱵᱚ ᱜᱟᱞᱢᱟᱨᱟᱣ ᱞᱮᱜᱮ ᱾ ᱵᱤᱥᱮᱥ ᱠᱟᱛᱮ, ᱦᱚᱨ ᱟᱲᱮ ᱨᱮ ᱵᱟᱝᱠᱷᱟᱱ **factory workshop** ᱵᱷᱤᱛᱨᱤ ᱨᱮ ᱜᱟᱞᱢᱟᱨᱟᱣ ᱡᱚᱦᱚᱜ ᱟᱹᱰᱤ ᱥᱟᱰᱮ (noisy environments) ᱛᱟᱦᱮᱸᱱᱟ ᱾ **Deep Residual Shrinkage Network** ᱫᱚ **speech recognition accuracy** ᱵᱟᱹᱲᱛᱤ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾ ᱵᱟᱝᱠᱷᱟᱱ ᱠᱚᱢ ᱥᱮ ᱠᱚᱢ, **network** ᱫᱚ ᱢᱤᱫᱴᱟᱹᱝ ᱦᱚᱨᱟ (methodology) ᱭ ᱩᱫᱩᱜᱟ ᱾ ᱱᱚᱣᱟ ᱦᱚᱨᱟ ᱫᱚ **speech recognition accuracy** ᱵᱟᱹᱲᱛᱤ ᱨᱮ ᱜᱚᱲᱚᱭ ᱮᱢ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱾

## Reference

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

[https://ieeexplore.ieee.org/document/8850096](https://ieeexplore.ieee.org/document/8850096)

## BibTeX
```bibtex
@article{Zhao2020,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}
```

## Academic Impact

ᱱᱚᱣᱟ **paper** ᱫᱚ **Google Scholar** ᱨᱮ ᱑᱔᱐᱐ ᱠᱷᱚᱱ ᱵᱟᱹᱲᱛᱤ **citations** ᱮ ᱧᱟᱢ ᱟᱠᱟᱫᱟ ᱾

ᱵᱟᱝ ᱯᱩᱨᱟᱹᱣ ᱟᱠᱟᱱ ᱦᱤᱥᱟᱹᱵ (incomplete statistics) ᱞᱮᱠᱟᱛᱮ, **researchers** ᱠᱚᱫᱚ **Deep Residual Shrinkage Network (DRSN)** ᱑᱐᱐᱐ ᱠᱷᱚᱱ ᱵᱟᱹᱲᱛᱤ **publications/studies** ᱨᱮᱠᱚ ᱞᱟᱹᱜᱩ (applied) ᱟᱠᱟᱫᱟ ᱾ ᱱᱚᱣᱟ ᱠᱚᱫᱚ ᱟᱭᱢᱟ **fields** ᱨᱮ ᱢᱮᱱᱟᱜᱼᱟ ᱾ ᱱᱚᱣᱟ **fields** ᱠᱚᱫᱚ ᱦᱩᱭᱩᱜ ᱠᱟᱱᱟ **mechanical engineering**, **electrical power**, **vision**, **healthcare**, **speech**, **text**, **radar**, ᱟᱨ **remote sensing** ᱾
