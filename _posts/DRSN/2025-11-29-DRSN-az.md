---
layout: post
title: "Deep Residual Shrinkage Network: Güclü səs-küylü məlumatlar üçün Süni İntellekt metodu"
date: 2025-11-29
tags: [Deep Learning, AI]
mathjax: true
---

**Deep Residual Shrinkage Network (DRSN) – Deep Residual Network (ResNet) arxitekturasının təkmilləşdirilmiş versiyasıdır. Mahiyyət etibarilə, bu, ResNet, diqqət mexanizmləri (attention mechanisms) və "soft thresholding" (yumşaq hüdudlama) funksiyalarının inteqrasiyasıdır.**

**Müəyyən mənada, Deep Residual Shrinkage Network-ün iş prinsipini belə başa düşmək olar: model, diqqət mexanizmi vasitəsilə vacib olmayan xüsusiyyətləri (features) aşkar edir və soft thresholding funksiyası ilə onları sıfıra bərabər edir; və ya əksinə, vacib xüsusiyyətləri diqqətə alır və onları saxlayır. Bununla da, dərin neyron şəbəkəsinin (Deep Neural Network) tərkibində səs-küy olan siqnallardan faydalı xüsusiyyətləri çıxarmaq qabiliyyəti gücləndirilir.**

## 1. Tədqiqat Motivasiyası
**Birincisi, nümunələri təsnif edərkən (classification), onların tərkibində qaçılmaz olaraq müəyyən qədər səs-küy (noise) olur – məsələn, Qauss səs-küyü, çəhrayı səs-küy, Laplas səs-küyü və s.** Daha geniş mənada desək, nümunənin tərkibində cari təsnifat tapşırığına aid olmayan məlumatlar ola bilər və bu məlumatlar da səs-küy kimi başa düşülə bilər. Bu səs-küylər təsnifatın nəticəsinə mənfi təsir göstərə bilər. (Soft thresholding bir çox siqnal təmizləmə alqoritmlərində həlledici addımdır).

Məsələn, yol kənarında söhbət edərkən, danışıq səsinə avtomobillərin siqnal səsləri, təkər səsləri və s. qarışa bilər. Bu səs siqnalları üzərində nitqin tanınması (speech recognition) aparılarkən, nəticə istər-istəməz siqnal və təkər səslərindən təsirlənəcək. Deep Learning (Dərin Öyrənmə) baxımından yanaşsaq, bu kənar səslərə uyğun gələn xüsusiyyətlər dərin neyron şəbəkəsinin daxilində "silinməlidir" ki, nitqin tanınması prosesinə mənfi təsir etməsin.

**İkincisi, hətta eyni verilənlər bazasında (dataset) belə, hər bir nümunənin səs-küy səviyyəsi tez-tez fərqli olur.** (Bu, diqqət mexanizmi ilə oxşarlıq təşkil edir; məsələn, bir şəkil datasetində hədəf obyektin yeri şəkillərdə fərqli ola bilər; diqqət mexanizmi hər şəkildə hədəf obyektin yerinə xüsusi olaraq fokuslana bilir).

Məsələn, pişik və it təsnifatçısını (classifier) öyrədərkən, "it" etiketi olan 5 şəkil düşünək. 1-ci şəkildə it və siçan, 2-ci şəkildə it və qaz, 3-cü şəkildə it və toyuq, 4-cü şəkildə it və eşşək, 5-ci şəkildə isə it və ördək ola bilər. Biz modeli öyrədərkən, istər-istəməz siçan, qaz, toyuq, eşşək və ördək kimi kənar obyektlərin müdaxiləsinə məruz qalırıq, bu da təsnifatın dəqiqliyini aşağı salır. Əgər biz bu kənar obyektləri – siçanı, qazı, toyuğu, eşşəyi və ördəyi aşkar edib, onlara uyğun gələn xüsusiyyətləri silə bilsək, pişik-it təsnifatçısının dəqiqliyini artırmaq mümkün olar.

## 2. Soft Thresholding (Yumşaq Hüdudlama)
**Soft thresholding – bir çox siqnal təmizləmə alqoritmlərinin əsas addımıdır. Bu proses, mütləq qiyməti müəyyən bir hüduddan (threshold) kiçik olan xüsusiyyətləri silir, mütləq qiyməti həmin hüduddan böyük olan xüsusiyyətləri isə sıfıra doğru "yığır" (shrinkage).** Bunu aşağıdakı düsturla həyata keçirmək olar:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

Soft thresholding çıxışının girişə nəzərən törəməsi belədir:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

Yuxarıdan göründüyü kimi, soft thresholding-in törəməsi ya 1-dir, ya da 0. Bu xüsusiyyət ReLU aktivasiya funksiyası ilə eynidir. Buna görə də, soft thresholding həm də Deep Learning alqoritmlərinin "gradient vanishing" (qradientin yoxa çıxması) və "gradient exploding" (qradientin partlaması) risklərini azaltmağa kömək edir.

**Soft thresholding funksiyasında hüdud qiymətinin (threshold) təyini iki şərtə cavab verməlidir: Birincisi, hüdud müsbət ədəd olmalıdır; İkincisi, hüdud giriş siqnalının maksimum qiymətindən böyük ola bilməz, əks halda çıxış tamamilə sıfıra bərabər olar.**

**Eyni zamanda, hüdudun üçüncü bir şərtə də uyğun olması arzuolunandır: hər bir nümunə öz səs-küy miqdarına uyğun olaraq öz müstəqil hüdud qiymətinə malik olmalıdır.**

Çünki bir çox hallarda nümunələrin səs-küy tərkibi fərqli olur. Məsələn, eyni dataset daxilində Nümunə A-nın az səs-küylü, Nümunə B-nin isə çox səs-küylü olması tez-tez rast gəlinən haldır. Belə olan halda, siqnal təmizləmə alqoritmində soft thresholding tətbiq edilərkən, Nümunə A üçün daha kiçik hüdud, Nümunə B üçün isə daha böyük hüdud istifadə edilməlidir. Dərin neyron şəbəkələrində bu xüsusiyyətlər və hüdudlar öz dəqiq fiziki mənalarını itirsələr də, əsas məntiq eyni qalır. Yəni, hər bir nümunə öz səs-küy səviyyəsinə uyğun olaraq fərdi hüdud qiymətinə malik olmalıdır.

## 3. Diqqət Mexanizmi (Attention Mechanism)
Kompüter görməsi (Computer Vision) sahəsində diqqət mexanizmini başa düşmək nisbətən asandır. Heyvanların görmə sistemi bütün sahəni sürətlə skan edə, hədəf obyekti tapa və diqqəti həmin obyektə cəmləyərək daha çox detal əldə edə bilir, eyni zamanda lazımsız məlumatları ignor edir. Təfərrüatlar üçün diqqət mexanizmi haqqında olan ədəbiyyata baxa bilərsiniz.

Squeeze-and-Excitation Network (SENet) diqqət mexanizminə əsaslanan nisbətən yeni bir Deep Learning metodudur. Müxtəlif nümunələrdə, müxtəlif xüsusiyyət kanallarının (feature channels) təsnifat tapşırığına verdiyi töhfə çox vaxt fərqli olur. SENet kiçik bir alt-şəbəkə (sub-network) vasitəsilə bir qrup çəki əmsalı (weights) əldə edir və sonra bu çəkiləri hər bir kanalın xüsusiyyətlərinə vuraraq onların böyüklüyünü tənzimləyir. Bu prosesi, müxtəlif xüsusiyyət kanallarına fərqli dərəcədə diqqət yetirmək kimi qəbul etmək olar.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-29-DRSN-az/SENET_az_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

Bu üsulda hər bir nümunənin özünəməxsus çəki qrupu olur. Başqa sözlə, ixtiyari iki nümunənin çəkiləri bir-birindən fərqlidir. SENet-də çəkilərin əldə edilməsi yolu belədir: "Global Pooling → Tam əlaqəli lay (Fully Connected Layer) → ReLU funksiyası → Tam əlaqəli lay → Sigmoid funksiyası".

<p align="center">
  <img src="/assets/img/DRSN/2025-11-29-DRSN-az/SENET_az_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Dərin Diqqət Mexanizmi altında Soft Thresholding
Deep Residual Shrinkage Network, dərin diqqət mexanizmi altında soft thresholding-i reallaşdırmaq üçün yuxarıda bəhs edilən SENet-in alt-şəbəkə strukturundan istifadə edir (bu struktur məqalədə SENet-dən ilhamlanaraq adaptasiya edilib). Qırmızı çərçivə daxilindəki alt-şəbəkə vasitəsilə bir qrup hüdud qiyməti öyrənilir və hər bir xüsusiyyət kanalına soft thresholding tətbiq edilir.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-29-DRSN-az/DRSN_az_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

Bu alt-şəbəkədə, ilk növbədə giriş xüsusiyyət xəritəsinin (feature map) bütün xüsusiyyətlərinin mütləq qiyməti hesablanır. Sonra qlobal orta pooling (global average pooling) və ortalama əməliyyatı vasitəsilə bir xüsusiyyət əldə edilir, bunu A kimi qeyd edək. Digər bir yolda isə, qlobal orta pooling-dən sonra alınan xüsusiyyət xəritəsi kiçik bir tam əlaqəli şəbəkəyə daxil edilir. Bu şəbəkənin son layı Sigmoid funksiyasıdır və çıxışı 0 ilə 1 arasına normallaşdıraraq bir əmsal əldə edir, bunu da α kimi qeyd edək. Yekun hüdud qiyməti α × A kimi ifadə edilə bilər. Beləliklə, hüdud qiyməti = (0 ilə 1 arasında bir ədəd) × (xüsusiyyət xəritəsinin mütləq qiymətlərinin ortalaması). **Bu üsul hüdudun həm müsbət olmasını, həm də çox böyük olmamasını təmin edir.**

**Üstəlik, fərqli nümunələr üçün fərqli hüdudlar yaranır. Buna görə də, bu prosesi müəyyən mənada xüsusi bir diqqət mexanizmi kimi başa düşmək olar: cari tapşırıqla əlaqəsi olmayan xüsusiyyətlər diqqətə alınır, iki konvolyusiya layı vasitəsilə bu xüsusiyyətlər 0-a yaxın qiymətlərə çevrilir və soft thresholding vasitəsilə tamamilə sıfırlanır; və ya əksinə, tapşırıqla əlaqəli xüsusiyyətlər diqqətə alınır, 0-dan uzaq qiymətlərə çevrilir və saxlanılır.**

Sonda, müəyyən sayda belə əsas modulları, eləcə də konvolyusiya laylarını, Batch Normalization, aktivasiya funksiyalarını, qlobal orta pooling və tam əlaqəli çıxış laylarını (FC output layer) üst-üstə yığmaqla tam Deep Residual Shrinkage Network əldə edilir.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-29-DRSN-az/DRSN_az_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Universallıq
Deep Residual Shrinkage Network, əslində, universal bir xüsusiyyət öyrənmə (feature learning) metodudur. Çünki bir çox tapşırıqlarda nümunələrin tərkibində az və ya çox dərəcədə səs-küy, eləcə də aidiyyəti olmayan məlumatlar olur. Bu səs-küy və lazımsız məlumatlar öyrənmə effektinə mənfi təsir göstərə bilər. Məsələn:

Şəkillərin təsnifatı zamanı, əgər şəkildə eyni vaxtda bir çox başqa obyektlər varsa, bu obyektlər "səs-küy" kimi başa düşülə bilər. Deep Residual Shrinkage Network diqqət mexanizmi vasitəsilə bu "səs-küyü" aşkar edə bilər, sonra isə soft thresholding köməyi ilə onlara uyğun xüsusiyyətləri sıfıra çevirərək təsnifatın dəqiqliyini artıra bilər.

Səsin tanınması zamanı, səs-küylü mühitlərdə (məsələn, yol kənarında və ya zavod sexində danışarkən) Deep Residual Shrinkage Network tanımanın dəqiqliyini artıra bilər və ya ən azından dəqiqliyi artırmaq üçün yeni bir yanaşma təqdim edə bilər.

## İstinadlar (Reference)

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

[https://ieeexplore.ieee.org/document/8850096](https://ieeexplore.ieee.org/document/8850096)

## BibTeX
```bibtex
@article{Zhao2020,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}
```

## Təsir dairəsi

Bu məqalə Google Scholar-da 1400-dən çox istinad toplayıb.

Natamam statistikaya görə, Deep Residual Shrinkage Network 1000-dən çox elmi məqalədə birbaşa tətbiq edilib və ya təkmilləşdirilərək mexanika, energetika, kompüter görməsi (computer vision), tibb, səs emalı, mətn analizi, radar, məsafədən zondlama və digər bir çox sahələrdə istifadə olunub.
