---
layout: post
title: "Deep Residual Shrinkage Network: Highly Noisy Data-на лерина Artificial Intelligence Method"
subtitle: "An Artificial Intelligence Method for Highly Noisy Data"
date: 2025-12-14
tags: [Deep Learning, AI]
mathjax: true
description: "Deep Residual Shrinkage Network (DRSN) гергга аьлча Deep Residual Network-ан то йина variant ю. Ма-дарра аьлча, Deep Residual Shrinkage Network-ас вовшахтуху Deep Residual Network, attention mechanisms, ткъа soft thresholding функцияш."
---

**Deep Residual Shrinkage Network (DRSN) гергга аьлча Deep Residual Network-ан то йина variant ю. Ма-дарра аьлча, Deep Residual Shrinkage Network-ас вовшахтуху Deep Residual Network, attention mechanisms, ткъа soft thresholding функцияш.**

**Вайга Deep Residual Shrinkage Network болх баран принцип иштта хетало. Хьалха, network-ас attention mechanisms юлайош, маьӏна доцу (unimportant) features къасто. Ткъа, network-ас soft thresholding функцияш юлайош уьш маьӏна доцу features zero-е дерзош. Мелхо а, network-ас маьӏна долу (important) features билгал йоккху, ткъа уьш лацуш. Оцу процесс-ас deep neural network-ан ницкъ тӏе-туху. Оцу процесс-ас гӏо до network-ана noise йолчу signal-аш чуьра пайден features ара яккха.**

## 1. Research Motivation (Таллам баран бахьана)

**Хьалха, algorithm-ас samples classify еш, noise хилар мацццел а хуьлу. Оцу noise-ан масала шуна ю Gaussian noise, pink noise, ткъа Laplacian noise.** Гергга аьлча, *samples* чуьра келахь хуьлу оцу *classification task*-ана оьшуш доцу информация. Иза оьшуш доцу информация вайна *noise* санна лара мегар ду. Оцу *noise*-ас *classification performance* охьа яккха мега. (*Soft thresholding* дукха а *signal denoising* algorithm-ашкахь мехала гӏулч ю.)

Масала, новкъа йистехь къаьмал дас. *Audio* чуьра хила мега *car horns* (машенан зӏенарш) ва *wheels* (чургаш). Вай оцу signal-аш тӏехь *speech recognition* я мега. *Background sounds* (тӏехьара азнаш) мацццел а ӏаткъам бо result-ашна. *Deep learning* агӏор хьажча, *deep neural network*-ас уьш *features* — *horns* ва *wheels* — дӏаяккха еза. И дӏаяккхаро гӏо до уьш *features* вай *speech recognition* result-ашна новкъалла цаяйта.

**Шозлагӏ, noise-ан йозалла (amount) хӏора sample-ан башха хуьлу. Иза хийцалар (variation) цхьана dataset чуьра а хуьлу.** (Хӏара хийцалар *attention mechanisms* тӏе тера ду. Масала, *image dataset* схьалаца. *Target object* (лерина хӏума) хӏора *image* тӏехь башха меттигахь хила мега. *Attention mechanisms*-ас хӏора *image* тӏехь *target object*-ан меттиг билгал яккха мега.)

Масала, вай *cat-and-dog classifier* *train* еш, "dog" label йолина 5 *image* ю. *Image 1* чуьра хила мега жӏаьла (dog) ва чхьаьри (mouse). *Image 2* чуьра — жӏаьла ва гӏаз (goose). *Image 3* чуьра — жӏаьла ва котам (chicken). *Image 4* чуьра — жӏаьла ва вир (donkey). *Image 5* чуьра — жӏаьла ва бад (duck). *Training* еш, уьш *irrelevant objects* (оьшуш доцу хӏумаш) новкъалла йийр ю *classifier*-ана. Уьш *objects* ю: *mice, geese, chickens, donkeys, ducks*. Хӏара новкъаллос *classification accuracy* охьа йоккху. Нагахь вайга уьш *irrelevant objects* билгал яккха лахь. Ткъа, вайга уьш *objects*-ашна догӏу *features* дӏаяккхалур ю. Оцу некъаца, вайга *cat-and-dog classifier*-ан *accuracy* лакха яккхалур ю.

## 2. Soft Thresholding

**Soft thresholding дукха а signal denoising algorithm-ашкахь мехала гӏулч ю. Algorithm-ас features дӏайоккху, нагахь оцу features-ан absolute values цхьана threshold-ал кӏезига елахь. Algorithm-ас features zero агӏор shrink еш (тӏе озош), нагахь оцу features-ан absolute values оцу threshold-ал яккха елахь.** Researcher-ашна *soft thresholding* гӏоьнца реализация ян мегар ду хӏокху формулаца:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

*Soft thresholding output*-ан *derivative*, *input*-ана лерина ю:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

Лакха йолчу формула-с гойту, *soft thresholding*-ан *derivative* я 1 ю, я 0 ю. Хӏара башхалла *ReLU activation function*-аца тера ю. Цун дела, *soft thresholding*-ас *deep learning* algorithm-ашкахь *gradient vanishing* ва *gradient exploding* risk охьа йоккху.

**Soft thresholding function чуьра, threshold хӏоттош ши шарт (condition) кхочуш хила еза. Хьалха, threshold positive number хила еза. Шозлагӏ, threshold input signal-ан maximum value-ал яккха хила йиш яц. Иштта яцахь, output ерриг zero хир ю.**

**Тӏе, threshold-ас кхоалгӏа шарт кхочуш елахь гӏолехь ду. Хӏора sample-ан шен-шен independent threshold хила еза, оцу sample-ан noise content тӏе хьожуш.**

Бахьана ду, *noise content* дукха а *samples* чуьра башха хилар. Масала, *Sample A* чуьра *noise* кӏезига хила мега, ткъа *Sample B* чуьра *noise* алкасам хила мега цхьана *dataset* чуьра. Оцу меттигахь, *Sample A*-с кӏезига *threshold* юлайор ю *soft thresholding* еш. *Sample B*-с яккха *threshold* юлайор ю. *Deep neural networks* чуьра, уьш *features* ва *thresholds* шайн *explicit physical definitions* дӏа яйъа мега. Делахь а, *basic logic* цхьа тера юьсу. Хьетош аьлча, хӏора *sample*-ан *independent threshold* хила еза. Билгал йолчу *noise content*-ас и *threshold* къаста йо.

## 3. Attention Mechanism

Researcher-ашна *computer vision* сферагахь *attention mechanisms* хета атта ду. Дийнатийн (animals) *visual systems* гӏо до *targets* къасто, массо area чехка *scan* еш. Тӏаьхьара, *visual systems*-ас *attention* тӏе-ягӏо *target object*-ана. Оцу *action*-ас гӏо до *systems*-ана алкасам *details* ара яккха. Цхьана хенахь, *systems*-ас *irrelevant information* охьа тӏеӏада. Кӏоргалла хьажа, дехар до *attention mechanisms* литератур тӏе.

*Squeeze-and-Excitation Network* (SENet) цхьа керла *deep learning method* ю, *attention mechanisms* юлайош йола. Башха *samples* чуьра, башха *feature channels* башха гӏо до *classification task*-ана. SENet-ас жима *sub-network* юлайош *Learn a set of weights* (йозалла) лаца. Ткъа, SENet-ас уьш *weights* multiply йо (эшар йо) *Apply weighting to each feature channel* принципаца. Оцу *operation*-ас хӏора *channel*-ан *features magnitude* adjust йо. Вай и процесс лара мегар ду башха *attention levels* башха *feature channels*-ана тӏе-ягӏор санна.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

Оцу некъаца, хӏора *sample*-ан *independent set of weights* ю. Хьетош аьлча, хӏора ши *samples*-ан *weights* башха ю. SENet чуьра, *weights* яккхар некъ иштта бу: "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function."

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding with Deep Attention Mechanism

Deep Residual Shrinkage Network-ас SENet sub-network структура юлайош. Network-ас и структура юлайош soft thresholding deep attention mechanism чуьра реализация ян. Sub-network-ас (red box чуьра гойтина) Learn a set of thresholds (thresholds лаца). Ткъа, network-ас уьш thresholds юлайош soft thresholding йо хӏора feature channel-ана.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

Оцу *sub-network* чуьра, system-ас хьалха массо *features*-ан *absolute values* лара *input feature map* чуьра. Ткъа, system-ас *global average pooling* ва *averaging* йо, цхьа *feature* яккха, *A* аьлла билгал йина йола. Вуьху *Identity path* (некъа) чуьра, system-ас *feature map* input йо жима *fully connected network* чуьра *global average pooling* йина яьллача. Оцу *fully connected network*-ас *Sigmoid function* юлайош *final layer* санна. Оцу *function*-ас *output normalize* йо 0 ва 1 юкъехь. Оцу процесс-ас *coefficient* лаца, *α* аьлла билгал йина йола. Вайга *final threshold* *α × A* санна яз я лур ю. Цун дела, *threshold* ши number-ан product (жамӏ) ю. Цхьа number 0 ва 1 юкъехь ю. Шозлагӏ number *feature map absolute values*-ан *average* ю. **Оцу method-ас threshold positive хилар кхаьмболу. Оцу method-ас threshold тӏуга яккха цахилар а кхаьмболу.**

**Тӏе, башха samples-ас башха thresholds лаца. Цун дела, вай хӏара method specialized attention mechanism санна лара мегар ду. Mechanism-ас identify йо features, current task-ана irrelevant йола. Mechanism-ас transform йо уьш features 0-на герга values-е ши convolutional layers гӏоьнца. Ткъа, mechanism-ас уьш features set to zero (zero-е дерзош) soft thresholding юлайош. Я, mechanism-ас identify йо features, current task-ана relevant йола. Mechanism-ас transform йо уьш features 0-на генна values-е ши convolutional layers гӏоьнца. Тӏаьхьара, mechanism-ас уьш features лацуш (preserves).**

Тӏаьхьара, вай *Stack many basic modules* (дукха basic modules тӏеттӏа догӏу). Вай *convolutional layers*, *batch normalization*, *activation functions*, *global average pooling*, ва *fully connected output layers* а тӏе-туху. Оцу процесс-ас ерриг *Deep Residual Shrinkage Network* construct йо.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generalization Capability

Deep Residual Shrinkage Network *feature learning*-ана лерина *general method* ю. Бахьана ду, *samples* чуьра дукха а *noise* хилар дукха *feature learning tasks* чуьра. *Samples* чуьра *irrelevant information* а хуьлу. Оцу *noise*-ас ва *irrelevant information*-ас *feature learning* performance тӏе ӏаткъа мега. Масала:

*Image classification* схьалаца. Цхьа *image* чуьра дукха а кхин *objects* хила мега. Вайга уьш *objects* "noise" санна хета лур ду. *Deep Residual Shrinkage Network*-ас *attention mechanism* юлайо. *Network*-ас и "noise" notice йо (тергам бо). Ткъа, *network*-ас *soft thresholding* юлайош уьш "noise"-на догӏу *features* zero-е дерзош. Оцу *action*-ас *image classification accuracy* лакха яккха мега.

*Speech recognition* схьалаца. Билгалла, *noisy environments* чуьра, масала новкъа йистехь я factory workshop чуьра къаьмал дас. *Deep Residual Shrinkage Network*-ас *speech recognition accuracy* лакха яккха мега. Я, мукънехь а, *network*-ас *methodology* лаца. Оцу *methodology*-с *speech recognition accuracy* лакха яккха ницкъ бу.

## 6. Academic Impact

Хӏокху paper-ана Google Scholar тӏехь 1400 сов citations (тӏе-яцийнарш) хилла.

Incomplete statistics агӏор хьажча, researcher-аш Deep Residual Shrinkage Network (DRSN) юлайина 1000 сов publications/studies чуьра. Хӏара applications (юлаярш) дукха а fields чуьра ю. Уьш fields ю: mechanical engineering, electrical power, vision, healthcare, speech, text, radar, ва remote sensing.

## Reference (Хьастлаш)

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

[https://ieeexplore.ieee.org/document/8850096](https://ieeexplore.ieee.org/document/8850096)

## BibTeX
```bibtex
@article{Zhao2020,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}
```
