---
layout: post
title: "Deep Residual Shrinkage Network: Иу Artificial Intelligence метод, кæцы пайда кæны тынг бирæ Noise кæм ис, ахæм Data-имæ кусынæн"
subtitle: "An Artificial Intelligence Method for Highly Noisy Data"
date: 2025-12-14
tags: [Deep Learning, AI]
mathjax: true
---

**Deep Residual Shrinkage Network у Deep Residual Network-ы хуыздæргонд вариант. Сæйраг мадзал уый у, æмæ Deep Residual Shrinkage Network иумæ æмбырд кæны Deep Residual Network, Attention mechanism, æмæ Soft thresholding функцитæ.**

**Махæн нæ бон у Deep Residual Shrinkage Network куыд кусы, уый афтæ бамбарын. Фыццаг, Network пайда кæны Attention mechanism-æй, цæмæй ахсджиаг чи нæу, уыцы feature-тæ сбæрæг кæна (identify unimportant features). Стæй, Network пайда кæны Soft thresholding функцитæй, цæмæй уыцы feature-тæ "zero" фестæт (set to zero). Иннæрдыгæй та, Network сбæрæг кæны ахсджиаг feature-тæ æмæ сæ бахъахъхъæны. Ацы процесс фæтыхджындæр кæны Deep Neural Network-ы арæхстдзинад. Ацы процесс Network-æн æххуыс кæны, цæмæй Noise кæм ис, ахæм Signal-тæй пайдаджын feature-тæ рахицæн кæна.**

## 1. Иртасæны мотиваци (Research Motivation)

**Фыццаг дæр, Algorithm sample-тæ куы фæхицæн кæны (classifies), уæд Noise алы хатт дæр вæййы, уымæй гæнæн нæй. Ахæм Noise-ы дæнцæгтæ сты Gaussian noise, Pink noise, æмæ Laplacian noise.** Ноджы дарддæр куы зæгъæм, уæд Sample-ты мидæг арæх вæййы ахæм информаци, кæцы нырыккон classification task-æн пайда нæу. Махæн нæ бон у ацы "irrelevant" (пайда кæмæн нæй) информаци банымайын куыд Noise. Ацы Noise-ы тыххæй classification performance гæнæн ис фæкъаддæр уа. (Soft thresholding у тынг ахсджиаг къахдзæф бирæ signal denoising algorithm-ты мидæг).

Зæгъæм, машинæты фæндагыл искæимæ ныхас кæныс. Audio signal-ы мидæг уыдзæн машинæты гæрæхтæ æмæ цалхыты хъæр. Махæн нæ бон у ацы signal-тыл Speech recognition скæнын. Фæлæ ам background sound-тæ нæ result-тæн, æвæццæгæн, къуылымпы кæндзысты. Deep learning цæстæнгасæй, Deep Neural Network хъуамæ аиуварс кæна уыцы машинæты гæрæхтæ æмæ цалхыты хъæр, цæмæй уыцы feature-тæ ма фæзыной Speech recognition-ы фæстиуæгыл.

**Дыккаг та, Noise цас ис, уый алы Sample-ы мидæг вæййы алыхуызон. Ацы хицæндзинад вæййы суанг иу Dataset-ы мидæг дæр.** (Ацы хицæндзинад Attention mechanism-ы хуызæн у. Зæгъæм, райсæм иу Image dataset. Target object кæм ис, уыцы бынат алы Image-ы мидæг уыдзæн алыхуызон. Attention mechanism-ы бон у "focus" скæнын (йæ хъус аздахын) target object кæм ис, уыцы конкрет бынатмæ алы Image-ы мидæг).

Зæгъæм, мах train кæнæм иу "cat-and-dog classifier" æмæ нæм ис 5 нывы (image), кæдоны label у "dog" (куыдз).
*   Image 1-ы мидæг ис куыдз æмæ мыст.
*   Image 2-ы мидæг ис куыдз æмæ хъаз.
*   Image 3-ы мидæг ис куыдз æмæ карк.
*   Image 4-ы мидæг ис куыдз æмæ хæрæг.
*   Image 5-ы мидæг ис куыдз æмæ бабыз.

Training-ы рæстæг, ацы "irrelevant" (пайда кæмæн нæй) объекттæ classifier-æн къуылымпы кæндзысты. Ацы объекттæ сты мыст, хъаз, карк, хæрæг æмæ бабыз. Ацы къуылымпыдзинады тыххæй classification accuracy фæкъаддæр уыдзæн. Кæд мах сбæрæг кæнæм ацы пайда кæмæн нæй, уыцы объектты, уæд нæ бон у аиуварс кæнын (eliminate) уыцы объектты feature-тæ. Афтæмæй, нæ бон у фæхуыздæр кæнын "cat-and-dog classifier"-ы accuracy.

## 2. Soft Thresholding

**Soft thresholding у сæйраг къахдзæф бирæ signal denoising algorithm-ты. Кæд feature-ы absolute value иу бæрæг Threshold-æй гыццылдæр у, уæд Algorithm уыцы feature-тæ "eliminate" кæны (аиуварс кæны). Кæд feature-ы absolute value уыцы Threshold-æй стырдæр у, уæд Algorithm уыцы feature-тæ кæны "shrink" (фæгыццылдæр кæны) zero-йы ардæм.** Иртасджытæ Soft thresholding арæзынц ацы formulæ-йæ:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

Soft thresholding output-ы derivative, input-мæ гæсгæ, у ахæм:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

Уæлдæр цы formulæ ис, уый нын æвдисы, æмæ Soft thresholding-ы derivative у кæнæ 1, кæнæ 0. Ай у ReLU activation function-ы хуызæн. Уый тыххæй Soft thresholding-ы бон у фæкъаддæр кæнын gradient vanishing æмæ gradient exploding-ы риск deep learning algorithm-ты мидæг.

**Soft thresholding function-ы мидæг, Threshold хъуамæ сæххæст кæна дыууæ уавæры. Фыццаг, Threshold хъуамæ уа positive number (positive нымæц). Дыккаг, Threshold input signal-ы maximum value-йæ стырдæр уæвын нæ хъуамæ. Кæннод, output иууылдæр уыдзæн zero.**

**Ноджы ма, хуыздæр уыдзæн, Threshold куы сæххæст кæна æртыккаг уавæр дæр. Алы Sample-æн дæр хъуамæ уа йæхи сæрмагонд Threshold, уыцы Sample-ы мидæг цас Noise ис, уымæ гæсгæ.**

Уымæн æмæ Noise цас ис, уый арæх вæййы алыхуызон алы Sample-ы дæр. Зæгъæм, иу Dataset-ы мидæг Sample A-йы мидæг Noise гæнæн ис гыццыл уа, Sample B-йы мидæг та Noise бирæ уа. Ахæм уавæры, Soft thresholding куы кæнæм, уæд Sample A хъуамæ пайда кæна гыццылдæр Threshold-æй. Sample B та хъуамæ пайда кæна стырдæр Threshold-æй. Deep Neural Network-ты мидæг, кæд ацы feature-тæ æмæ threshold-тæн нæй бæрæг physical definition, уæддæр сæ бындурон logic (логикæ) баззайы иухуызон. Ома, алы Sample-æн дæр хъуамæ уа independent (хибар) threshold. Цас Noise дзы ис, уый бæрæг кæны ацы threshold.

## 3. Attention Mechanism

Иртасджытæн тынг æнцон у Attention mechanism бамбарын Computer Vision-ы къабазы. Цæрæгойты visual system-тæн сæ бон у target (нысан) рахицæн кæнын, тагъд "scan" куы скæнынц æппæт фæзуатыл, уæд. Стæй, visual system-тæ сæ хъус (attention) аздахынц target object-мæ. Ацы архайд system-тæн дæтты фадат, цæмæй фылдæр detail-тæ райсой. Уыцы иу рæстæг, system "suppress" кæны (ныкъуылын кæны) irrelevant information. Кæд у фылдæр базонын фæнды, уæд дæ хорзæхæй, бакæс Attention mechanism-ы тыххæй literaturæ.

Squeeze-and-Excitation Network (SENet) у иу ногдæр Deep learning метод, кæцы пайда кæны Attention mechanism-æй. Алыхуызон Sample-ты мидæг, classification task-æн алы Feature channel-тæ æххуыс кæнынц алыхуызон. SENet пайда кæны иу гыццыл Sub-network-æй, цæмæй Weight-ты иу set райса. Стæй, SENet ацы Weight-тæ фæбар кæны (multiplies) алы channel-ы feature-тимæ. Ацы операци ивы feature-ты бæрц алы channel-ы дæр. Махæн нæ бон у ацы процесс бамбарын афтæ: мах "apply" кæнæм (æвæрæм) алыхуызон бæрцы Attention алы feature channel-ыл дæр.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

Ацы методы, алы Sample-æн дæр ис йæхи independent set of weights. Ома, дыууæ алыхуызон sample-æн сæ weight-тæ уыдзысты алыхуызон. SENet-ы мидæг, weight-тæ райсыны фæндаг у ахæм: "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function".

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding with Deep Attention Mechanism

Deep Residual Shrinkage Network пайда кæны SENet sub-network-ы структурæйæ. Network пайда кæны ацы структурæйæ, цæмæй сæххæст кæна Soft thresholding иу Deep Attention mechanism-ы бын. Sub-network (кæцы Red box-ы мидæг ис) ахуыр кæны (learns) иу set of thresholds. Стæй, Network пайда кæны ацы threshold-тæй, цæмæй Soft thresholding скæна алы feature channel-æн дæр.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

Ацы Sub-network-ы мидæг, System фыццаг нымайы feature map-ы æппæт feature-ты absolute value-тæ. Стæй, system кæны Global Average Pooling, цæмæй райса иу feature, кæй хонæм A. Иннæ "path"-ы (фæндагыл), system feature map арвиты иу гыццыл Fully Connected Network-мæ, Global Average Pooling-ы фæстæ. Ацы Fully Connected Network пайда кæны Sigmoid function-æй куыд фæстаг layer. Ацы function output кæны normalize 0 æмæ 1-ы ’хсæн. Ацы процесс дæтты иу coefficient, кæй хонæм α. Махæн нæ бон у фæстаг Threshold банымайын куыд α × A. Уæдæ, Threshold у дыууæ нымæцы product (фæстиуæг). Иу нымæц у 0 æмæ 1-ы ’хсæн. Иннæ нымæц у feature map-ы absolute value-ты average. **Ацы метод "ensure" кæны (фидарæй зæгъы), æмæ Threshold у positive. Ацы метод ма ноджы "ensure" кæны, æмæ Threshold тынг стыр нæ уыдзæн.**

**Ноджы ма, алыхуызон Sample-тæ дæттынц алыхуызон Threshold-тæ. Уымæ гæсгæ, махæн нæ бон у ацы метод бамбарын куыд сæрмагонд Attention mechanism. Ацы Mechanism сбæрæг кæны, нырыккон task-æн irrelevant (пайда чи нæу) чи у, уыцы feature-тæ. Mechanism ацы feature-тæ ивы 0-мæ хæстæг value-тæм дыууæ Convolutional layer-ы фæрцы. Стæй, mechanism ацы feature-тæ "set" кæны (æвæры) zero-йыл, Soft thresholding-æй пайда кæнгæйæ. Кæнæ та, Mechanism сбæрæг кæны, нырыккон task-æн relevant (пайда чи у) чи у, уыцы feature-тæ. Mechanism ацы feature-тæ ивы 0-йæ дард чи у, ахæм value-тæм дыууæ Convolutional layer-ы фæрцы. Фæстагмæ, Mechanism бахъахъхъæны (preserves) ацы feature-тæ.**

Кæронбæттæны, мах "stack" кæнæм (æвæрæм сæ кæрæдзийы сæрыл) цалдæр Basic module. Мах ма бавæрæм Convolutional layer-тæ, Batch Normalization, Activation function-тæ, Global Average Pooling, æмæ Fully Connected Output Layer. Ацы процесс арæзы æххæст Deep Residual Shrinkage Network.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generalization Capability (Уæрæх кæныны арæхстдзинад)

Deep Residual Shrinkage Network у Feature learning-æн иу "general" (алкæмæн дæр пайда) метод. Уымæн æмæ Sample-ты мидæг арæх вæййы Noise бирæ Feature learning task-ты. Sample-ты ма вæййы Irrelevant information. Ацы Noise æмæ Irrelevant information гæнæн ис фæагрег кæной Feature learning-ы performance-ыл. Зæгъæм:

Бакæсæм Image classification-мæ. Иу Image-ы мидæг гæнæн ис æмæ уа бирæ æндæр объекттæ. Махæн нæ бон у ацы объекттæ банымайын куыд "Noise". Deep Residual Shrinkage Network-ы бон, æвæццæгæн, уыдзæн пайда кæнын Attention mechanism-æй. Network фæфиппайы ацы "Noise". Стæй, Network пайда кæны Soft thresholding-æй, цæмæй ацы "Noise"-æн цы feature-тæ ис, уыдон zero фестæт. Ацы архайд, æвæццæгæн, фæхуыздæр кæндзæн Image classification accuracy.

Бакæсæм Speech recognition-мæ. Сæрмагондæй та, Noise кæм ис, ахæм уавæртæм, зæгъæм ныхас кæнын машинæты фæндагыл кæнæ заводты цехы мидæг. Deep Residual Shrinkage Network, æвæццæгæн, фæхуыздæр кæндзæн Speech recognition accuracy. Кæнæ æппынкъаддæр, Network дæтты Methodology. Ацы Methodology-йы бон у фæхуыздæр кæнын Speech recognition accuracy.

## Academic Impact (Академион ндæвдад)

Ацы статьяйæн Google Scholar-ы ис 1400 citation-æй фылдæр.

Æххæст статистикæ нæу, фæлæ иртасджытæ Deep Residual Shrinkage Network (DRSN)-æй спайда кодтой 1000 publication/study-йæ фылдæры. Ацы "application"-тæ (спайда кæныны цаутæ) æххæст кæнынц тынг уæрæх къабæзтæ. Ацы къабæзтæ сты Mechanical engineering, Electrical power, Vision, Healthcare, Speech, Text, Radar, æмæ Remote sensing.

## Reference

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

[https://ieeexplore.ieee.org/document/8850096](https://ieeexplore.ieee.org/document/8850096)

## BibTeX
```bibtex
@article{Zhao2020,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}
```
