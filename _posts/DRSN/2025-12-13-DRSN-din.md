---
layout: post
title: "Deep Residual Shrinkage Network: Kuɛr de Artificial Intelligence tënë Data cï Noise thɔ̈ŋ apɛi"
subtitle: "An Artificial Intelligence Method for Highly Noisy Data"
date: 2025-12-13
tags: [Deep Learning, AI]
mathjax: true
---

**Kënë cɔl Deep Residual Shrinkage Network ee kuɛr yam cï looi bï Deep Residual Network cɔl apath. Të tïŋ wok ye thïn, Deep Residual Shrinkage Network a mat Deep Residual Network, attention mechanisms, ku soft thresholding functions bïk ya tök.**

**Wok a lëu bïk kuɛr ye Deep Residual Shrinkage Network luui thïn deetic ë kuɛr kënë. Tueŋ, network ee attention mechanisms luɔ̈ɔ̈i bï features cïï thiekiic yök. Ku ka, network ee soft thresholding functions luɔ̈ɔ̈i bï features kɛ̈ cïï thiekiic nyaai (bïk ya zero). Ku ë kuɛr dɛ̈t, network ee features thiekiic yök ku gɛl ke. Kuɛr kënë ee riɛl de deep neural network cɔl adït. Kënë ee network kony bï useful features yök tënë signals cï noise nɔŋ ic.**

## 1. Kë ye kɔc cɔl aa luɔ̈i kënë (Research Motivation)

**Tueŋ, noise a cïï lëu bïk paal të ye algorithm samples wääc. Akɔ̈ɔ̈n de noise kɛ̈ aa mat Gaussian noise, pink noise, ku Laplacian noise.** Ku të luel wok wɛt ë path, **samples** a kɔ̈k nɔŋ ic wɛ̈t cïï mat kekë luɔi de **classification** kënë. Wok a lëu bïk wɛ̈t cïï mat kënë deetic ke ye **noise**. Kënë cɔl **noise** a lëu bï luɔi de **classification** cɔl arac. (**Soft thresholding** ee kuɛr dït apɛi tënë **algorithms** juëc ke **signal denoising**.)

Tak akɔ̈ɔ̈n kënë: të nɔŋ jam ë kuɛr gɛ̈l. Wɛ̈t ë jam kënë (audio) a lëu bï rol de tɔ̈ŋ de makiina ku rol de thiɔ̈k de makiina nɔŋ ic. Wok a lëu bïk **speech recognition** looi tënë **signals** kɛ̈. Rol tɔ̈ lɔɔŋ a bï luɔi kënë rac. Të tïŋ wok ye në kuɛr de **deep learning**, **deep neural network** a rïïl bï **features** ye nyuɔɔth rol de tɔ̈ŋ ku thiɔ̈k nyaai. Luɔi de nyaai kënë ee **features** kɛ̈ gɛ̈l bïk cïï **speech recognition** rac.

**Ku kë de rou, adït de noise ee wääc tënë samples. Wääc kënë a looi rot aya në dataset tök ic.** (Wääc kënë a thöŋ thiin kekë **attention mechanisms**. Tak **image dataset** tök. Të tɔ̈ kënë ye wïc (target object) thïn a lëu bï wääc në **images** yiic. **Attention mechanisms** a lëu bï tïŋ të tɔ̈ **target object** thïn në **image** tök ic.)

Tak akɔ̈ɔ̈n kënë: na wïc yïn ba **classifier** de **cat-and-dog** (aŋau ku jɔ̈k) piɔ̈ɔ̈c kekë **images** kadhiëc nɔŋ **label** ke ye "**dog**".
*   **Image 1** a lëu bï **dog** (jɔ̈k) ku **mouse** (riɔ̈p) nɔŋ ic.
*   **Image 2** a lëu bï **dog** ku **goose** (amiwök) nɔŋ ic.
*   **Image 3** a lëu bï **dog** ku **chicken** (ajith) nɔŋ ic.
*   **Image 4** a lëu bï **dog** ku **donkey** (akaja) nɔŋ ic.
*   **Image 5** a lëu bï **dog** ku **duck** (atuot) nɔŋ ic.
Në thää piɔ̈ɔ̈c (training), kä cïï thiekiic aa bï **classifier** rac. Kä kɛ̈ aa mat **mice**, **geese**, **chickens**, **donkeys**, ku **ducks**. Kënë a bï **classification accuracy** cɔl akuɔ̈r piny. Na lëu wok bïk kä cïï thiekiic kɛ̈ yök. Ka wok a lëu bïk **features** ye nyuɔɔth kä kɛ̈ nyaai. Në kuɛr kënë, wok a lëu bïk **accuracy** de **cat-and-dog classifier** cɔl adït.

## 2. Soft Thresholding

**Soft thresholding ee kuɛr thiekiic apɛi tënë signal denoising algorithms juëc. Algorithm ee features nyaai na kënë cɔl absolute value de features akoor tënë kënë cɔl threshold. Algorithm ee features cɔl a lɔ thiɔ̈k kekë zero na kënë cɔl absolute value de features adït tënë threshold kënë.** Kɔc piɔ̈ɔ̈c (researchers) a lëu bïk **soft thresholding** looi ë kuɛr de yï kënë:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

**Derivative** de **soft thresholding output** tënë **input** ee:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

Yï tɔ̈ nhial a nyuɔɔth lɔn **derivative** de **soft thresholding** ee 1 wala 0. Kënë a thöŋ kekë **ReLU activation function**. Rin kënë, **soft thresholding** a lëu bï **gradient vanishing** ku **gradient exploding** gɛ̈l në **deep learning algorithms** yiic.

**Në soft thresholding function ic, të ye threshold tɔ̈ɔ̈u thïn a rïïl bï kä kerou looi. Tueŋ, threshold a rïïl bï ya positive number. Kë de rou, threshold a cïï lëu bï dït tënë maximum value de input signal. Tëdë, output abï ya zero ëbɛ̈n.**

**Ku aya, threshold a ŋuɛ̈n bï kë de diäk looi. Sample tök ku sample tök a rïïl bï threshold de nɔŋ, cök tɛ̈ nɔŋ noise thïn.**

Kënë a looi rot rin **noise** a lëu bï wääc në **samples** yiic. Akɔ̈ɔ̈n, **Sample A** a lëu bï **noise** koor nɔŋ ic ku **Sample B** a nɔŋ **noise** dït në **dataset** tök ic. Në kënë ic, **Sample A** a rïïl bï **threshold** koor luɔ̈ɔ̈i në thää **soft thresholding**. **Sample B** a rïïl bï **threshold** dït luɔ̈ɔ̈i. **Features** kɛ̈ ku **thresholds** a cïï nɔŋ maana path në **deep neural networks** yiic. Lakin, kuɛr luɔi tɔ̈ piny a thöŋ. Wɛ̈t ë luel, **sample** tök ku **sample** tök a rïïl bï **threshold** de nɔŋ. Adït de **noise** yen ë **threshold** kënë looi.

## 3. Attention Mechanism

Kɔc piɔ̈ɔ̈c a lëu bïk **attention mechanisms** deetic apath në **computer vision**. Tïïŋ de läi (visual systems of animals) a lëu bï kä wääc yök ë rin ye kek piny tïŋ ajuɛ̈r. Ku ka, tïïŋ kënë ee **attention** de tɔ̈ɔ̈u në kënë wïc yök. Luɔi kënë ee **systems** kony bïk kä juëc yök. Në thää tök, **systems** ee wɛ̈t cïï thiekiic gɛ̈l. Wïc wɛ̈t juëc, tïŋ wɛ̈t cï gɔ̈t në **attention mechanisms**.

**Squeeze-and-Excitation Network (SENet)** ee kuɛr yam de **deep learning** cï **attention mechanisms** luɔ̈ɔ̈i. Në **samples** wääc yiic, **feature channels** wääc aa luui ë kuɛr wääc tënë **classification task**. **SENet** ee **sub-network** thiin luɔ̈ɔ̈i bï **set of weights** (kä ye thiem) yök. Ku ka, **SENet** ee **weights** kɛ̈ biɔ̈k (multiply) kekë **features** ke **channels** kɛ̈. Luɔi kënë ee adït de **features** tɔ̈ **channel** ic looi. Wok a lëu bïk kënë tïŋ ke ye luɔi de **attention** wääc tënë **feature channels** wääc.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

Në kuɛr kënë, **sample** tök a nɔŋ **set of weights** de. Wɛ̈t ë luel, **weights** ke **samples** kerou a wääc. Në **SENet** ic, kuɛr ye **weights** yök thïn ee "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function."

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding with Deep Attention Mechanism

**Deep Residual Shrinkage Network** ee luɔi de **SENet sub-network** luɔ̈ɔ̈i. **Network** ee luɔi kënë luɔ̈ɔ̈i bï **soft thresholding** looi në **deep attention mechanism** kɔ̈u. **Sub-network** (tɔ̈ **box** many thïn) a lëu bï **Learn a set of thresholds** (bï thresholds juëc piɔ̈ɔ̈c). Ku ka, **network** ee **soft thresholding** looi tënë **feature channel** tök ku **channel** tök ke luui **thresholds** kɛ̈.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

Në **sub-network** kënë ic, **system** ee **absolute values** ke **features** kedhie tɔ̈ **input feature map** ic kuen. Ku ka, **system** ee **global average pooling** ku **averaging** looi bï **feature** yök, cï gɔ̈t keye A. Në kuɛr dɛ̈t, **system** ee **feature map** tɔ̈ɔ̈u në **fully connected network** thiin ic bï **global average pooling** cɔl lɔ. **Fully connected network** kënë ee **Sigmoid function** luɔ̈ɔ̈i keye **layer** de ciëën. **Function** kënë ee **output** cɔl a tɔ̈ në kam 0 ku 1. Luɔi kënë ee kënë cɔl coefficient yök, cï gɔ̈t keye α. Wok a lëu bïk **threshold** de ciëën luel keye α × A. Rin kënë, **threshold** ee kënë ye yök të biɔ̈k yïn namba kerou. Namba tök a tɔ̈ kam 0 ku 1. Namba dɛ̈t ee **average** de **absolute values** ke **feature map**. **Kuɛr kënë ee ye cɔl a ŋic lɔn threshold a dït tënë zero (positive). Kuɛr kënë ee ye cɔl a ŋic aya lɔn threshold a cïï dït apɛi.**

**Ku aya, samples wääc aa thresholds wääc yök. Rin kënë, wok a lëu bïk kuɛr kënë deetic keye attention mechanism dɛ̈t. Mechanism kënë ee features cïï mat kekë task kënë yök. Mechanism ee features kɛ̈ cɔl a lɔ thiɔ̈k kekë zero në kuɛr de convolutional layers kerou. Ku ka, mechanism ee features kɛ̈ cɔl a ya zero në kuɛr de soft thresholding. Tëdë, mechanism ee features mat kekë task kënë yök. Mechanism ee features kɛ̈ cɔl a lɔ mec tënë zero në kuɛr de convolutional layers kerou. Në ciëën, mechanism ee features kɛ̈ gɛ̈l.**

Në ciëën, wok a lëu bïk **Stack many basic modules** (bï modules juëc tɔ̈ɔ̈u në kɔ̈u). Wok aa **convolutional layers**, **batch normalization**, **activation functions**, **global average pooling**, ku **fully connected output layers** mat thïn. Luɔi kënë ee **Deep Residual Shrinkage Network** looi a cï thök.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generalization Capability

**Deep Residual Shrinkage Network** ee kuɛr path tënë **feature learning**. Rin ee, në **feature learning tasks** juëc yiic, **samples** aa **noise** nɔŋ ic. **Samples** aa wɛ̈t cïï thiekiic nɔŋ ic aya. **Noise** kɛ̈ ku wɛ̈t cïï thiekiic a lëu bïk luɔi de **feature learning** rac. Akɔ̈ɔ̈n:

Tak **image classification**. **Image** a lëu bï kä kɔ̈k juëc nɔŋ ic. Wok a lëu bïk kä kɛ̈ deetic keye "**noise**". **Deep Residual Shrinkage Network** a lëu bï **attention mechanism** luɔ̈ɔ̈i. **Network** a bï "**noise**" kënë tïŋ. Ku ka, **network** ee **soft thresholding** luɔ̈ɔ̈i bï **features** ke "**noise**" kënë cɔl a ya zero. Luɔi kënë a lëu bï **image classification accuracy** cɔl adït.

Tak **speech recognition**. Tëdït, tak të nɔŋ **noise** apɛi, cït jam ë kuɛr gɛ̈l wala në ɣön de luɔi (factory workshop) ic. **Deep Residual Shrinkage Network** a lëu bï **speech recognition accuracy** cɔl adït. Tëdë, **network** ee kuɛr path nyuɔɔth. Kuɛr kënë a lëu bï **speech recognition accuracy** cɔl adït.

## Reference

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

[https://ieeexplore.ieee.org/document/8850096](https://ieeexplore.ieee.org/document/8850096)

## BibTeX
```bibtex
@article{Zhao2020,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}
```

## Academic Impact

Wɛ̈t kënë (paper) a cï kɔc tïŋ ku gɔ̈t (citations) lɔ tɔ̈ŋ 1,400 në **Google Scholar**.

Në kuɛr de gɔ̈t cïï thök, kɔc piɔ̈ɔ̈c (researchers) a cï **Deep Residual Shrinkage Network (DRSN)** luɔ̈ɔ̈i në **publications/studies** tɔ̈ŋ 1,000 ic. Luɔi kɛ̈ aa tɔ̈ në **fields** juëc yiic. **Fields** kɛ̈ aa mat **mechanical engineering**, **electrical power**, **vision**, **healthcare**, **speech**, **text**, **radar**, ku **remote sensing**.
