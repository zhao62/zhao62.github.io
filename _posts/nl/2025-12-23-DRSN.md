---
layout: post
title: "Deep Residual Shrinkage Network: Een AI-methode voor data met veel ruis"
date: 2025-12-23
author: "Minghang Zhao, Harbin Institute of Technology"
tags: [Deep Learning, AI]
mathjax: true
description: "De Deep Residual Shrinkage Network is een verbeterde variant van de Deep Residual Network (ResNet). In essentie is het een integratie van de Deep Residual Network, attention mechanisms en soft thresholding functies."
lang: nl
categories: nl
ref: drsn-2025
buttons:
  - type: hit
    text: HIT Homepage
    url: https://homepage.hit.edu.cn/zhaominghang?lang=zh
  - type: scholar
    text: Google Scholar
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
  - type: ieee
    text: IEEE Paper
    url: https://ieeexplore.ieee.org/document/8850096
  - type: github
    text: GitHub Code
    url: https://github.com/zhao62/Deep-Residual-Shrinkage-Networks
  - type: citation
    text: "Citations: 1400+"
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
---

**De Deep Residual Shrinkage Network is een verbeterde variant van de Deep Residual Network (ResNet). In essentie is het een integratie van de Deep Residual Network, attention mechanisms en soft thresholding functies.**

**De werking van de Deep Residual Shrinkage Network kan tot op zekere hoogte als volgt worden begrepen: via een attention mechanism worden onbelangrijke features opgemerkt, die vervolgens door een soft thresholding functie op nul worden gezet. Anders gezegd: het mechanisme merkt belangrijke features op en behoudt deze. Dit versterkt het vermogen van het deep neural network om nuttige features te extracten uit signalen die ruis bevatten.**

## 1. Motivatie voor het onderzoek

**Ten eerste: bij het classificeren van samples is de aanwezigheid van ruis – zoals Gaussische ruis, roze ruis en Laplace-ruis – onvermijdelijk.** In bredere zin bevatten samples vaak informatie die niet relevant is voor de huidige classificatietaak; ook dit kan worden gezien als ruis. Deze ruis kan de prestaties van de classificatie negatief beïnvloeden. (Soft thresholding is een cruciale stap in veel algoritmen voor signaalruisonderdrukking).

Een voorbeeld: tijdens een gesprek langs de weg kan het stemgeluid vermengd raken met toeterende auto's of bandengeruis. Bij **speech recognition** op deze signalen zal het resultaat onvermijdelijk worden beïnvloed door deze achtergrondgeluiden. Vanuit een **deep learning**-perspectief zouden de features die corresponderen met dat getoeter en bandengeruis binnen het deep neural network verwijderd moeten worden, om te voorkomen dat ze de spraakherkenning verstoren.

**Ten tweede: zelfs binnen dezelfde dataset varieert de hoeveelheid ruis vaak per sample.** (Dit vertoont overeenkomsten met **attention mechanisms**; neem een dataset met afbeeldingen als voorbeeld: de locatie van het doelobject kan per foto verschillen, en het attention mechanism kan focussen op de specifieke locatie van het object in elke afzonderlijke afbeelding).

Stel dat we bijvoorbeeld een honden-en-katten-classifier **trainen**. Neem vijf afbeeldingen met het label "hond". De eerste afbeelding bevat misschien een hond én een muis, de tweede een hond én een gans, de derde een hond én een kip, de vierde een hond én een ezel, en de vijfde een hond én een eend. Tijdens het trainen van de classifier ondervinden we onvermijdelijk storing van deze irrelevante objecten (muis, gans, kip, ezel en eend), wat leidt tot een lagere classificatie-nauwkeurigheid (**accuracy**). Als we in staat zijn om deze irrelevante objecten op te merken en de bijbehorende features te verwijderen, kunnen we de nauwkeurigheid van de classifier verbeteren.

## 2. Soft Thresholding

**Soft thresholding is een kernstap in veel algoritmen voor signaalruisonderdrukking. Het verwijdert features waarvan de absolute waarde lager is dan een bepaalde drempelwaarde (threshold) en "krimpt" features die daarboven zitten richting nul.** Dit kan worden geïmplementeerd met de volgende formule:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

De afgeleide van de output van soft thresholding ten opzichte van de input is:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

Zoals hierboven te zien is, is de afgeleide van soft thresholding ofwel 1 ofwel 0. Deze eigenschap is identiek aan die van de **ReLU** activatiefunctie. Hierdoor kan soft thresholding ook het risico verkleinen dat deep learning-algoritmen last krijgen van **gradient vanishing** en **gradient exploding**.

**Bij het instellen van de threshold in de soft thresholding functie moet aan twee voorwaarden worden voldaan: ten eerste moet de threshold een positief getal zijn; ten tweede mag de threshold niet groter zijn dan de maximale waarde van het inputsignaal, anders wordt de output volledig nul.**

**Tegelijkertijd is het wenselijk dat de threshold aan een derde voorwaarde voldoet: elk sample zou, gebaseerd op zijn eigen ruisniveau, een eigen onafhankelijke threshold moeten hebben.**

Dit komt doordat de hoeveelheid ruis vaak varieert tussen samples. Het komt bijvoorbeeld vaak voor dat binnen dezelfde dataset Sample A weinig ruis bevat en Sample B veel ruis. Als we dan soft thresholding toepassen in een ruisonderdrukkingsalgoritme, zou Sample A een kleinere threshold moeten gebruiken en Sample B een grotere. Hoewel deze features en thresholds in een deep neural network hun expliciete fysische betekenis verliezen, blijft de onderliggende logica hetzelfde. Oftewel: elk sample heeft een eigen, onafhankelijke threshold nodig.

## 3. Attention Mechanism

Het concept van een **attention mechanism** is vrij eenvoudig te begrijpen binnen het vakgebied **Computer Vision**. Het visuele systeem van dieren kan snel een volledige omgeving scannen, een doelobject ontdekken en vervolgens de aandacht (attention) focussen op dat object om meer details te zien, terwijl irrelevante informatie wordt onderdrukt. Zie voor details de literatuur over attention mechanisms.

**Squeeze-and-Excitation Network (SENet)** is een relatief nieuwe deep learning-methode die gebruikmaakt van attention mechanisms. De bijdrage van verschillende **feature channels** aan een classificatietaak verschilt vaak per sample. SENet gebruikt een klein sub-netwerk om een set gewichten (weights) te verkrijgen. Deze gewichten worden vervolgens vermenigvuldigd met de features van de respectievelijke channels om de grootte van de features per channel aan te passen. Dit proces kan worden gezien als het toepassen van verschillende maten van "aandacht" op de verschillende feature channels.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-28-DRSN-nl/SENET_nl_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

Op deze manier heeft elk sample zijn eigen onafhankelijke set gewichten. Met andere woorden: de gewichten zijn voor elk willekeurig paar samples verschillend. In SENet is het specifieke pad om deze gewichten te verkrijgen: "**Global Pooling** → **Fully Connected Layer** → **ReLU** functie → **Fully Connected Layer** → **Sigmoid** functie".

<p align="center">
  <img src="/assets/img/DRSN/2025-11-28-DRSN-nl/SENET_nl_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding met Deep Attention Mechanism

De Deep Residual Shrinkage Network maakt gebruik van de hierboven genoemde sub-netwerkstructuur van SENet om soft thresholding te realiseren binnen een **deep attention mechanism**. Via het sub-netwerk (aangegeven in de rode kaders) kan een set thresholds worden geleerd om soft thresholding toe te passen op elk feature channel.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-28-DRSN-nl/DRSN_nl_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

In dit sub-netwerk wordt eerst de absolute waarde genomen van alle features in de input **feature map**. Vervolgens wordt via **global average pooling** en middeling een feature verkregen, die we noteren als A. In het andere pad wordt de feature map na global average pooling ingevoerd in een klein **fully connected network**. Dit netwerk gebruikt een Sigmoid-functie als laatste laag om de output te normaliseren tussen 0 en 1, wat een coëfficiënt oplevert, genoteerd als α. De uiteindelijke threshold kan worden uitgedrukt als α×A. De threshold is dus: een getal tussen 0 en 1 vermenigvuldigd met het gemiddelde van de absolute waarden van de feature map. **Deze methode garandeert niet alleen dat de threshold positief is, maar ook dat deze niet te groot wordt.**

**Bovendien krijgen verschillende samples hierdoor verschillende thresholds. Daarom kan dit tot op zekere hoogte worden begrepen als een speciaal attention mechanism: het merkt features op die niet relevant zijn voor de huidige taak, transformeert deze via twee convolutional layers naar waarden dicht bij 0, en zet ze via soft thresholding op nul; of anders gezegd: het merkt features op die wél relevant zijn voor de taak, transformeert deze via twee convolutional layers naar waarden ver van 0, en behoudt deze features.**

Tot slot wordt de volledige Deep Residual Shrinkage Network geconstrueerd door een bepaald aantal basismodules te stapelen, samen met **convolutional layers**, **Batch Normalization**, activatiefuncties, **global average pooling** en een **fully connected** outputlaag.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-28-DRSN-nl/DRSN_nl_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generaliseerbaarheid

De Deep Residual Shrinkage Network is in feite een generieke methode voor **feature learning**. Dit komt doordat samples in veel feature learning-taken min of meer ruis en irrelevante informatie bevatten. Deze ruis en irrelevante informatie kunnen een negatieve invloed hebben op het leerproces. Bijvoorbeeld:

Bij **image classification**: als een afbeelding tegelijkertijd veel andere objecten bevat, kunnen deze objecten worden opgevat als "ruis". De Deep Residual Shrinkage Network kan mogelijk via het attention mechanism deze "ruis" opmerken en vervolgens via soft thresholding de features die bij deze "ruis" horen op nul zetten. Dit kan de nauwkeurigheid van de beeldclassificatie verhogen.

Bij **speech recognition**: in omgevingen met veel achtergrondgeluid, zoals tijdens een gesprek langs de weg of in een fabriekshal, kan de Deep Residual Shrinkage Network de nauwkeurigheid van de spraakherkenning verbeteren, of op zijn minst een strategie bieden die kan leiden tot betere prestaties.

## 6. Wetenschappelijke impact

Volgens Google Scholar is deze paper al meer dan 1400 keer geciteerd.

Volgens een conservatieve schatting is de Deep Residual Shrinkage Network in meer dan 1000 publicaties direct toegepast of in verbeterde vorm gebruikt in uiteenlopende gebieden, waaronder werktuigbouwkunde, energiesystemen, computer vision, medische technologie, spraakverwerking, tekstanalyse, radar en remote sensing.

## 7. Artikelinformatie

<div style="background-color: #fff; border: 1px solid #e1e4e8; border-radius: 6px; padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-bottom: 20px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;">
    
    <!-- 1. 论文标题 -->
    <div style="font-size: 18px; font-weight: 700; color: #0366d6; margin-bottom: 8px; line-height: 1.4;">
        <a href="https://ieeexplore.ieee.org/document/8850096" target="_blank" style="text-decoration: none; color: inherit; transition: color 0.2s;">
            Deep Residual Shrinkage Networks for Fault Diagnosis
        </a>
    </div>

    <!-- 2. 作者列表 -->
    <div style="font-size: 14px; color: #24292e; margin-bottom: 6px; line-height: 1.5;">
        <strong>Minghang Zhao</strong>, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht
    </div>

    <!-- 3. 期刊信息 -->
    <div style="font-size: 14px; color: #586069; font-style: italic; margin-bottom: 15px; line-height: 1.5;">
        IEEE Transactions on Industrial Informatics, vol. 16, no. 7, pp. 4681-4690, July 2020.
    </div>

    <!-- 4. 操作按钮行 (Mobile & Desktop Perfect) -->
    <div style="display: flex; gap: 8px; flex-wrap: wrap; align-items: center;">
        
        <!-- IEEE 官方链接 -->
        <a href="https://ieeexplore.ieee.org/document/8850096" target="_blank" style="text-decoration: none;">
            <div style="background: #00629B; color: white; padding: 5px 12px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                IEEE Xplore
            </div>
        </a>

        <!-- PDF 下载 -->
        <a href="https://zhao62.github.io/assets/pdf/Zhao2020DRSN.pdf" target="_blank" style="text-decoration: none;">
            <div style="background: #cb2431; color: white; padding: 5px 12px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                Download PDF
            </div>
        </a>

        <!-- 谷歌学术 -->
        <a href="https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en" target="_blank" style="text-decoration: none;">
            <div style="background: #fff; color: #24292e; border: 1px solid #d1d5da; padding: 4px 11px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                Google Scholar
            </div>
        </a>

        <!-- 复制纯文本按钮 -->
        <button id="btn-copy-cite-text-zhao2020" onclick="copyCitationText('citation-content-zhao2020', 'btn-copy-cite-text-zhao2020')" style="background: #f6f8fa; color: #24292e; border: 1px solid #d1d5da; padding: 4px 11px; border-radius: 4px; font-size: 12px; font-weight: 600; cursor: pointer; outline: none; font-family: inherit; line-height: normal;">
            Copy Citation
        </button>
    </div>

    <!-- 隐藏的纯文本源 -->
    <div id="citation-content-zhao2020" style="display: none;">M. Zhao, S. Zhong, X. Fu, B. Tang, and M. Pecht, "Deep Residual Shrinkage Networks for Fault Diagnosis," IEEE Transactions on Industrial Informatics, vol. 16, no. 7, pp. 4681-4690, 2020.</div>
</div>

<script>
function copyCitationText(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        var originalText = btn.innerText;
        // 使用 textContent 兼容性更好
        btn.textContent = 'Copied! ✓';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.textContent = 'Copy Citation';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed', err);
        // 如果失败，不做任何操作，或者可以 alert
    }

    // 优先使用现代 Clipboard API
    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopyText(content);
        });
    } else {
        fallbackCopyText(content);
    }

    // 终极兼容：使用 execCommand
    function fallbackCopyText(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            
            // 关键优化：防止手机端弹出键盘
            textArea.setAttribute('readonly', '');
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            
            // 针对 iOS 的特殊处理
            var range = document.createRange();
            range.selectNodeContents(textArea);
            var selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            textArea.setSelectionRange(0, 999999);

            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            
            if (successful) handleSuccess();
            else handleError('execCommand fail');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>

## 8. BibTeX

<!-- 终极兼容版 BibTeX 块 -->
<div class="bibtex-container" style="border: 1px solid #e1e4e8; border-radius: 6px; background-color: #f6f8fa; margin-bottom: 16px; max-width: 100%;">
    
    <!-- 顶部工具栏 -->
    <div style="display: flex; justify-content: space-between; align-items: center; padding: 8px 12px; border-bottom: 1px solid #e1e4e8; background-color: #ffffff; border-radius: 6px 6px 0 0;">
        <span style="font-size: 13px; font-weight: 600; color: #586069; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;">
            BibTeX
        </span>
        <button id="copy-btn-zhao2020" onclick="copyBibtexStable('bibtex-content-zhao2020', 'copy-btn-zhao2020')" style="border: 1px solid #d1d5da; background-color: #fff; color: #24292e; border-radius: 4px; padding: 4px 10px; font-size: 12px; cursor: pointer; font-weight: 600; line-height: 20px; transition: all 0.2s ease; outline: none;">
            Copy
        </button>
    </div>

    <!-- 代码区域 -->
    <div style="overflow-x: auto; padding: 15px;">
<!-- 注意：这里的第一行已经改成了 @article{Zhao2020DRSN, -->
<pre id="bibtex-content-zhao2020" style="margin: 0; font-family: SFMono-Regular, Consolas, 'Liberation Mono', Menlo, monospace; font-size: 13px; line-height: 1.45; color: #24292e; white-space: pre;">@article{Zhao2020DRSN,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}</pre>
    </div>
</div>

<script>
/**
 * 高兼容性复制函数
 */
function copyBibtexStable(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        btn.innerText = 'Copied! ✓';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.innerText = 'Copy';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed:', err);
        alert('Press Ctrl+C to copy');
    }

    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopy(content);
        });
    } else {
        fallbackCopy(content);
    }

    function fallbackCopy(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            if (successful) handleSuccess();
            else handleError('execCommand returned false');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>
