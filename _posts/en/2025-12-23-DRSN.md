---
layout: post
title: "Deep Residual Shrinkage Network: An Artificial Intelligence Method for Highly Noisy Data"
date: 2025-12-23
author: "Minghang Zhao, Harbin Institute of Technology"
tags: 
  - Deep Learning
  - DRSN
  - Fault Diagnosis
  - Signal Processing
  - ResNet
  - Attention Mechanism
  - Soft Thresholding
  - Denoising
mathjax: true
description: "Deep Residual Shrinkage Networks (DRSN) are a deep learning method designed for highly noisy data. Integrating ResNet, attention mechanisms, and soft thresholding, DRSN excels in fault diagnosis, signal processing, and image classification by effectively learning features while denoising."
lang: en
categories: en
ref: drsn-2025
buttons:
  - type: hit
    text: HIT Homepage
    url: https://homepage.hit.edu.cn/zhaominghang?lang=zh
  - type: scholar
    text: Google Scholar
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
  - type: ieee
    text: IEEE Paper
    url: https://ieeexplore.ieee.org/document/8850096
  - type: github
    text: GitHub Code
    url: https://github.com/zhao62/Deep-Residual-Shrinkage-Networks
  - type: citation
    text: "Citations: 1400+"
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
---

**The Deep Residual Shrinkage Network is an improved variant of the Deep Residual Network. Essentially, it is an integration of the Deep Residual Network, attention mechanisms, and soft thresholding functions.**

**To a certain extent, the working principle of the Deep Residual Shrinkage Network can be understood as follows: it utilizes attention mechanisms to identify unimportant features and employs soft thresholding functions to set them to zero; conversely, it identifies important features and retains them. This process enhances the deep neural network's ability to extract useful features from signals containing noise.**

## 1. Research Motivation

**First, when classifying samples, the presence of noise‚Äîsuch as Gaussian noise, pink noise, and Laplacian noise‚Äîis inevitable.** More broadly, samples often contain information irrelevant to the current classification task, which can also be interpreted as noise. This noise may negatively affect classification performance. (Soft thresholding is a key step in many signal denoising algorithms.)

For example, during a conversation by a roadside, the audio may be mixed with the sounds of car horns and wheels. When performing speech recognition on these signals, the results will inevitably be affected by these background sounds. From a deep learning perspective, the features corresponding to the horns and wheels should be eliminated within the deep neural network to prevent them from affecting the speech recognition results.

**Secondly, even within the same dataset, the amount of noise often varies from sample to sample.** (This shares similarities with attention mechanisms; taking an image dataset as an example, the location of the target object may differ across images, and attention mechanisms can focus on the specific location of the target object in each image.)

For instance, when training a cat-and-dog classifier, consider five images labeled as "dog." The first image might contain a dog and a mouse, the second a dog and a goose, the third a dog and a chicken, the fourth a dog and a donkey, and the fifth a dog and a duck. During training, the classifier will inevitably be subject to interference from irrelevant objects such as mice, geese, chickens, donkeys, and ducks, resulting in a decrease in classification accuracy. If we can identify these irrelevant objects‚Äîthe mice, geese, chickens, donkeys, and ducks‚Äîand eliminate their corresponding features, it is possible to improve the accuracy of the cat-and-dog classifier.

## 2. Soft Thresholding

**Soft thresholding is a core step in many signal denoising algorithms. It eliminates features whose absolute values are lower than a certain threshold and shrinks features whose absolute values are higher than this threshold towards zero.** It can be implemented using the following formula:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

The derivative of the soft thresholding output with respect to the input is:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

As shown above, the derivative of soft thresholding is either 1 or 0. This property is identical to that of the ReLU activation function. Therefore, soft thresholding can also reduce the risk of deep learning algorithms encountering gradient vanishing and gradient exploding.

**In the soft thresholding function, the setting of the threshold must satisfy two conditions: first, the threshold must be a positive number; second, the threshold cannot exceed the maximum value of the input signal, otherwise the output will be entirely zero.**

**Additionally, it is preferable for the threshold to satisfy a third condition: each sample should have its own independent threshold based on its noise content.**

This is because the noise content often varies among samples. For example, it is common within the same dataset for Sample A to contain less noise while Sample B contains more noise. In this case, when performing soft thresholding in a denoising algorithm, Sample A should utilize a smaller threshold, whereas Sample B should utilize a larger threshold. Although these features and thresholds lose their explicit physical definitions in deep neural networks, the basic underlying logic remains the same. In other words, each sample should have its own independent threshold determined by its specific noise content.

## 3. Attention Mechanism

Attention mechanisms are relatively easy to understand in the field of computer vision. The visual systems of animals can distinguish targets by rapidly scanning the entire area, subsequently focusing attention on the target object to extract more details while suppressing irrelevant information. For specifics, please refer to literature regarding attention mechanisms.

The Squeeze-and-Excitation Network (SENet) represents a relatively new deep learning method utilizing attention mechanisms. Across different samples, the contribution of different feature channels to the classification task often varies. SENet employs a small sub-network to obtain a set of weights and then multiplies these weights by the features of the respective channels to adjust the magnitude of the features in each channel. This process can be viewed as applying varying levels of attention to different feature channels.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

In this approach, every sample possesses its own independent set of weights. In other words, the weights for any two arbitrary samples are different. In SENet, the specific path for obtaining weights is "Global Pooling ‚Üí Fully Connected Layer ‚Üí ReLU Function ‚Üí Fully Connected Layer ‚Üí Sigmoid Function."

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding with Deep Attention Mechanism

The Deep Residual Shrinkage Network draws inspiration from the aforementioned SENet sub-network structure to implement soft thresholding under a deep attention mechanism. Through the sub-network (indicated within the red box), a set of thresholds can be learned to apply soft thresholding to each feature channel.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

In this sub-network, the absolute values of all features in the input feature map are first calculated. Then, through global average pooling and averaging, a feature is obtained, denoted as A. In the other path, the feature map after global average pooling is input into a small fully connected network. This fully connected network uses the Sigmoid function as its final layer to normalize the output between 0 and 1, yielding a coefficient denoted as Œ±. The final threshold can be expressed as Œ±√óA. Therefore, the threshold is the product of a number between 0 and 1 and the average of the absolute values of the feature map. **This method ensures that the threshold is not only positive but also not excessively large.**

**Furthermore, different samples result in different thresholds. Consequently, to a certain extent, this can be interpreted as a specialized attention mechanism: it identifies features irrelevant to the current task, transforms them into values close to zero via two convolutional layers, and sets them to zero using soft thresholding; alternatively, it identifies features relevant to the current task, transforms them into values far from zero via two convolutional layers, and preserves them.**

Finally, by stacking a certain number of basic modules along with convolutional layers, batch normalization, activation functions, global average pooling, and fully connected output layers, the complete Deep Residual Shrinkage Network is constructed.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generalization Capability

The Deep Residual Shrinkage Network is, in fact, a general feature learning method. This is because, in many feature learning tasks, samples more or less contain some noise as well as irrelevant information. This noise and irrelevant information may affect the performance of feature learning. For example:

In image classification, if an image simultaneously contains many other objects, these objects can be understood as "noise." The Deep Residual Shrinkage Network may be able to utilize the attention mechanism to notice this "noise" and then employ soft thresholding to set the features corresponding to this "noise" to zero, thereby potentially improving image classification accuracy.

In speech recognition, specifically in relatively noisy environments such as conversational settings by a roadside or inside a factory workshop, the Deep Residual Shrinkage Network may improve speech recognition accuracy, or at the very least, offer a methodology capable of improving speech recognition accuracy.

## 6. Academic Impact

This paper has received over 1,400 citations on Google Scholar.

According to conservative estimates, Deep Residual Shrinkage Networks (DRSN) have been utilized in more than 1,000 publications. These works have either directly applied or improved upon the network across a wide range of fields, including mechanical engineering, electric power, computer vision, healthcare, speech processing, text analysis, radar, and remote sensing.

## 7. Paper Info

<div style="background-color: #fff; border: 1px solid #e1e4e8; border-radius: 6px; padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-bottom: 20px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;">
    
    <!-- 1. ËÆ∫ÊñáÊ†áÈ¢ò -->
    <div style="font-size: 18px; font-weight: 700; color: #0366d6; margin-bottom: 8px; line-height: 1.4;">
        <a href="https://ieeexplore.ieee.org/document/8850096" target="_blank" style="text-decoration: none; color: inherit; transition: color 0.2s;">
            Deep Residual Shrinkage Networks for Fault Diagnosis
        </a>
    </div>

    <!-- 2. ‰ΩúËÄÖÂàóË°® -->
    <div style="font-size: 14px; color: #24292e; margin-bottom: 6px; line-height: 1.5;">
        <strong>Minghang Zhao</strong>, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht
    </div>

    <!-- 3. ÊúüÂàä‰ø°ÊÅØ -->
    <div style="font-size: 14px; color: #586069; font-style: italic; margin-bottom: 15px; line-height: 1.5;">
        IEEE Transactions on Industrial Informatics, vol. 16, no. 7, pp. 4681-4690, July 2020.
    </div>

    <!-- 4. Êìç‰ΩúÊåâÈíÆË°å (Mobile & Desktop Perfect) -->
    <div style="display: flex; gap: 8px; flex-wrap: wrap; align-items: center;">
        
        <!-- IEEE ÂÆòÊñπÈìæÊé• -->
        <a href="https://ieeexplore.ieee.org/document/8850096" target="_blank" style="text-decoration: none;">
            <div style="background: #00629B; color: white; padding: 5px 12px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                IEEE Xplore
            </div>
        </a>

        <!-- PDF ‰∏ãËΩΩ -->
        <a href="https://zhao62.github.io/assets/pdf/Zhao2020DRSN.pdf" target="_blank" style="text-decoration: none;">
            <div style="background: #cb2431; color: white; padding: 5px 12px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                Download PDF
            </div>
        </a>

        <!-- Ë∞∑Ê≠åÂ≠¶ÊúØ -->
        <a href="https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en" target="_blank" style="text-decoration: none;">
            <div style="background: #fff; color: #24292e; border: 1px solid #d1d5da; padding: 4px 11px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                Google Scholar
            </div>
        </a>

        <!-- Â§çÂà∂Á∫ØÊñáÊú¨ÊåâÈíÆ -->
        <button id="btn-copy-cite-text-zhao2020" onclick="copyCitationText('citation-content-zhao2020', 'btn-copy-cite-text-zhao2020')" style="background: #f6f8fa; color: #24292e; border: 1px solid #d1d5da; padding: 4px 11px; border-radius: 4px; font-size: 12px; font-weight: 600; cursor: pointer; outline: none; font-family: inherit; line-height: normal;">
            Copy Citation
        </button>
    </div>

    <!-- ÈöêËóèÁöÑÁ∫ØÊñáÊú¨Ê∫ê -->
    <div id="citation-content-zhao2020" style="display: none;">M. Zhao, S. Zhong, X. Fu, B. Tang, and M. Pecht, "Deep Residual Shrinkage Networks for Fault Diagnosis," IEEE Transactions on Industrial Informatics, vol. 16, no. 7, pp. 4681-4690, 2020.</div>
</div>

<script>
function copyCitationText(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        var originalText = btn.innerText;
        // ‰ΩøÁî® textContent ÂÖºÂÆπÊÄßÊõ¥Â•Ω
        btn.textContent = 'Copied! ‚úì';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.textContent = 'Copy Citation';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed', err);
        // Â¶ÇÊûúÂ§±Ë¥•Ôºå‰∏çÂÅö‰ªª‰ΩïÊìç‰ΩúÔºåÊàñËÄÖÂèØ‰ª• alert
    }

    // ‰ºòÂÖà‰ΩøÁî®Áé∞‰ª£ Clipboard API
    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopyText(content);
        });
    } else {
        fallbackCopyText(content);
    }

    // ÁªàÊûÅÂÖºÂÆπÔºö‰ΩøÁî® execCommand
    function fallbackCopyText(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            
            // ÂÖ≥ÈîÆ‰ºòÂåñÔºöÈò≤Ê≠¢ÊâãÊú∫Á´ØÂºπÂá∫ÈîÆÁõò
            textArea.setAttribute('readonly', '');
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            
            // ÈíàÂØπ iOS ÁöÑÁâπÊÆäÂ§ÑÁêÜ
            var range = document.createRange();
            range.selectNodeContents(textArea);
            var selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            textArea.setSelectionRange(0, 999999);

            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            
            if (successful) handleSuccess();
            else handleError('execCommand fail');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>

## 8. BibTeX

<!-- ÁªàÊûÅÂÖºÂÆπÁâà BibTeX Âùó -->
<div class="bibtex-container" style="border: 1px solid #e1e4e8; border-radius: 6px; background-color: #f6f8fa; margin-bottom: 16px; max-width: 100%;">
    
    <!-- È°∂ÈÉ®Â∑•ÂÖ∑Ê†è -->
    <div style="display: flex; justify-content: space-between; align-items: center; padding: 8px 12px; border-bottom: 1px solid #e1e4e8; background-color: #ffffff; border-radius: 6px 6px 0 0;">
        <span style="font-size: 13px; font-weight: 600; color: #586069; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;">
            BibTeX
        </span>
        <button id="copy-btn-zhao2020" onclick="copyBibtexStable('bibtex-content-zhao2020', 'copy-btn-zhao2020')" style="border: 1px solid #d1d5da; background-color: #fff; color: #24292e; border-radius: 4px; padding: 4px 10px; font-size: 12px; cursor: pointer; font-weight: 600; line-height: 20px; transition: all 0.2s ease; outline: none;">
            Copy
        </button>
    </div>

    <!-- ‰ª£Á†ÅÂå∫Âüü -->
    <div style="overflow-x: auto; padding: 15px;">
<!-- Ê≥®ÊÑèÔºöËøôÈáåÁöÑÁ¨¨‰∏ÄË°åÂ∑≤ÁªèÊîπÊàê‰∫Ü @article{Zhao2020DRSN, -->
<pre id="bibtex-content-zhao2020" style="margin: 0; font-family: SFMono-Regular, Consolas, 'Liberation Mono', Menlo, monospace; font-size: 13px; line-height: 1.45; color: #24292e; white-space: pre;">@article{Zhao2020DRSN,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}</pre>
    </div>
</div>

<script>
/**
 * È´òÂÖºÂÆπÊÄßÂ§çÂà∂ÂáΩÊï∞
 */
function copyBibtexStable(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        btn.innerText = 'Copied! ‚úì';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.innerText = 'Copy';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed:', err);
        alert('Press Ctrl+C to copy');
    }

    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopy(content);
        });
    } else {
        fallbackCopy(content);
    }

    function fallbackCopy(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            if (successful) handleSuccess();
            else handleError('execCommand returned false');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>

## 9. Research Gallery & Latest Works

If you find DRSN useful, you might be interested in our broader research landscape. We focus on **Imbalanced/Few-shot Learning**, **Wavelet Integration**, **Battery Health**, and **Physics-Informed Diagnosis**.

<div style="font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;">

  <!-- ======================================================= -->
  <!-- GROUP 1: Imbalanced Data & Few-Shot Learning (ÊúÄÁÉ≠Èó®ÊñπÂêë) -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #0366d6; padding-bottom: 10px; margin-top: 40px; color: #24292e;">
    üöÄ Imbalanced Data & Small Sample Learning
  </h3>
  <p style="font-size: 14px; color: #586069; margin-bottom: 20px;">
    Solutions for scenarios where fault data is scarce or highly imbalanced (Data Augmentation, SMOTE, Metric Learning).
  </p>

  <!-- 2025/2024 New Papers -->
  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #d73a49; background-color: #fff; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
    <div style="display: flex; align-items: center; margin-bottom: 4px;">
      <span style="background: #d73a49; color: white; font-size: 10px; font-weight: bold; padding: 2px 6px; border-radius: 3px; margin-right: 8px;">NEW 2025</span>
      <span style="font-size: 12px; font-weight: 600; color: #586069;">Advanced Engineering Informatics</span>
    </div>
    <a href="https://doi.org/10.1016/j.aei.2024.103297" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 15px; display: block; line-height: 1.4;">
      Continual contrastive reinforcement learning: Towards stronger agent for environment-aware fault diagnosis
    </a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #28a745; background-color: #fff; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
    <div style="display: flex; align-items: center; margin-bottom: 4px;">
      <span style="background: #28a745; color: white; font-size: 10px; font-weight: bold; padding: 2px 6px; border-radius: 3px; margin-right: 8px;">MSSP 2024</span>
      <span style="font-size: 12px; font-weight: 600; color: #586069;">Mechanical Systems and Signal Processing</span>
    </div>
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 15px; display: block; line-height: 1.4;">
      High imbalance fault diagnosis of aviation hydraulic pump based on data augmentation via local wavelet similarity fusion
    </a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #0366d6; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[Measurement 2024] DCSN: Focusing on hard samples mining in small-sample fault diagnosis</a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #0366d6; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[ESWA 2024] Feature-level SMOTE: Augmenting Fault Samples in Learnable Feature Space</a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #0366d6; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[IEEE TIM 2022] Data augmentation via randomized wavelet expansion for few-shot fault diagnosis</a>
  </div>
  
  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #0366d6; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[AEI 2022] Highly imbalanced fault diagnosis based on wavelet packet distortion and CNNs</a>
  </div>

  <!-- Foldable older papers to save space -->
  <details style="margin-top: 10px; cursor: pointer; color: #586069; font-size: 13px;">
    <summary>View more papers on Data Augmentation & Imbalance</summary>
    <ul style="margin-top: 10px; line-height: 1.6; padding-left: 20px;">
        <li><b>[CII 2023]</b> Deep attention SMOTE: Data augmentation with a learnable interpolation factor</li>
        <li><b>[AEI 2022]</b> Highly imbalanced fault diagnosis via clustering-based downsampling and deep siamese self-attention</li>
        <li><b>[CII 2022]</b> Empirical mode reconstruction: Preserving intrinsic components in data augmentation</li>
        <li><b>[Neurocomputing 2025]</b> CUR-Estimator: Towards reliable missing data imputation</li>
    </ul>
  </details>


  <!-- ======================================================= -->
  <!-- GROUP 2: Battery Health & RUL Prediction (Êñ∞ÂÖ¥Â∫îÁî®) -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #6f42c1; padding-bottom: 10px; margin-top: 40px; color: #24292e;">
    üîã Battery Health (SOH) & RUL Prediction
  </h3>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #d73a49; background-color: #fff; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
     <div style="display: flex; align-items: center; margin-bottom: 4px;">
      <span style="background: #d73a49; color: white; font-size: 10px; font-weight: bold; padding: 2px 6px; border-radius: 3px; margin-right: 8px;">NEW 2025</span>
      <span style="font-size: 12px; font-weight: 600; color: #586069;">Journal of Power Sources</span>
    </div>
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 15px; display: block; line-height: 1.4;">
      Deep transfer learning enabled online state-of-health estimation of lithium-ion batteries under small samples
    </a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #6f42c1; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[Energy 2024] BMSFormer: An efficient deep learning model for online SOH estimation</a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #6f42c1; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[RESS 2021] Deep residual LSTM with domain-invariance for remaining useful life prediction</a>
  </div>
  
  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #6f42c1; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[Measurement 2016] Bearing remaining useful life estimation based on time‚Äìfrequency representation</a>
  </div>


  <!-- ======================================================= -->
  <!-- GROUP 3: Advanced Networks & Attention (DRSN Á≤â‰∏ùÊúÄÁà±) -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #fd8c73; padding-bottom: 10px; margin-top: 40px; color: #24292e;">
    üß† Advanced Deep Architectures & Attention
  </h3>
  <p style="font-size: 14px; color: #586069; margin-bottom: 20px;">
    Novel architectures focusing on Attention Mechanisms, Activation Functions, and Semi-supervised learning.
  </p>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #fd8c73; background-color: #f6f8fa;">
    <div style="font-size: 12px; font-weight: 600; color: #586069; margin-bottom: 4px;">SHM 2024 (Attention Mechanism)</div>
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">Deep Exponential Excitation Networks: Towards Stronger Attention Mechanism for Weak Fault Diagnosis</a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #fd8c73; background-color: #f6f8fa;">
    <div style="font-size: 12px; font-weight: 600; color: #586069; margin-bottom: 4px;">IEEE TIE 2021 (Activation Function)</div>
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">Deep residual networks with adaptively parametric rectifier linear units (APReLU)</a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #fd8c73; background-color: #f6f8fa;">
    <div style="font-size: 12px; font-weight: 600; color: #586069; margin-bottom: 4px;">Measurement 2022 (Shrinkage Variant)</div>
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">Mechanical compound fault diagnosis via suppressing intra-class dispersions: A deep progressive shrinkage perspective</a>
  </div>

  <details style="margin-top: 10px; cursor: pointer; color: #586069; font-size: 13px;">
    <summary>View other Architectures (Semi-supervised / Anomaly Detection)</summary>
    <ul style="margin-top: 10px; line-height: 1.6; padding-left: 20px;">
        <li><b>[NCA 2023]</b> CSiamese: a novel semi-supervised anomaly detection framework</li>
        <li><b>[QREI 2022]</b> CAE-WANN: A novel anomaly detection method for gas turbines</li>
    </ul>
  </details>


  <!-- ======================================================= -->
  <!-- GROUP 4: Classic Wavelet & Simulation (ÁªèÂÖ∏Â∑•‰Ωú) -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #586069; padding-bottom: 10px; margin-top: 40px; color: #24292e;">
    ‚öôÔ∏è Wavelet Fusion & Physics-Informed
  </h3>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #24292e; background-color: #fff;">
    <div style="display: flex; align-items: center; margin-bottom: 4px;">
      <span style="background: #24292e; color: white; font-size: 10px; font-weight: bold; padding: 2px 6px; border-radius: 3px; margin-right: 8px;">Highly Cited</span>
      <span style="font-size: 12px; font-weight: 600; color: #586069;">IEEE TIE 2019</span>
    </div>
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 15px; display: block; line-height: 1.4;">
      Multiple wavelet coefficients fusion in deep residual networks for fault diagnosis
    </a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #586069; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[IEEE TIE 2018] Deep residual networks with dynamically weighted wavelet coefficients</a>
  </div>

  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #586069; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[Measurement 2020] Multiple wavelet regularized deep residual networks</a>
  </div>
  
  <div class="paper-card" style="margin-bottom: 12px; padding: 12px; border-left: 4px solid #586069; background-color: #f6f8fa;">
    <a href="#" style="font-weight: 600; color: #0366d6; text-decoration: none; font-size: 14px;">[Measurement 2025] Thermodynamic simulation-assisted random forest: Towards explainable fault diagnosis</a>
  </div>

</div>

<div style="text-align: center; margin-top: 40px; margin-bottom: 40px;">
  <a href="https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en" target="_blank" style="background: #0366d6; color: white; padding: 12px 24px; border-radius: 6px; text-decoration: none; font-weight: bold; font-size: 16px; box-shadow: 0 4px 6px rgba(3, 102, 214, 0.2); transition: transform 0.2s;">
    View All 100+ Publications on Google Scholar
  </a>
</div>
