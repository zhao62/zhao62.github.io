---
layout: post
title: "Deep Residual Shrinkage Network: An Artificial Intelligence Method for Highly Noisy Data"
date: 2025-12-23
author: "Minghang Zhao, Harbin Institute of Technology"
tags: 
  - Deep Learning
  - DRSN
  - Fault Diagnosis
  - Signal Processing
  - ResNet
  - Attention Mechanism
  - Soft Thresholding
  - Denoising
mathjax: true
description: "Deep Residual Shrinkage Networks (DRSN) are a deep learning method designed for highly noisy data. Integrating ResNet, attention mechanisms, and soft thresholding, DRSN excels in fault diagnosis, signal processing, and image classification by effectively learning features while denoising."
lang: en
categories: en
ref: drsn-2025
buttons:
  - type: hit
    text: HIT Homepage
    url: https://homepage.hit.edu.cn/zhaominghang?lang=zh
  - type: scholar
    text: Google Scholar
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
  - type: ieee
    text: IEEE Paper
    url: https://ieeexplore.ieee.org/document/8850096
  - type: github
    text: GitHub Code
    url: https://github.com/zhao62/Deep-Residual-Shrinkage-Networks
  - type: citation
    text: "Citations: 1400+"
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
---

**The Deep Residual Shrinkage Network is an improved variant of the Deep Residual Network. Essentially, it is an integration of the Deep Residual Network, attention mechanisms, and soft thresholding functions.**

**To a certain extent, the working principle of the Deep Residual Shrinkage Network can be understood as follows: it utilizes attention mechanisms to identify unimportant features and employs soft thresholding functions to set them to zero; conversely, it identifies important features and retains them. This process enhances the deep neural network's ability to extract useful features from signals containing noise.**

## 1. Research Motivation

**First, when classifying samples, the presence of noiseâ€”such as Gaussian noise, pink noise, and Laplacian noiseâ€”is inevitable.** More broadly, samples often contain information irrelevant to the current classification task, which can also be interpreted as noise. This noise may negatively affect classification performance. (Soft thresholding is a key step in many signal denoising algorithms.)

For example, during a conversation by a roadside, the audio may be mixed with the sounds of car horns and wheels. When performing speech recognition on these signals, the results will inevitably be affected by these background sounds. From a deep learning perspective, the features corresponding to the horns and wheels should be eliminated within the deep neural network to prevent them from affecting the speech recognition results.

**Secondly, even within the same dataset, the amount of noise often varies from sample to sample.** (This shares similarities with attention mechanisms; taking an image dataset as an example, the location of the target object may differ across images, and attention mechanisms can focus on the specific location of the target object in each image.)

For instance, when training a cat-and-dog classifier, consider five images labeled as "dog." The first image might contain a dog and a mouse, the second a dog and a goose, the third a dog and a chicken, the fourth a dog and a donkey, and the fifth a dog and a duck. During training, the classifier will inevitably be subject to interference from irrelevant objects such as mice, geese, chickens, donkeys, and ducks, resulting in a decrease in classification accuracy. If we can identify these irrelevant objectsâ€”the mice, geese, chickens, donkeys, and ducksâ€”and eliminate their corresponding features, it is possible to improve the accuracy of the cat-and-dog classifier.

## 2. Soft Thresholding

**Soft thresholding is a core step in many signal denoising algorithms. It eliminates features whose absolute values are lower than a certain threshold and shrinks features whose absolute values are higher than this threshold towards zero.** It can be implemented using the following formula:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

The derivative of the soft thresholding output with respect to the input is:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

As shown above, the derivative of soft thresholding is either 1 or 0. This property is identical to that of the ReLU activation function. Therefore, soft thresholding can also reduce the risk of deep learning algorithms encountering gradient vanishing and gradient exploding.

**In the soft thresholding function, the setting of the threshold must satisfy two conditions: first, the threshold must be a positive number; second, the threshold cannot exceed the maximum value of the input signal, otherwise the output will be entirely zero.**

**Additionally, it is preferable for the threshold to satisfy a third condition: each sample should have its own independent threshold based on its noise content.**

This is because the noise content often varies among samples. For example, it is common within the same dataset for Sample A to contain less noise while Sample B contains more noise. In this case, when performing soft thresholding in a denoising algorithm, Sample A should utilize a smaller threshold, whereas Sample B should utilize a larger threshold. Although these features and thresholds lose their explicit physical definitions in deep neural networks, the basic underlying logic remains the same. In other words, each sample should have its own independent threshold determined by its specific noise content.

## 3. Attention Mechanism

Attention mechanisms are relatively easy to understand in the field of computer vision. The visual systems of animals can distinguish targets by rapidly scanning the entire area, subsequently focusing attention on the target object to extract more details while suppressing irrelevant information. For specifics, please refer to literature regarding attention mechanisms.

The Squeeze-and-Excitation Network (SENet) represents a relatively new deep learning method utilizing attention mechanisms. Across different samples, the contribution of different feature channels to the classification task often varies. SENet employs a small sub-network to obtain a set of weights and then multiplies these weights by the features of the respective channels to adjust the magnitude of the features in each channel. This process can be viewed as applying varying levels of attention to different feature channels.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

In this approach, every sample possesses its own independent set of weights. In other words, the weights for any two arbitrary samples are different. In SENet, the specific path for obtaining weights is "Global Pooling â†’ Fully Connected Layer â†’ ReLU Function â†’ Fully Connected Layer â†’ Sigmoid Function."

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. Soft Thresholding with Deep Attention Mechanism

The Deep Residual Shrinkage Network draws inspiration from the aforementioned SENet sub-network structure to implement soft thresholding under a deep attention mechanism. Through the sub-network (indicated within the red box), a set of thresholds can be learned to apply soft thresholding to each feature channel.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

In this sub-network, the absolute values of all features in the input feature map are first calculated. Then, through global average pooling and averaging, a feature is obtained, denoted as A. In the other path, the feature map after global average pooling is input into a small fully connected network. This fully connected network uses the Sigmoid function as its final layer to normalize the output between 0 and 1, yielding a coefficient denoted as Î±. The final threshold can be expressed as Î±Ã—A. Therefore, the threshold is the product of a number between 0 and 1 and the average of the absolute values of the feature map. **This method ensures that the threshold is not only positive but also not excessively large.**

**Furthermore, different samples result in different thresholds. Consequently, to a certain extent, this can be interpreted as a specialized attention mechanism: it identifies features irrelevant to the current task, transforms them into values close to zero via two convolutional layers, and sets them to zero using soft thresholding; alternatively, it identifies features relevant to the current task, transforms them into values far from zero via two convolutional layers, and preserves them.**

Finally, by stacking a certain number of basic modules along with convolutional layers, batch normalization, activation functions, global average pooling, and fully connected output layers, the complete Deep Residual Shrinkage Network is constructed.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Generalization Capability

The Deep Residual Shrinkage Network is, in fact, a general feature learning method. This is because, in many feature learning tasks, samples more or less contain some noise as well as irrelevant information. This noise and irrelevant information may affect the performance of feature learning. For example:

In image classification, if an image simultaneously contains many other objects, these objects can be understood as "noise." The Deep Residual Shrinkage Network may be able to utilize the attention mechanism to notice this "noise" and then employ soft thresholding to set the features corresponding to this "noise" to zero, thereby potentially improving image classification accuracy.

In speech recognition, specifically in relatively noisy environments such as conversational settings by a roadside or inside a factory workshop, the Deep Residual Shrinkage Network may improve speech recognition accuracy, or at the very least, offer a methodology capable of improving speech recognition accuracy.

## 6. Academic Impact

This paper has received over 1,400 citations on Google Scholar.

According to conservative estimates, Deep Residual Shrinkage Networks (DRSN) have been utilized in more than 1,000 publications. These works have either directly applied or improved upon the network across a wide range of fields, including mechanical engineering, electric power, computer vision, healthcare, speech processing, text analysis, radar, and remote sensing.

## 7. Paper Info

<div style="background-color: #fff; border: 1px solid #e1e4e8; border-radius: 6px; padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-bottom: 20px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;">
    
    <!-- 1. è®ºæ–‡æ ‡é¢˜ -->
    <div style="font-size: 18px; font-weight: 700; color: #0366d6; margin-bottom: 8px; line-height: 1.4;">
        <a href="https://ieeexplore.ieee.org/document/8850096" target="_blank" style="text-decoration: none; color: inherit; transition: color 0.2s;">
            Deep Residual Shrinkage Networks for Fault Diagnosis
        </a>
    </div>

    <!-- 2. ä½œè€…åˆ—è¡¨ -->
    <div style="font-size: 14px; color: #24292e; margin-bottom: 6px; line-height: 1.5;">
        <strong>Minghang Zhao</strong>, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht
    </div>

    <!-- 3. æœŸåˆŠä¿¡æ¯ -->
    <div style="font-size: 14px; color: #586069; font-style: italic; margin-bottom: 15px; line-height: 1.5;">
        IEEE Transactions on Industrial Informatics, vol. 16, no. 7, pp. 4681-4690, July 2020.
    </div>

    <!-- 4. æ“ä½œæŒ‰é’®è¡Œ (Mobile & Desktop Perfect) -->
    <div style="display: flex; gap: 8px; flex-wrap: wrap; align-items: center;">
        
        <!-- IEEE å®˜æ–¹é“¾æ¥ -->
        <a href="https://ieeexplore.ieee.org/document/8850096" target="_blank" style="text-decoration: none;">
            <div style="background: #00629B; color: white; padding: 5px 12px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                IEEE Xplore
            </div>
        </a>

        <!-- PDF ä¸‹è½½ -->
        <a href="https://zhao62.github.io/assets/pdf/Zhao2020DRSN.pdf" target="_blank" style="text-decoration: none;">
            <div style="background: #cb2431; color: white; padding: 5px 12px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                Download PDF
            </div>
        </a>

        <!-- è°·æ­Œå­¦æœ¯ -->
        <a href="https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en" target="_blank" style="text-decoration: none;">
            <div style="background: #fff; color: #24292e; border: 1px solid #d1d5da; padding: 4px 11px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                Google Scholar
            </div>
        </a>

        <!-- å¤åˆ¶çº¯æ–‡æœ¬æŒ‰é’® -->
        <button id="btn-copy-cite-text-zhao2020" onclick="copyCitationText('citation-content-zhao2020', 'btn-copy-cite-text-zhao2020')" style="background: #f6f8fa; color: #24292e; border: 1px solid #d1d5da; padding: 4px 11px; border-radius: 4px; font-size: 12px; font-weight: 600; cursor: pointer; outline: none; font-family: inherit; line-height: normal;">
            Copy Citation
        </button>
    </div>

    <!-- éšè—çš„çº¯æ–‡æœ¬æº -->
    <div id="citation-content-zhao2020" style="display: none;">M. Zhao, S. Zhong, X. Fu, B. Tang, and M. Pecht, "Deep Residual Shrinkage Networks for Fault Diagnosis," IEEE Transactions on Industrial Informatics, vol. 16, no. 7, pp. 4681-4690, 2020.</div>
</div>

<script>
function copyCitationText(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        var originalText = btn.innerText;
        // ä½¿ç”¨ textContent å…¼å®¹æ€§æ›´å¥½
        btn.textContent = 'Copied! âœ“';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.textContent = 'Copy Citation';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed', err);
        // å¦‚æœå¤±è´¥ï¼Œä¸åšä»»ä½•æ“ä½œï¼Œæˆ–è€…å¯ä»¥ alert
    }

    // ä¼˜å…ˆä½¿ç”¨ç°ä»£ Clipboard API
    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopyText(content);
        });
    } else {
        fallbackCopyText(content);
    }

    // ç»ˆæå…¼å®¹ï¼šä½¿ç”¨ execCommand
    function fallbackCopyText(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            
            // å…³é”®ä¼˜åŒ–ï¼šé˜²æ­¢æ‰‹æœºç«¯å¼¹å‡ºé”®ç›˜
            textArea.setAttribute('readonly', '');
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            
            // é’ˆå¯¹ iOS çš„ç‰¹æ®Šå¤„ç†
            var range = document.createRange();
            range.selectNodeContents(textArea);
            var selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            textArea.setSelectionRange(0, 999999);

            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            
            if (successful) handleSuccess();
            else handleError('execCommand fail');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>

## 8. BibTeX

<!-- ç»ˆæå…¼å®¹ç‰ˆ BibTeX å— -->
<div class="bibtex-container" style="border: 1px solid #e1e4e8; border-radius: 6px; background-color: #f6f8fa; margin-bottom: 16px; max-width: 100%;">
    
    <!-- é¡¶éƒ¨å·¥å…·æ  -->
    <div style="display: flex; justify-content: space-between; align-items: center; padding: 8px 12px; border-bottom: 1px solid #e1e4e8; background-color: #ffffff; border-radius: 6px 6px 0 0;">
        <span style="font-size: 13px; font-weight: 600; color: #586069; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;">
            BibTeX
        </span>
        <button id="copy-btn-zhao2020" onclick="copyBibtexStable('bibtex-content-zhao2020', 'copy-btn-zhao2020')" style="border: 1px solid #d1d5da; background-color: #fff; color: #24292e; border-radius: 4px; padding: 4px 10px; font-size: 12px; cursor: pointer; font-weight: 600; line-height: 20px; transition: all 0.2s ease; outline: none;">
            Copy
        </button>
    </div>

    <!-- ä»£ç åŒºåŸŸ -->
    <div style="overflow-x: auto; padding: 15px;">
<!-- æ³¨æ„ï¼šè¿™é‡Œçš„ç¬¬ä¸€è¡Œå·²ç»æ”¹æˆäº† @article{Zhao2020DRSN, -->
<pre id="bibtex-content-zhao2020" style="margin: 0; font-family: SFMono-Regular, Consolas, 'Liberation Mono', Menlo, monospace; font-size: 13px; line-height: 1.45; color: #24292e; white-space: pre;">@article{Zhao2020DRSN,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}</pre>
    </div>
</div>

<script>
/**
 * é«˜å…¼å®¹æ€§å¤åˆ¶å‡½æ•°
 */
function copyBibtexStable(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        btn.innerText = 'Copied! âœ“';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.innerText = 'Copy';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed:', err);
        alert('Press Ctrl+C to copy');
    }

    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopy(content);
        });
    } else {
        fallbackCopy(content);
    }

    function fallbackCopy(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            if (successful) handleSuccess();
            else handleError('execCommand returned false');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>

<!-- ======================================================= -->
<!-- STYLES & SCRIPT (Place this block once)                 -->
<!-- ======================================================= -->
<style>
  /* åŸºç¡€å®¹å™¨ */
  .paper-gallery {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
    color: #24292e;
    line-height: 1.6;
  }
  
  /* è®ºæ–‡å¡ç‰‡æ ·å¼ */
  .paper-card {
    background-color: #fff;
    border: 1px solid #e1e4e8;
    border-radius: 6px;
    padding: 16px;
    margin-bottom: 16px;
    transition: box-shadow 0.2s;
  }
  .paper-card:hover {
    box-shadow: 0 4px 12px rgba(0,0,0,0.08);
  }
  
  /* å·¦ä¾§å½©è‰²è¾¹æ¡†å®šä¹‰ */
  .border-red   { border-left: 4px solid #d73a49; }
  .border-green { border-left: 4px solid #28a745; }
  .border-blue  { border-left: 4px solid #0366d6; }
  .border-purple{ border-left: 4px solid #6f42c1; }
  .border-orange{ border-left: 4px solid #fd8c73; }
  .border-teal  { border-left: 4px solid #17a2b8; } /* ä½ çš„è¦æ±‚2ï¼šé’è‰² */
  .border-darkteal { border-left: 4px solid #138496; }

  /* æ ‡ç­¾æ ·å¼ */
  .paper-badge {
    display: inline-block;
    color: white;
    font-size: 11px;
    font-weight: 700;
    padding: 2px 6px;
    border-radius: 3px;
    margin-bottom: 6px;
    vertical-align: middle;
  }
  
  /* å¼•ç”¨æ–‡æœ¬åŒºåŸŸ */
  .citation-content {
    font-family: "Times New Roman", Times, serif;
    font-size: 16px;
    margin-bottom: 12px;
    word-wrap: break-word; /* é˜²æ­¢æ‰‹æœºç«¯æº¢å‡º */
  }
  .citation-content a {
    color: #0366d6;
    text-decoration: none;
    font-weight: 600;
  }
  .citation-content a:hover {
    text-decoration: underline;
  }

  /* åº•éƒ¨æŒ‰é’®å·¥å…·æ  */
  .action-bar {
    display: flex;
    gap: 8px;
    flex-wrap: wrap; /* å…³é”®ï¼šæ‰‹æœºç«¯æŒ‰é’®è‡ªåŠ¨æ¢è¡Œ */
    margin-top: 10px;
    padding-top: 10px;
    border-top: 1px dashed #e1e4e8;
  }

  /* æŒ‰é’®é€šç”¨æ ·å¼ */
  .btn-action {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    padding: 4px 10px;
    font-size: 12px;
    font-weight: 600;
    border-radius: 4px;
    cursor: pointer;
    text-decoration: none;
    transition: all 0.2s;
    user-select: none;
    line-height: 1.4;
  }
  
  /* PDF æŒ‰é’® - ä¿®æ”¹ç‰ˆï¼šä½¿ç”¨æ²‰ç¨³çš„å­¦æœ¯è“ */
  .btn-pdf {
    background-color: #f1f8ff;  /* ææµ…çš„è“è‰²èƒŒæ™¯ï¼Œä¸åˆºçœ¼ */
    color: #0366d6;             /* ç»å…¸çš„é“¾æ¥è“å­—ä½“ */
    border: 1px solid #c8e1ff;  /* æµ…è“è‰²è¾¹æ¡† */
  }
  
  /* é¼ æ ‡æ‚¬åœæ•ˆæœ */
  .btn-pdf:hover {
    background-color: #0366d6;  /* æ‚¬åœæ—¶å˜æ·±è‰²ï¼Œæä¾›äº¤äº’æ„Ÿ */
    color: #fff;                /* å­—ä½“å˜ç™½ */
    border-color: #0366d6;
  }

  /* å¤åˆ¶æŒ‰é’® */
  .btn-copy {
    background-color: #fafbfc;
    color: #24292e;
    border: 1px solid #d1d5da;
  }
  .btn-copy:hover {
    background-color: #f3f4f6;
    border-color: #24292e;
  }
  .btn-copy.copied {
    color: #22863a;
    border-color: #22863a;
    background-color: #f0fff4;
  }
</style>

<script>
/**
 * å…¼å®¹æ€§æå¥½çš„å¤åˆ¶å‡½æ•°
 * è‡ªåŠ¨å¤„ç† iOS/Android/Desktop å·®å¼‚
 */
function copyCitation(elementId, btnElement) {
  // 1. è·å–çº¯æ–‡æœ¬å¼•ç”¨ï¼ˆç§»é™¤HTMLæ ‡ç­¾ï¼‰
  var text = document.getElementById(elementId).innerText;
  
  // 2. æˆåŠŸåçš„å›è°ƒUIå¤„ç†
  function markSuccess() {
    var originalText = btnElement.innerHTML;
    btnElement.innerHTML = 'âœ“ Copied';
    btnElement.classList.add('copied');
    setTimeout(function() {
      btnElement.innerHTML = originalText;
      btnElement.classList.remove('copied');
    }, 2000);
  }

  // 3. å°è¯•ä½¿ç”¨ç°ä»£ API (Clipboard API)
  if (navigator.clipboard && window.isSecureContext) {
    navigator.clipboard.writeText(text).then(markSuccess).catch(function(err) {
      fallbackCopy(text);
    });
  } else {
    // 4. å›é€€åˆ°è€å¼æ–¹æ³• (execCommand) - å…¼å®¹æ—§æ‰‹æœº
    fallbackCopy(text);
  }

  function fallbackCopy(text) {
    var textArea = document.createElement("textarea");
    textArea.value = text;
    // é¿å…æ‰‹æœºå¼¹å‡ºé”®ç›˜
    textArea.style.position = "fixed";
    textArea.style.left = "-9999px"; 
    textArea.setAttribute('readonly', '');
    document.body.appendChild(textArea);
    
    // é€‰ä¸­å¹¶å¤åˆ¶
    textArea.select();
    textArea.setSelectionRange(0, 99999); /* For mobile devices */
    
    try {
      var successful = document.execCommand('copy');
      if (successful) markSuccess();
    } catch (err) {
      console.error('Fallback copy failed', err);
      alert('Copy failed. Please select text manually.');
    }
    document.body.removeChild(textArea);
  }
}
</script>

<!-- ======================================================= -->
<!-- STYLES & SCRIPT (æ ·å¼å·²ä¸¥æ ¼å¯¹é½æ‚¨çš„å‚è€ƒä»£ç )              -->
<!-- ======================================================= -->
<style>
  /* åŸºç¡€å®¹å™¨ */
  .paper-gallery {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
    color: #24292e;
    line-height: 1.6;
  }
  
  /* è®ºæ–‡å¡ç‰‡æ ·å¼ */
  .paper-card {
    background-color: #fff;
    border: 1px solid #e1e4e8;
    border-radius: 6px;
    padding: 16px;
    margin-bottom: 16px;
    transition: box-shadow 0.2s;
  }
  .paper-card:hover {
    box-shadow: 0 4px 12px rgba(0,0,0,0.08);
  }
  
  /* å·¦ä¾§å½©è‰²è¾¹æ¡†å®šä¹‰ */
  .border-red   { border-left: 4px solid #d73a49; }
  .border-green { border-left: 4px solid #28a745; }
  .border-blue  { border-left: 4px solid #0366d6; }
  .border-purple{ border-left: 4px solid #6f42c1; }
  .border-orange{ border-left: 4px solid #fd8c73; }
  .border-teal  { border-left: 4px solid #17a2b8; }
  .border-darkteal { border-left: 4px solid #138496; }

  /* æ ‡ç­¾æ ·å¼ */
  .paper-badge {
    display: inline-block;
    color: white;
    font-size: 11px;
    font-weight: 700;
    padding: 2px 6px;
    border-radius: 3px;
    margin-bottom: 6px;
    vertical-align: middle;
  }
  
  /* å¼•ç”¨æ–‡æœ¬åŒºåŸŸ */
  .citation-content {
    font-family: "Times New Roman", Times, serif;
    font-size: 16px;
    margin-bottom: 12px;
    word-wrap: break-word;
  }
  .citation-content a {
    color: #0366d6;
    text-decoration: none;
    font-weight: 600;
  }
  .citation-content a:hover {
    text-decoration: underline;
  }

  /* åº•éƒ¨æŒ‰é’®å·¥å…·æ  */
  .action-bar {
    display: flex;
    gap: 8px;
    flex-wrap: wrap;
    margin-top: 10px;
    padding-top: 10px;
    border-top: 1px dashed #e1e4e8;
    align-items: center;
  }

  /* é€šç”¨æŒ‰é’®åŸºç¡€æ ·å¼ */
  .btn-action {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    padding: 5px 12px; /* æ‚¨çš„å‚è€ƒå€¼ */
    font-size: 12px;
    font-weight: 600;
    border-radius: 4px;
    cursor: pointer;
    text-decoration: none;
    line-height: normal;
    font-family: inherit;
    transition: all 0.2s;
    user-select: none;
    white-space: nowrap;
  }
  
  /* PDF æŒ‰é’® - ä¸¥æ ¼åŒ¹é…å‚è€ƒä»£ç  (#cb2431) */
  .btn-pdf {
    background-color: #cb2431; /* æ‚¨çš„å‚è€ƒçº¢è‰² */
    color: white !important;
    border: none;
  }
  .btn-pdf:hover {
    background-color: #a31c26; /* æ‚¬åœç¨å¾®å˜æ·± */
    color: white;
  }

  /* å¤åˆ¶æŒ‰é’® - ä¸¥æ ¼åŒ¹é…å‚è€ƒä»£ç  */
  .btn-copy {
    background-color: #f6f8fa; /* æ‚¨çš„å‚è€ƒæµ…ç° */
    color: #24292e;
    border: 1px solid #d1d5da;
    padding: 4px 11px; /* æ‚¨çš„å‚è€ƒpaddingç•¥æœ‰ä¸åŒï¼Œå·²å¯¹é½ */
  }
  .btn-copy:hover {
    background-color: #f3f4f6;
    border-color: #24292e;
  }
  .btn-copy.copied {
    color: #22863a;
    border-color: #22863a;
    background-color: #f0fff4;
  }
</style>

<script>
/**
 * é«˜å…¼å®¹æ€§å¤åˆ¶å‡½æ•° (åŸºäºæ‚¨æä¾›çš„é€»è¾‘ä¼˜åŒ–)
 */
function copyCitation(elementId, btnElement) {
  var text = document.getElementById(elementId).innerText;
  
  function markSuccess() {
    var originalText = btnElement.innerText;
    btnElement.innerText = 'Copied! âœ“';
    btnElement.style.color = '#22863a';
    btnElement.style.borderColor = '#22863a';
    setTimeout(function() {
      btnElement.innerText = originalText;
      btnElement.style.color = '#24292e';
      btnElement.style.borderColor = '#d1d5da';
    }, 2000);
  }

  if (navigator.clipboard && window.isSecureContext) {
    navigator.clipboard.writeText(text).then(markSuccess).catch(function() {
      fallbackCopy(text);
    });
  } else {
    fallbackCopy(text);
  }

  function fallbackCopy(text) {
    var textArea = document.createElement("textarea");
    textArea.value = text;
    textArea.style.position = "fixed";
    textArea.style.left = "-9999px"; 
    textArea.setAttribute('readonly', '');
    document.body.appendChild(textArea);
    textArea.focus();
    textArea.select();
    
    // iOS å…¼å®¹å¤„ç†
    var range = document.createRange();
    range.selectNodeContents(textArea);
    var selection = window.getSelection();
    selection.removeAllRanges();
    selection.addRange(range);
    textArea.setSelectionRange(0, 999999);

    try {
      var successful = document.execCommand('copy');
      if (successful) markSuccess();
    } catch (err) {
      console.error('Copy failed', err);
    }
    document.body.removeChild(textArea);
  }
}
</script>


<!-- ======================================================= -->
<!-- CONTENT SECTION STARTS HERE                             -->
<!-- ======================================================= -->

## 9. Research Gallery & Latest Works

If you are interested in **Deep Residual Shrinkage Networks**, you might also find our other research topics useful. Below is a selected list of our publications.

<div class="paper-gallery">

  <!-- ======================================================= -->
  <!-- GROUP 1: Imbalanced Data & Few-Shot Learning -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #0366d6; padding-bottom: 10px; margin-top: 40px;">
    ğŸš€ Imbalanced Data & Small Sample Learning
  </h3>

  <!-- Paper: AEI 2025 -->
  <div class="paper-card border-red">
    <span class="paper-badge" style="background: #d73a49;">NEW 2025</span>
    <div class="citation-content" id="cite-aei2025">
      H. Wu, S. Zhong, M. Zhao, et al. 
      <a href="https://doi.org/10.1016/j.aei.2024.103297" target="_blank">
        Continual contrastive reinforcement learning: Towards stronger agent for environment-aware fault diagnosis of aero-engines through long-term optimization under highly imbalance scenarios
      </a>. 
      <i>Advanced Engineering Informatics</i>, 2025, 65(C): 103297.
    </div>
    <div class="action-bar">
      <!-- REPLACE href="#" WITH YOUR PDF LINK -->
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-aei2025', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: MSSP 2024 -->
  <div class="paper-card border-green">
    <span class="paper-badge" style="background: #28a745;">MSSP</span>
    <div class="citation-content" id="cite-mssp2024">
      S. Fu, L. Lin, Y. Wang, et al. 
      <a href="https://doi.org/10.1016/j.ymssp.2024.111115" target="_blank">
        High imbalance fault diagnosis of aviation hydraulic pump based on data augmentation via local wavelet similarity fusion
      </a>. 
      <i>Mechanical Systems and Signal Processing</i>, 2024, 209: 111115.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-mssp2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Measurement 2024 -->
  <div class="paper-card border-blue">
    <div class="citation-content" id="cite-meas2024">
      B. Zhong, M. Zhao, L. Wang, et al. 
      <a href="https://doi.org/10.1016/j.measurement.2024.114929" target="_blank">
        DCSN: Focusing on hard samples mining in small-sample fault diagnosis of marine engine
      </a>. 
      <i>Measurement</i>, 2024, 235: 114929.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-meas2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: ESWA 2024 -->
  <div class="paper-card border-blue">
    <div class="citation-content" id="cite-eswa2024">
      D. Liu, S. Zhong, L. Lin, et al. 
      <a href="https://doi.org/10.1016/j.eswa.2023.122023" target="_blank">
        Feature-level SMOTE: Augmenting Fault Samples in Learnable Feature Space for Imbalanced Fault Diagnosis of Gas Turbines
      </a>. 
      <i>Expert Systems with Applications</i>, 2024, 238(F): 122023.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-eswa2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: IEEE TIM 2022 -->
  <div class="paper-card border-blue">
    <div class="citation-content" id="cite-tim2022">
      M. Zhao, X. Fu, Y. Zhang, et al. 
      <a href="https://doi.org/10.1109/TIM.2021.3130300" target="_blank">
        Data augmentation via randomized wavelet expansion and its application in few-shot fault diagnosis of aviation hydraulic pumps
      </a>. 
      <i>IEEE Transactions on Instrumentation and Measurement</i>, 2022, 71: 3503213.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-tim2022', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: AEI 2022 -->
  <div class="paper-card border-blue">
    <div class="citation-content" id="cite-aei2022">
      M. Zhao, X. Fu, Y. Zhang, et al. 
      <a href="https://doi.org/10.1016/j.aei.2021.101535" target="_blank">
        Highly imbalanced fault diagnosis of mechanical systems based on wavelet packet distortion and convolutional neural networks
      </a>. 
      <i>Advanced Engineering Informatics</i>, 2022, 51: 101535.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-aei2022', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: CII 2023 -->
  <div class="paper-card border-blue">
    <div class="citation-content" id="cite-cii2023">
      D. Liu, S. Zhong, L. Lin, et al. 
      <a href="https://doi.org/10.1016/j.compind.2023.103972" target="_blank">
        Deep attention SMOTE: Data augmentation with a learnable interpolation factor for imbalanced anomaly detection of gas turbines
      </a>. 
      <i>Computers in Industry</i>, 2023, 151: 103972.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-cii2023', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: AEI 2022 (Cluster) -->
  <div class="paper-card border-blue">
    <div class="citation-content" id="cite-aei2022cluster">
      D. Liu, S. Zhong, L. Lin, et al. 
      <a href="https://doi.org/10.1016/j.aei.2022.101725" target="_blank">
        Highly imbalanced fault diagnosis of gas turbines via clustering-based downsampling and deep siamese self-attention network
      </a>. 
      <i>Advanced Engineering Informatics</i>, 2022, 54: 101725.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-aei2022cluster', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: CII 2022 -->
  <div class="paper-card border-blue">
    <div class="citation-content" id="cite-cii2022">
      L. Meng, M. Zhao, Z. Cui, et al. 
      <a href="https://doi.org/10.1016/j.compind.2021.103557" target="_blank">
        Empirical mode reconstruction: Preserving intrinsic components in data augmentation for intelligent fault diagnosis of civil aviation hydraulic pumps
      </a>. 
      <i>Computers in Industry</i>, 2022, 134: 103557.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-cii2022', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Neurocomputing 2025 -->
  <div class="paper-card border-blue">
    <div class="citation-content" id="cite-neuro2025">
      H. Wu, S. Zhong, M. Zhao, et al. 
      <a href="https://doi.org/10.1016/j.neucom.2024.130876" target="_blank">
        CUR-Estimator: Towards reliable missing data imputation for aero-engine degradation process
      </a>. 
      <i>Neurocomputing</i>, 2025, 649: 130876.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-neuro2025', this)">Copy Citation</button>
    </div>
  </div>


  <!-- ======================================================= -->
  <!-- GROUP 2: Battery Health & RUL Prediction -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #6f42c1; padding-bottom: 10px; margin-top: 40px;">
    ğŸ”‹ Battery Health (SOH) & RUL Prediction
  </h3>

  <!-- Paper: JPS 2025 -->
  <div class="paper-card border-purple">
    <span class="paper-badge" style="background: #d73a49;">NEW 2025</span>
    <div class="citation-content" id="cite-jps2025">
      X. Li, M. Zhao, S. Zhong, et al. 
      <a href="https://doi.org/10.1016/j.jpowsour.2025.237503" target="_blank">
        Deep transfer learning enabled online state-of-health estimation of lithium-ion batteries under small samples across different cathode materials, ambient temperature and charge-discharge protocols
      </a>. 
      <i>Journal of Power Sources</i>, 2025, 650: 237503.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-jps2025', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Energy 2024 -->
  <div class="paper-card border-purple">
    <div class="citation-content" id="cite-energy2024">
      X. Li, M. Zhao, S. Zhong, et al. 
      <a href="https://doi.org/10.1016/j.energy.2024.134030" target="_blank">
        BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator
      </a>. 
      <i>Energy</i>, 2024, 313: 134030.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-energy2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: RESS 2021 -->
  <div class="paper-card border-purple">
    <div class="citation-content" id="cite-ress2021">
      S. Fu, Y. Zhang, L. Lin, et al. 
      <a href="https://doi.org/10.1016/j.ress.2021.108012" target="_blank">
        Deep residual LSTM with domain-invariance for remaining useful life prediction across domains
      </a>. 
      <i>Reliability Engineering & System Safety</i>, 2021, 216: 108012.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-ress2021', this)">Copy Citation</button>
    </div>
  </div>


  <!-- ======================================================= -->
  <!-- GROUP 3: Advanced Networks & Attention -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #fd8c73; padding-bottom: 10px; margin-top: 40px;">
    ğŸ—ï¸ Advanced Deep Architectures & Attention
  </h3>

  <!-- Paper: SHM 2024 -->
  <div class="paper-card border-orange">
    <div class="citation-content" id="cite-shm2024">
      B. Zhong, M. Zhao, S. Zhong, et al. 
      <a href="https://doi.org/10.1177/14759217231221532" target="_blank">
        Deep Exponential Excitation Networks: Towards Stronger Attention Mechanism for Weak Fault Diagnosis
      </a>. 
      <i>Structural Health Monitoring</i>, 2024, 23(6): 3850-3866.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-shm2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: APReLU -->
  <div class="paper-card border-orange">
    <div class="citation-content" id="cite-aprelu">
      M. Zhao, S. Zhong, X. Fu, et al. 
      <a href="https://doi.org/10.1109/TIE.2020.2975482" target="_blank">
        Deep residual networks with adaptively parametric rectifier linear units for fault diagnosis
      </a>. 
      <i>IEEE Transactions on Industrial Electronics</i>, 2021, 68(3): 2587-2597.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-aprelu', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Measurement 2022 -->
  <div class="paper-card border-orange">
    <div class="citation-content" id="cite-meas2022">
      B. Zhong, M. Zhao, S. Zhong, et al. 
      <a href="https://doi.org/10.1016/j.measurement.2022.111433" target="_blank">
        Mechanical compound fault diagnosis via suppressing intra-class dispersions: A deep progressive shrinkage perspective
      </a>. 
      <i>Measurement</i>, 2022, 199: 111433.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-meas2022', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: NCA 2023 -->
  <div class="paper-card border-orange">
    <div class="citation-content" id="cite-nca2023">
      D. Liu, S. Zhong, L. Lin, et al. 
      <a href="https://doi.org/10.1007/s00521-022-08083-w" target="_blank">
        CSiamese: a novel semi-supervised anomaly detection framework for gas turbines via reconstruction similarity
      </a>. 
      <i>Neural Computing and Applications</i>, 2023, 35: 16403â€“16427.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-nca2023', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: QREI 2022 -->
  <div class="paper-card border-orange">
    <div class="citation-content" id="cite-qrei2022">
      S. Zhong, D. Liu, L. Lin, et al. 
      <a href="https://doi.org/10.1002/qre.3116" target="_blank">
        CAE-WANN: A novel anomaly detection method for gas turbines via search space extension
      </a>. 
      <i>Quality and Reliability Engineering International</i>, 2022, 38(6): 3116-3134.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-qrei2022', this)">Copy Citation</button>
    </div>
  </div>


  <!-- ======================================================= -->
  <!-- GROUP 4: Classic Wavelet & Simulation -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #17a2b8; padding-bottom: 10px; margin-top: 40px;">
    âš™ï¸ Wavelet Fusion & Physics-Informed
  </h3>

  <!-- Paper: IEEE TIE 2019 -->
  <div class="paper-card border-darkteal">
    <span class="paper-badge" style="background: #138496;">Highly Cited</span>
    <div class="citation-content" id="cite-tie2019">
      M. Zhao, M. Kang, B. Tang, M. Pecht. 
      <a href="https://doi.org/10.1109/TIE.2018.2863271" target="_blank">
        Multiple wavelet coefficients fusion in deep residual networks for fault diagnosis
      </a>. 
      <i>IEEE Transactions on Industrial Electronics</i>, 2019, 66(6): 4696-4706.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-tie2019', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: IEEE TIE 2018 -->
  <div class="paper-card border-teal">
    <div class="citation-content" id="cite-tie2018">
      M. Zhao, M. Kang, B. Tang, M. Pecht. 
      <a href="https://doi.org/10.1109/TIE.2017.2764517" target="_blank">
        Deep residual networks with dynamically weighted wavelet coefficients for fault diagnosis of planetary gearboxes
      </a>. 
      <i>IEEE Transactions on Industrial Electronics</i>, 2018, 65(5): 4290-4300.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-tie2018', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Measurement 2020 -->
  <div class="paper-card border-teal">
    <div class="citation-content" id="cite-meas2020">
      M. Zhao, B. Tang, L. Deng, M. Pecht. 
      <a href="https://doi.org/10.1016/j.measurement.2019.107331" target="_blank">
        Multiple wavelet regularized deep residual networks for fault diagnosis
      </a>. 
      <i>Measurement</i>, 2020, 152: 107331.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-meas2020', this)">Copy Citation</button>
    </div>
  </div>
  
  <!-- Paper: Measurement 2025 -->
  <div class="paper-card border-teal">
    <div class="citation-content" id="cite-meas2025">
      C. Luo, M. Zhao, X. Fu, et al. 
      <a href="https://doi.org/10.1016/j.measurement.2025.117252" target="_blank">
        Thermodynamic simulation-assisted random forest: Towards explainable fault diagnosis of combustion chamber components of marine diesel engines
      </a>. 
      <i>Measurement</i>, 2025, 251: 117252.
    </div>
    <div class="action-bar">
      <a href="#" class="btn-action btn-pdf" target="_blank">Download PDF</a>
      <button class="btn-action btn-copy" onclick="copyCitation('cite-meas2025', this)">Copy Citation</button>
    </div>
  </div>

</div>

<div style="text-align: center; margin-top: 40px; margin-bottom: 40px;">
  <a href="https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en" target="_blank" style="background: #0366d6; color: white; padding: 12px 24px; border-radius: 6px; text-decoration: none; font-weight: bold; font-size: 16px; box-shadow: 0 4px 6px rgba(3, 102, 214, 0.2); transition: transform 0.2s; display: inline-block;">
    View All 100+ Publications on Google Scholar
  </a>
</div>
