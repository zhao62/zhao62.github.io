---
layout: post
title: "<div style='text-align: center; direction: rtl;'>Deep Residual Shrinkage Network: یک روش هوش مصنوعی برای داده‌های با نویز شدید (Highly Noisy Data)</div>"
subtitle: "<div style='text-align: center; direction: ltr;'>Deep Residual Shrinkage Network: An Artificial Intelligence Method for Highly Noisy Data</div>"
date: 2025-12-23
author: "Minghang Zhao, Harbin Institute of Technology"
tags: [Deep Learning, AI]
mathjax: true
description: "شبکه Deep Residual Shrinkage Network یک نسخه بهبودیافته از Deep Residual Network است. در اصل، این شبکه تلفیقی از Deep Residual Network، مکانیزم‌های توجه (Attention mechanisms) و توابع Soft thresholding است."
lang: fa
dir: rtl
categories: fa
ref: drsn-2025
buttons:
  - type: hit
    text: HIT Homepage
    url: https://homepage.hit.edu.cn/zhaominghang?lang=zh
  - type: scholar
    text: Google Scholar
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
  - type: ieee
    text: IEEE Paper
    url: https://ieeexplore.ieee.org/document/8850096
  - type: github
    text: GitHub Code
    url: https://github.com/zhao62/Deep-Residual-Shrinkage-Networks
  - type: citation
    text: "Citations: 1400+"
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
---

<!-- CSS Styling -->
<style>
  /* 1. Force Headers Right */
  h1, h2, h3, h4, h5, h6 { text-align: right !important; }
  
  /* 2. Force Lists Right */
  ul, ol { text-align: right !important; direction: rtl !important; padding-right: 40px; padding-left: 0; }

  /* 3. Force Code LTR */
  pre, code { text-align: left !important; direction: ltr !important; }
  
  /* 4. Force References LTR */
  .references-ltr { text-align: left !important; direction: ltr !important; }
</style>

<!-- Main Content Wrapper -->
<div dir="rtl" markdown="1" style="text-align: right; direction: rtl; font-family: 'Sakkal Majalla', 'Traditional Arabic', serif; font-size: 1.1em;">

<strong>شبکه Deep Residual Shrinkage Network یک نسخه بهبودیافته از Deep Residual Network است. در اصل، این شبکه تلفیقی از Deep Residual Network، مکانیزم‌های توجه (Attention mechanisms) و توابع Soft thresholding است.</strong>

<strong>تا حدودی، اصول کاری Deep Residual Shrinkage Network را می‌توان این‌گونه درک کرد: این شبکه از Attention mechanisms استفاده می‌کند تا Featureهای غیرمهم را شناسایی کرده و با استفاده از توابع Soft thresholding آن‌ها را صفر کند؛ و برعکس، Featureهای مهم را شناسایی و حفظ نماید. این فرآیند توانایی Deep Neural Network را در استخراج Featureهای مفید از سیگنال‌های حاوی نویز ارتقا می‌دهد.</strong>

## 1. انگیزه تحقیق (Research Motivation)

<strong>نخست، هنگام طبقه‌بندی نمونه‌ها (Samples)، وجود نویز—مانند Gaussian noise، Pink noise و Laplacian noise—اجتناب‌ناپذیر است.</strong> به بیان وسیع‌تر، نمونه‌ها اغلب حاوی اطلاعاتی هستند که با Task طبقه‌بندی فعلی نامرتبط‌اند، که این اطلاعات نیز می‌توانند به عنوان نویز تفسیر شوند. این نویز ممکن است بر عملکرد طبقه‌بندی تأثیر منفی بگذارد. (لازم به ذکر است که <strong>Soft thresholding</strong> یک گام کلیدی در بسیاری از الگوریتم‌های حذف نویز یا Signal Denoising است.)

برای مثال، در طول یک گفتگو در کنار جاده، صدای ضبط شده ممکن است با صدای بوق ماشین‌ها و چرخ‌ها ترکیب شود. هنگام انجام تشخیص گفتار (Speech Recognition) روی این سیگنال‌ها، نتایج ناگزیر تحت تأثیر این صداهای پس‌زمینه قرار می‌گیرند. از دیدگاه <strong>Deep Learning</strong>، فیچرهای (Features) مربوط به بوق و چرخ‌ها باید در داخل <strong>Deep Neural Network</strong> حذف شوند تا از تأثیر آن‌ها بر نتایج تشخیص گفتار جلوگیری شود.

<strong>دوم، حتی در یک Dataset یکسان، میزان نویز اغلب از یک نمونه به نمونه دیگر متفاوت است.</strong> (این موضوع شباهت‌هایی با <strong>Attention mechanisms</strong> دارد؛ با در نظر گرفتن یک Dataset تصویری به عنوان مثال، مکان شیء هدف ممکن است در تصاویر مختلف متفاوت باشد، و Attention mechanisms می‌توانند روی مکان خاص شیء هدف در هر تصویر تمرکز کنند.)

به عنوان مثال، هنگام آموزش یک Classifier سگ و گربه، ۵ تصویر با برچسب "سگ" را در نظر بگیرید. تصویر اول ممکن است شامل یک سگ و یک موش باشد، دومی یک سگ و یک غاز، سومی یک سگ و یک مرغ، چهارمی یک سگ و یک الاغ، و پنجمی یک سگ و یک اردک. در طول آموزش، Classifier ناگزیر تحت تداخل اشیاء نامرتبط مانند موش، غاز، مرغ، الاغ و اردک قرار می‌گیرد که منجر به کاهش دقت طبقه‌بندی می‌شود. اگر بتوانیم این اشیاء نامرتبط—موش، غاز، مرغ، الاغ و اردک—را شناسایی کرده و Featureهای مربوط به آن‌ها را حذف کنیم، امکان بهبود دقت Classifier سگ و گربه وجود دارد.

## 2. آستانه‌گذاری نرم (Soft Thresholding)

<strong>روش Soft thresholding یک گام اصلی در بسیاری از الگوریتم‌های Signal Denoising است. این روش Featureهایی را که قدر مطلق آن‌ها کمتر از یک آستانه (Threshold) مشخص است حذف می‌کند و Featureهایی را که قدر مطلق آن‌ها بیشتر از این آستانه است، به سمت صفر Shrink (منقبض) می‌کند.</strong> این عمل می‌تواند با استفاده از فرمول زیر پیاده‌سازی شود:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

مشتق خروجی <strong>Soft thresholding</strong> نسبت به ورودی عبارت است از:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

همان‌طور که در بالا نشان داده شد، مشتق <strong>Soft thresholding</strong> یا ۱ است یا ۰. این ویژگی دقیقاً مشابه تابع فعال‌سازی <strong>ReLU</strong> است. بنابراین، <strong>Soft thresholding</strong> همچنین می‌تواند ریسک مواجهه الگوریتم‌های <strong>Deep Learning</strong> با مشکلات <strong>Gradient Vanishing</strong> و <strong>Gradient Exploding</strong> را کاهش دهد.

<strong>در تابع Soft thresholding، تعیین مقدار Threshold باید دو شرط را برآورده کند: اول، Threshold باید یک عدد مثبت باشد؛ دوم، Threshold نمی‌تواند از مقدار ماکزیمم سیگنال ورودی بیشتر باشد، در غیر این صورت خروجی کاملاً صفر خواهد شد.</strong>

<strong>علاوه بر این، بهتر است که Threshold شرط سومی را نیز برآورده کند: هر نمونه (Sample) باید بر اساس محتوای نویز خود، Threshold مستقل و منحصر به فرد خود را داشته باشد.</strong>

دلیل این امر آن است که محتوای نویز اغلب در میان نمونه‌ها متفاوت است. برای مثال، در یک Dataset یکسان رایج است که نمونه A حاوی نویز کمتری باشد در حالی که نمونه B حاوی نویز بیشتری است. در این حالت، هنگام انجام <strong>Soft thresholding</strong> در یک الگوریتم حذف نویز، نمونه A باید از Threshold کوچکتری استفاده کند، در حالی که نمونه B باید از Threshold بزرگتری استفاده نماید. اگرچه در <strong>Deep Neural Network</strong>ها، این Featureها و Thresholdها تعاریف فیزیکی صریح خود را از دست می‌دهند، اما منطق پایه و زیربنایی یکسان باقی می‌ماند. به عبارت دیگر، هر نمونه باید Threshold مستقل خود را داشته باشد که توسط محتوای نویز خاص آن تعیین می‌شود.

## 3. مکانیزم توجه (Attention Mechanism)

مفهوم <strong>Attention mechanisms</strong> در حوزه بینایی ماشین (Computer Vision) نسبتاً قابل درک است. سیستم‌های بینایی حیوانات می‌توانند با اسکن سریع کل منطقه، اهداف را تشخیص دهند و سپس توجه (Attention) را روی شیء هدف متمرکز کنند تا جزئیات بیشتری استخراج کرده و اطلاعات نامرتبط را سرکوب نمایند. برای جزئیات، لطفاً به ادبیات مربوط به <strong>Attention mechanisms</strong> مراجعه کنید.

شبکه Squeeze-and-Excitation Network (SENet) نشان‌دهنده یک روش نسبتاً جدید در <strong>Deep Learning</strong> است که از <strong>Attention mechanisms</strong> استفاده می‌کند. در نمونه‌های مختلف، سهم <strong>Feature Channel</strong>های مختلف در Task طبقه‌بندی اغلب متفاوت است. مدل SENet از یک زیرشبکه (Sub-network) کوچک برای به دست آوردن مجموعه‌ای از وزن‌ها (<strong>Learn a set of weights</strong>) استفاده می‌کند و سپس این وزن‌ها را در Featureهای کانال‌های مربوطه ضرب می‌کند (<strong>Apply weighting to each feature channel</strong>) تا بزرگی Featureها را در هر کانال تنظیم کند. این فرآیند می‌تواند به عنوان اعمال سطوح مختلفی از توجه (Attention) به <strong>Feature Channel</strong>های مختلف در نظر گرفته شود (<strong>Weighting</strong>).

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

در این رویکرد، هر نمونه دارای مجموعه وزن‌های مستقل خود است. به عبارت دیگر، وزن‌ها برای هر دو نمونه‌ی دلخواه، متفاوت هستند. در SENet، مسیر خاص برای به دست آوردن وزن‌ها عبارت است از: "Global Pooling → Fully Connected Layer → ReLU Function → Fully Connected Layer → Sigmoid Function".

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/SENET_en_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. آستانه‌گذاری نرم با مکانیزم توجه عمیق (Soft Thresholding with Deep Attention Mechanism)

شبکه <strong>Deep Residual Shrinkage Network</strong> از ساختار زیرشبکه SENet که در بالا ذکر شد الهام می‌گیرد تا <strong>Soft thresholding</strong> را تحت یک مکانیزم توجه عمیق پیاده‌سازی کند. از طریق این زیرشبکه (که در کادر قرمز نشان داده شده است)، می‌توان مجموعه‌ای از آستانه‌ها را یاد گرفت (<strong>Learn a set of thresholds</strong>) تا <strong>Soft thresholding</strong> را روی هر <strong>Feature Channel</strong> اعمال کرد.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

در این زیرشبکه، ابتدا قدر مطلق تمام Featureها در Feature Map ورودی محاسبه می‌شود. سپس، از طریق Global Average Pooling و میانگین‌گیری، یک Feature به دست می‌آید که با A نشان داده می‌شود. در مسیر دیگر (<strong>Identity path</strong> مربوط به محاسبه آستانه)، Feature Map پس از Global Average Pooling وارد یک شبکه تمام متصل (Fully Connected) کوچک می‌شود. این شبکه کوچک از تابع Sigmoid به عنوان لایه نهایی خود استفاده می‌کند تا خروجی را بین ۰ و ۱ نرمال‌سازی کند و یک ضریب به دست می‌آورد که با α نشان داده می‌شود. آستانه (Threshold) نهایی می‌تواند به صورت α × A بیان شود. بنابراین، Threshold حاصل‌ضربِ یک عدد بین ۰ و ۱ در میانگین قدر مطلق‌های Feature Map است. <strong>این روش تضمین می‌کند که Threshold نه تنها مثبت است، بلکه بیش از حد بزرگ نیز نخواهد بود.</strong>

<strong>علاوه بر این، نمونه‌های مختلف منجر به Thresholdهای متفاوتی می‌شوند. در نتیجه، تا حدودی، این می‌تواند به عنوان یک Attention Mechanism تخصصی تفسیر شود: این مکانیزم Featureهای نامرتبط با Task فعلی را شناسایی می‌کند، آن‌ها را از طریق دو لایه کانولوشن (Convolutional layers) به مقادیر نزدیک به صفر تبدیل می‌کند، و با استفاده از Soft thresholding آن‌ها را صفر می‌کند؛ یا برعکس، Featureهای مرتبط با Task فعلی را شناسایی کرده، آن‌ها را به مقادیری دور از صفر تبدیل می‌کند و آن‌ها را حفظ می‌نماید.</strong>

در نهایت، با پشته‌سازی (Stacking) تعداد مشخصی از ماژول‌های پایه (<strong>Stack many basic modules</strong>) به همراه لایه‌های کانولوشن، <strong>Batch Normalization</strong>، توابع فعال‌سازی، Global Average Pooling و لایه‌های خروجی Fully Connected، ساختار کامل <strong>Deep Residual Shrinkage Network</strong> ساخته می‌شود.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-en/DRSN_en_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. قابلیت تعمیم (Generalization Capability)

شبکه <strong>Deep Residual Shrinkage Network</strong> در واقع یک روش عمومی برای یادگیری ویژگی (Feature Learning) است. دلیل این امر آن است که در بسیاری از وظایف Feature Learning، نمونه‌ها کم و بیش حاوی مقداری نویز و همچنین اطلاعات نامرتبط هستند. این نویز و اطلاعات نامرتبط ممکن است بر عملکرد یادگیری ویژگی تأثیر بگذارند. برای مثال:

در طبقه‌بندی تصویر (Image Classification)، اگر یک تصویر همزمان حاوی اشیاء بسیار دیگری باشد، این اشیاء می‌توانند به عنوان "نویز" درک شوند. <strong>Deep Residual Shrinkage Network</strong> ممکن است بتواند از <strong>Attention mechanism</strong> برای توجه به این "نویز" استفاده کند و سپس <strong>Soft thresholding</strong> را به کار گیرد تا Featureهای مربوط به این "نویز" را صفر کند، و بدین ترتیب پتانسیل بهبود دقت طبقه‌بندی تصویر را دارد.

در تشخیص گفتار (Speech Recognition)، به ویژه در محیط‌های نسبتاً پر سر و صدا مانند محیط گفتگو در کنار جاده یا داخل کارگاه کارخانه، <strong>Deep Residual Shrinkage Network</strong> ممکن است دقت تشخیص گفتار را بهبود بخشد، یا حداقل، متدولوژی‌ای ارائه دهد که قادر به بهبود دقت تشخیص گفتار باشد.

## 6. تأثیر علمی (Academic Impact)

این مقاله بیش از ۱۴۰۰ بار در Google Scholar ارجاع (Citation) شده است.

بر اساس آمار غیررسمی، <strong>Deep Residual Shrinkage Network (DRSN)</strong> در بیش از ۱۰۰۰ مقاله/پژوهش در طیف وسیعی از زمینه‌ها، از جمله مهندسی مکانیک، برق قدرت، بینایی ماشین، مراقبت‌های بهداشتی، گفتار، متن، رادار و سنجش از دور، مستقیماً اعمال شده یا پس از اصلاح به کار گرفته شده است.

## 7. اطلاعات مقاله (Paper Info)

<div class="references-ltr" dir="ltr" style="text-align: left; direction: ltr;">

Minghang Zhao, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht, Deep residual shrinkage networks for fault diagnosis, IEEE Transactions on Industrial Informatics, 2020, 16(7): 4681-4690.

<a href="https://ieeexplore.ieee.org/document/8850096">https://ieeexplore.ieee.org/document/8850096</a>

</div>

## 8. BibTex

<!-- 终极兼容版 BibTeX 块 -->
<div class="bibtex-container" style="border: 1px solid #e1e4e8; border-radius: 6px; background-color: #f6f8fa; margin-bottom: 16px; max-width: 100%;">
    
    <!-- 顶部工具栏 -->
    <div style="display: flex; justify-content: space-between; align-items: center; padding: 8px 12px; border-bottom: 1px solid #e1e4e8; background-color: #ffffff; border-radius: 6px 6px 0 0;">
        <span style="font-size: 13px; font-weight: 600; color: #586069; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;">
            BibTeX
        </span>
        <button id="copy-btn-zhao2020" onclick="copyBibtexStable('bibtex-content-zhao2020', 'copy-btn-zhao2020')" style="border: 1px solid #d1d5da; background-color: #fff; color: #24292e; border-radius: 4px; padding: 4px 10px; font-size: 12px; cursor: pointer; font-weight: 600; line-height: 20px; transition: all 0.2s ease; outline: none;">
            Copy
        </button>
    </div>

    <!-- 代码区域 -->
    <div style="overflow-x: auto; padding: 15px;">
<!-- 注意：这里的第一行已经改成了 @article{Zhao2020DRSN, -->
<pre id="bibtex-content-zhao2020" style="margin: 0; font-family: SFMono-Regular, Consolas, 'Liberation Mono', Menlo, monospace; font-size: 13px; line-height: 1.45; color: #24292e; white-space: pre;">@article{Zhao2020DRSN,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}</pre>
    </div>
</div>

<script>
/**
 * 高兼容性复制函数
 */
function copyBibtexStable(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        btn.innerText = 'Copied! ✓';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.innerText = 'Copy';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed:', err);
        alert('Press Ctrl+C to copy');
    }

    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopy(content);
        });
    } else {
        fallbackCopy(content);
    }

    function fallbackCopy(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            if (successful) handleSuccess();
            else handleError('execCommand returned false');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>
