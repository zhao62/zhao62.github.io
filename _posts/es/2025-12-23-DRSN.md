---
layout: post
title: "Deep Residual Shrinkage Network: Un enfoque de inteligencia artificial para datos altamente ruidosos"
date: 2025-12-23
author: "Minghang Zhao, Harbin Institute of Technology"
tags: 
  - Deep Learning
  - Aprendizaje profundo
  - DRSN
  - DiagnÃ³stico de fallos
  - Procesamiento de seÃ±ales
  - ResNet
  - Mecanismos de atenciÃ³n
  - UmbralizaciÃ³n suave
  - ReducciÃ³n de ruido
mathjax: true
description: "Las Deep Residual Shrinkage Networks (DRSN) son un mÃ©todo de aprendizaje profundo diseÃ±ado para datos altamente ruidosos. Al integrar ResNet, mecanismos de atenciÃ³n y umbralizaciÃ³n suave, DRSN destaca en el diagnÃ³stico de fallos, el procesamiento de seÃ±ales y la clasificaciÃ³n de imÃ¡genes, logrando una efectiva reducciÃ³n de ruido."
lang: es
categories: es
ref: drsn-2025
buttons:
  - type: hit
    text: HIT Homepage
    url: https://homepage.hit.edu.cn/zhaominghang?lang=zh
  - type: scholar
    text: Google Scholar
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
  - type: ieee
    text: IEEE Paper
    url: https://ieeexplore.ieee.org/document/8850096
  - type: github
    text: GitHub Code
    url: https://github.com/zhao62/Deep-Residual-Shrinkage-Networks
  - type: citation
    text: "Citations: 1400+"
    url: https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en
---

**La *Deep Residual Shrinkage Network* (DRSN) es una variante mejorada de la clÃ¡sica ResNet (*Deep Residual Network*). En esencia, integra la arquitectura residual, mecanismos de atenciÃ³n y funciones de umbralizaciÃ³n suave (*soft thresholding*).**

**La DRSN presenta una alta interpretabilidad. Su principio de funcionamiento puede entenderse de la siguiente manera: utiliza mecanismos de atenciÃ³n para identificar caracterÃ­sticas (*features*) irrelevantes y emplea *soft thresholding* para anularlas (llevarlas a cero); simultÃ¡neamente, identifica y preserva las caracterÃ­sticas relevantes. Esto potencia la capacidad de la red neuronal para extraer informaciÃ³n Ãºtil incluso en seÃ±ales altamente ruidosas.**

## 1. MotivaciÃ³n de la investigaciÃ³n
**En primer lugar, es inevitable que las muestras de clasificaciÃ³n contengan ruido, ya sea gaussiano, rosa, laplaciano, etc.** En un sentido mÃ¡s amplio, las muestras suelen contener informaciÃ³n ajena a la tarea actual, lo cual tambiÃ©n se interpreta como ruido. Este ruido degrada el rendimiento del modelo. (Cabe notar que el *soft thresholding* es un paso clave en algoritmos tradicionales de *denoising* de seÃ±ales).

Por ejemplo, en una conversaciÃ³n junto a una carretera, el audio se mezcla con el claxon de los coches y el ruido del trÃ¡fico. Si aplicamos reconocimiento de voz, el resultado se verÃ¡ afectado. Desde la perspectiva del *Deep Learning*, las caracterÃ­sticas correspondientes al trÃ¡fico deberÃ­an ser **suprimidas** internamente por la red para evitar interferencias.

**En segundo lugar, la cantidad de ruido varÃ­a entre muestras dentro del mismo *dataset*.** (Esto se alinea con el concepto de atenciÃ³n: igual que la posiciÃ³n de un objeto varÃ­a entre imÃ¡genes y la red debe "enfocar" su atenciÃ³n en lugares distintos).

Imaginemos que entrenamos un clasificador "perro vs. gato" con 5 imÃ¡genes de perros: la 1Âª tiene un perro y un ratÃ³n, la 2Âª un perro y un ganso, la 3Âª un perro y una gallina, etc. Durante el entrenamiento, el clasificador sufrirÃ¡ la interferencia de estos objetos irrelevantes (ratones, gansos...), reduciendo la precisiÃ³n (*accuracy*). Si logramos identificar y anular las caracterÃ­sticas de estos elementos ajenos, mejoraremos significativamente el rendimiento del clasificador.

## 2. UmbralizaciÃ³n Suave (*Soft Thresholding*)
**El *soft thresholding* es fundamental en la reducciÃ³n de ruido. Consiste en eliminar las caracterÃ­sticas cuyo valor absoluto es menor que un umbral (Ï„) y "contraer" hacia cero aquellas cuyo valor absoluto es mayor.** La fÃ³rmula es:

$$
y = \begin{cases} 
x - \tau & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
x + \tau & x < -\tau 
\end{cases}
$$

La derivada de la salida respecto a la entrada es:

$$
\frac{\partial y}{\partial x} = \begin{cases} 
1 & x > \tau \\ 
0 & -\tau \le x \le \tau \\ 
1 & x < -\tau 
\end{cases}
$$

Como se observa, la derivada es 1 o 0. Esta propiedad es idÃ©ntica a la funciÃ³n de activaciÃ³n **ReLU**. Por tanto, el *soft thresholding* tambiÃ©n ayuda a mitigar el riesgo de *vanishing gradient* (desvanecimiento del gradiente) y *exploding gradient* en redes profundas.

**Para configurar el umbral, se deben cumplir dos condiciones: 1) debe ser positivo; 2) no puede superar el valor mÃ¡ximo de la seÃ±al de entrada (o la salida serÃ­a cero).**

**AdemÃ¡s, existe una tercera condiciÃ³n ideal: cada muestra debe tener su propio umbral independiente, adaptado a su nivel de ruido especÃ­fico.**

Esto es crucial porque el ruido no es homogÃ©neo. En un mismo *dataset*, la Muestra A puede ser limpia y la Muestra B muy ruidosa. Por ende, la Muestra A requiere un umbral bajo y la B uno alto. Aunque en *Deep Learning* los umbrales pierden su significado fÃ­sico explÃ­cito, la lÃ³gica de adaptabilidad se mantiene.

## 3. Mecanismo de AtenciÃ³n
El concepto es intuitivo en VisiÃ³n por Computador (*Computer Vision*). El sistema visual biolÃ³gico escanea rÃ¡pidamente para detectar un objeto y luego "focaliza" su atenciÃ³n en Ã©l para extraer detalles, ignorando el fondo.

**SENet** (*Squeeze-and-Excitation Network*) es un referente en este campo. SENet asume que la contribuciÃ³n de cada canal de caracterÃ­sticas (*feature channel*) varÃ­a segÃºn la muestra. Utiliza una sub-red para aprender un conjunto de pesos (*weights*) que, al multiplicarse por los canales, ajustan su importancia relativa.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-es/SENET_es_1.png" alt="Squeeze-and-Excitation Network" width="90%">
</p>

En este enfoque, cada muestra genera sus propios pesos. En SENet, estos se obtienen mediante: "*Global Average Pooling* â†’ Capa Densa (*Fully Connected*) â†’ ReLU â†’ Capa Densa â†’ Sigmoide".

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-es/SENET_es_2.png" alt="Squeeze-and-Excitation Network" width="60%">
</p>

## 4. UmbralizaciÃ³n Suave con AtenciÃ³n Profunda
La **DRSN** se inspira en la estructura de SENet para implementar un *soft thresholding* adaptativo. A travÃ©s de una sub-red (marcada en rojo en los diagramas originales), la red aprende automÃ¡ticamente el umbral Ã³ptimo para cada canal.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-es/DRSN_es_1.png" alt="Deep Residual Shrinkage Network" width="75%">
</p>

El proceso es el siguiente: primero se calcula el valor absoluto de todas las caracterÃ­sticas del *feature map* de entrada. Luego, mediante *Global Average Pooling*, se obtiene un valor promedio A. Paralelamente, el mapa pasa por una pequeÃ±a red densa que finaliza en una funciÃ³n Sigmoide, generando un coeficiente Î± (entre 0 y 1). El umbral final se calcula como Î±Ã—A. **Esto garantiza un umbral positivo y de magnitud controlada.**

**Lo brillante de este mÃ©todo es que cada muestra genera un umbral distinto. Funciona como un mecanismo de atenciÃ³n especializado: detecta caracterÃ­sticas irrelevantes, las lleva cerca de 0 mediante capas convolucionales y las anula con el *soft thresholding*; a su vez, preserva las caracterÃ­sticas relevantes.**

Finalmente, la red completa se construye apilando estos mÃ³dulos bÃ¡sicos junto con capas convolucionales, *Batch Normalization*, activaciones, *Global Average Pooling* y la capa de salida.

<p align="center">
  <img src="/assets/img/DRSN/2025-11-25-DRSN-es/DRSN_es_2.png" alt="Deep Residual Shrinkage Network" width="55%">
</p>

## 5. Capacidad de GeneralizaciÃ³n
La **DRSN** es, de hecho, un mÃ©todo de aprendizaje de caracterÃ­sticas (*feature learning*) de propÃ³sito general, aplicable siempre que las muestras contengan ruido o informaciÃ³n irrelevante.

*   **En clasificaciÃ³n de imÃ¡genes:** Si el fondo contiene objetos distractores ("ruido"), la red puede usar la atenciÃ³n para detectarlos y anular sus caracterÃ­sticas mediante *soft thresholding*, mejorando la precisiÃ³n.
*   **En reconocimiento de voz:** En entornos ruidosos (fÃ¡bricas, trÃ¡fico), la red ofrece una metodologÃ­a robusta para limpiar la seÃ±al y mejorar la tasa de reconocimiento.

## 6. Impacto AcadÃ©mico

El artÃ­culo original cuenta con mÃ¡s de **1400 citas** en Google Scholar.

Se estima que la *Deep Residual Shrinkage Network* ha sido aplicada o mejorada en mÃ¡s de **1000 publicaciones** en campos tan diversos como ingenierÃ­a mecÃ¡nica, sistemas elÃ©ctricos, visiÃ³n por computador, medicina, procesamiento de voz y texto, radar y teledetecciÃ³n.

## 7. InformaciÃ³n del artÃ­culo

<div style="background-color: #fff; border: 1px solid #e1e4e8; border-radius: 6px; padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); margin-bottom: 20px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;">
    
    <!-- 1. è®ºæ–‡æ ‡é¢˜ -->
    <div style="font-size: 18px; font-weight: 700; color: #0366d6; margin-bottom: 8px; line-height: 1.4;">
        <a href="https://ieeexplore.ieee.org/document/8850096" target="_blank" style="text-decoration: none; color: inherit; transition: color 0.2s;">
            Deep Residual Shrinkage Networks for Fault Diagnosis
        </a>
    </div>

    <!-- 2. ä½œè€…åˆ—è¡¨ -->
    <div style="font-size: 14px; color: #24292e; margin-bottom: 6px; line-height: 1.5;">
        <strong>Minghang Zhao</strong>, Shisheng Zhong, Xuyun Fu, Baoping Tang, Michael Pecht
    </div>

    <!-- 3. æœŸåˆŠä¿¡æ¯ -->
    <div style="font-size: 14px; color: #586069; font-style: italic; margin-bottom: 15px; line-height: 1.5;">
        IEEE Transactions on Industrial Informatics, vol. 16, no. 7, pp. 4681-4690, July 2020.
    </div>

    <!-- 4. æ“ä½œæŒ‰é’®è¡Œ (Mobile & Desktop Perfect) -->
    <div style="display: flex; gap: 8px; flex-wrap: wrap; align-items: center;">
        
        <!-- IEEE å®˜æ–¹é“¾æ¥ -->
        <a href="https://ieeexplore.ieee.org/document/8850096" target="_blank" style="text-decoration: none;">
            <div style="background: #00629B; color: white; padding: 5px 12px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                IEEE Xplore
            </div>
        </a>

        <!-- PDF ä¸‹è½½ -->
        <a href="https://zhao62.github.io/assets/pdf/Zhao2020DRSN.pdf" target="_blank" style="text-decoration: none;">
            <div style="background: #cb2431; color: white; padding: 5px 12px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                Download PDF
            </div>
        </a>

        <!-- è°·æ­Œå­¦æœ¯ -->
        <a href="https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en" target="_blank" style="text-decoration: none;">
            <div style="background: #fff; color: #24292e; border: 1px solid #d1d5da; padding: 4px 11px; border-radius: 4px; font-size: 12px; font-weight: 600; text-align: center; cursor: pointer; white-space: nowrap; line-height: normal; font-family: inherit;">
                Google Scholar
            </div>
        </a>

        <!-- å¤åˆ¶çº¯æ–‡æœ¬æŒ‰é’® -->
        <button id="btn-copy-cite-text-zhao2020" onclick="copyCitationText('citation-content-zhao2020', 'btn-copy-cite-text-zhao2020')" style="background: #f6f8fa; color: #24292e; border: 1px solid #d1d5da; padding: 4px 11px; border-radius: 4px; font-size: 12px; font-weight: 600; cursor: pointer; outline: none; font-family: inherit; line-height: normal;">
            Copy Citation
        </button>
    </div>

    <!-- éšè—çš„çº¯æ–‡æœ¬æº -->
    <div id="citation-content-zhao2020" style="display: none;">M. Zhao, S. Zhong, X. Fu, B. Tang, and M. Pecht, "Deep Residual Shrinkage Networks for Fault Diagnosis," IEEE Transactions on Industrial Informatics, vol. 16, no. 7, pp. 4681-4690, 2020.</div>
</div>

<script>
function copyCitationText(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        var originalText = btn.innerText;
        // ä½¿ç”¨ textContent å…¼å®¹æ€§æ›´å¥½
        btn.textContent = 'Copied! âœ“';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.textContent = 'Copy Citation';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed', err);
        // å¦‚æœå¤±è´¥ï¼Œä¸åšä»»ä½•æ“ä½œï¼Œæˆ–è€…å¯ä»¥ alert
    }

    // ä¼˜å…ˆä½¿ç”¨ç°ä»£ Clipboard API
    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopyText(content);
        });
    } else {
        fallbackCopyText(content);
    }

    // ç»ˆæå…¼å®¹ï¼šä½¿ç”¨ execCommand
    function fallbackCopyText(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            
            // å…³é”®ä¼˜åŒ–ï¼šé˜²æ­¢æ‰‹æœºç«¯å¼¹å‡ºé”®ç›˜
            textArea.setAttribute('readonly', '');
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            
            // é’ˆå¯¹ iOS çš„ç‰¹æ®Šå¤„ç†
            var range = document.createRange();
            range.selectNodeContents(textArea);
            var selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            textArea.setSelectionRange(0, 999999);

            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            
            if (successful) handleSuccess();
            else handleError('execCommand fail');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>

## 8. BibTeX

<!-- ç»ˆæå…¼å®¹ç‰ˆ BibTeX å— -->
<div class="bibtex-container" style="border: 1px solid #e1e4e8; border-radius: 6px; background-color: #f6f8fa; margin-bottom: 16px; max-width: 100%;">
    
    <!-- é¡¶éƒ¨å·¥å…·æ  -->
    <div style="display: flex; justify-content: space-between; align-items: center; padding: 8px 12px; border-bottom: 1px solid #e1e4e8; background-color: #ffffff; border-radius: 6px 6px 0 0;">
        <span style="font-size: 13px; font-weight: 600; color: #586069; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;">
            BibTeX
        </span>
        <button id="copy-btn-zhao2020" onclick="copyBibtexStable('bibtex-content-zhao2020', 'copy-btn-zhao2020')" style="border: 1px solid #d1d5da; background-color: #fff; color: #24292e; border-radius: 4px; padding: 4px 10px; font-size: 12px; cursor: pointer; font-weight: 600; line-height: 20px; transition: all 0.2s ease; outline: none;">
            Copy
        </button>
    </div>

    <!-- ä»£ç åŒºåŸŸ -->
    <div style="overflow-x: auto; padding: 15px;">
<!-- æ³¨æ„ï¼šè¿™é‡Œçš„ç¬¬ä¸€è¡Œå·²ç»æ”¹æˆäº† @article{Zhao2020DRSN, -->
<pre id="bibtex-content-zhao2020" style="margin: 0; font-family: SFMono-Regular, Consolas, 'Liberation Mono', Menlo, monospace; font-size: 13px; line-height: 1.45; color: #24292e; white-space: pre;">@article{Zhao2020DRSN,
  author    = {Minghang Zhao and Shisheng Zhong and Xuyun Fu and Baoping Tang and Michael Pecht},
  title     = {Deep Residual Shrinkage Networks for Fault Diagnosis},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4681-4690},
  doi       = {10.1109/TII.2019.2943898}
}</pre>
    </div>
</div>

<script>
/**
 * é«˜å…¼å®¹æ€§å¤åˆ¶å‡½æ•°
 */
function copyBibtexStable(contentId, btnId) {
    var content = document.getElementById(contentId).innerText;
    var btn = document.getElementById(btnId);

    function handleSuccess() {
        btn.innerText = 'Copied! âœ“';
        btn.style.color = '#22863a';
        btn.style.borderColor = '#22863a';
        setTimeout(function() {
            btn.innerText = 'Copy';
            btn.style.color = '#24292e';
            btn.style.borderColor = '#d1d5da';
        }, 2000);
    }

    function handleError(err) {
        console.error('Copy failed:', err);
        alert('Press Ctrl+C to copy');
    }

    if (navigator.clipboard && window.isSecureContext) {
        navigator.clipboard.writeText(content).then(handleSuccess).catch(function() {
            fallbackCopy(content);
        });
    } else {
        fallbackCopy(content);
    }

    function fallbackCopy(text) {
        try {
            var textArea = document.createElement("textarea");
            textArea.value = text;
            textArea.style.position = "fixed";
            textArea.style.left = "-9999px";
            textArea.style.top = "0";
            document.body.appendChild(textArea);
            textArea.focus();
            textArea.select();
            var successful = document.execCommand('copy');
            document.body.removeChild(textArea);
            if (successful) handleSuccess();
            else handleError('execCommand returned false');
        } catch (err) {
            handleError(err);
        }
    }
}
</script>

## 9. Destacados de investigaciÃ³n y Ãºltimos avances

<style>
  /* åŸºç¡€å®¹å™¨ - å¢åŠ ç›’æ¨¡å‹é‡ç½®ï¼Œé˜²æ­¢æ‰‹æœºç«¯æ’ç‰ˆæº¢å‡º */
  .paper-gallery {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
    color: #24292e;
    line-height: 1.5;
    box-sizing: border-box;
    width: 100%;
  }
  
  /* å¼ºåˆ¶å†…éƒ¨æ‰€æœ‰å…ƒç´ ä¹Ÿéµå¾ªç›’æ¨¡å‹ */
  .paper-gallery * {
    box-sizing: border-box;
  }
  
  /* è®ºæ–‡å¡ç‰‡ - æç®€ç´§å‡‘ */
  .paper-card {
    background-color: #fff;
    border: 1px solid #e1e4e8;
    border-radius: 4px;
    padding: 10px 14px;
    margin-bottom: 10px;
    transition: box-shadow 0.2s;
    /* ç¡®ä¿åœ¨æå°å±å¹•ä¸‹ä¸ä¼šæº¢å‡º */
    max-width: 100%;
    word-wrap: break-word;
  }
  .paper-card:hover {
    box-shadow: 0 2px 8px rgba(0,0,0,0.08);
  }
  
  /* å·¦ä¾§å½©è‰²è¾¹æ¡† */
  .border-red   { border-left: 3px solid #d73a49; }
  .border-green { border-left: 3px solid #28a745; }
  .border-blue  { border-left: 3px solid #0366d6; }
  .border-purple{ border-left: 3px solid #6f42c1; }
  .border-orange{ border-left: 3px solid #fd8c73; }
  .border-teal  { border-left: 3px solid #17a2b8; }
  .border-darkteal { border-left: 3px solid #138496; }

  /* å¼•ç”¨æ–‡æœ¬å®¹å™¨ */
  .citation-wrapper {
    font-family: "Times New Roman", Times, serif;
    font-size: 15px;
    color: #24292e;
  }
  
  /* é“¾æ¥æ ·å¼ */
  .citation-wrapper a {
    color: #0366d6;
    text-decoration: none;
    font-weight: 600;
  }
  .citation-wrapper a:hover {
    text-decoration: underline;
  }

  /* å¤åˆ¶æŒ‰é’® - å…¼å®¹æ€§å¢å¼ºç‰ˆ */
  .btn-copy {
    display: inline-block;
    margin-left: 8px;
    background-color: #f6f8fa;
    color: #586069;
    border: 1px solid #d1d5da;
    padding: 1px 6px;
    font-size: 11px;
    font-weight: 500;
    border-radius: 3px;
    cursor: pointer;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
    line-height: 1.4;
    vertical-align: middle;
    transition: all 0.2s;
    outline: none;
    white-space: nowrap;
    
    /* å…³é”®ä¿®æ”¹ï¼šæ¸…é™¤ç§»åŠ¨ç«¯é»˜è®¤æ ·å¼ (iOS/Android) */
    -webkit-appearance: none;
    -moz-appearance: none;
    appearance: none;
    -webkit-user-select: none;
    user-select: none;
  }
  
  .btn-copy:hover {
    background-color: #0366d6;
    color: #fff;
    border-color: #0366d6;
  }
  .btn-copy.copied {
    background-color: #22863a;
    color: #fff;
    border-color: #22863a;
  }
</style>

<script>
/**
 * å¤åˆ¶åŠŸèƒ½è„šæœ¬ - ç§»åŠ¨ç«¯å…¼å®¹æ€§å¢å¼ºç‰ˆ
 */
function copyCitation(elementId, btnElement) {
  var text = document.getElementById(elementId).innerText;
  
  function markSuccess() {
    var originalText = btnElement.innerText;
    // å¼ºåˆ¶é‡ç»˜ï¼Œé˜²æ­¢ç§»åŠ¨ç«¯æ–‡å­—ä¸æ›´æ–°
    btnElement.innerHTML = '&#10003; Copied'; 
    btnElement.classList.add('copied');
    
    setTimeout(function() {
      btnElement.innerText = originalText;
      btnElement.classList.remove('copied');
    }, 2000);
  }

  // ä¼˜å…ˆä½¿ç”¨ç°ä»£ API
  if (navigator.clipboard && window.isSecureContext) {
    navigator.clipboard.writeText(text).then(markSuccess).catch(function() {
      fallbackCopy(text);
    });
  } else {
    fallbackCopy(text);
  }

  // å…¼å®¹è€æ—§æµè§ˆå™¨å’Œç§»åŠ¨ç«¯ Webview çš„é™çº§æ–¹æ¡ˆ
  function fallbackCopy(text) {
    var textArea = document.createElement("textarea");
    textArea.value = text;
    
    // å…³é”®ä¿®æ”¹ï¼šé¿å…ç§»åŠ¨ç«¯é”®ç›˜å¼¹å‡ºå’Œå±å¹•è·³åŠ¨
    textArea.setAttribute('readonly', '');
    textArea.style.position = "fixed"; 
    textArea.style.left = "0";
    textArea.style.top = "0";
    textArea.style.opacity = "0";
    textArea.style.pointerEvents = "none";
    textArea.style.zIndex = "-999";
    // é˜²æ­¢ iOS ç¼©æ”¾ (font-size >= 16px)
    textArea.style.fontSize = "16px"; 

    document.body.appendChild(textArea);
    
    // é’ˆå¯¹ iOS çš„ç‰¹æ®Šé€‰ä¸­ç­–ç•¥
    if (navigator.userAgent.match(/ipad|ipod|iphone/i)) {
      var range = document.createRange();
      range.selectNodeContents(textArea);
      var selection = window.getSelection();
      selection.removeAllRanges();
      selection.addRange(range);
      textArea.setSelectionRange(0, 999999);
    } else {
      textArea.select();
    }
    
    try {
      var successful = document.execCommand('copy');
      if (successful) markSuccess();
    } catch (err) {
      console.error('Copy failed', err);
    }
    document.body.removeChild(textArea);
  }
}
</script>

Si le interesa Deep Residual Shrinkage Network, tal vez quiera echar un vistazo a nuestras otras investigaciones. A continuaciÃ³n se enumeran algunos de nuestros artÃ­culos.

<div class="paper-gallery">

  <!-- ======================================================= -->
  <!-- GROUP 1: Imbalanced Data & Few-Shot Learning -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #28a745; padding-bottom: 8px; margin-top: 30px; margin-bottom: 15px; font-size: 1.2em;">
    ğŸš€ Imbalanced Data & Small Sample Learning
  </h3>

  <!-- Paper: AEI 2025 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-aei2025">H. Wu, S. Zhong, M. Zhao, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S1474034625001909" target="_blank">Continual contrastive reinforcement learning: Towards stronger agent for environment-aware fault diagnosis of aero-engines through long-term optimization under highly imbalance scenarios</a>. <i>Advanced Engineering Informatics</i>, 2025, 65(C): 103297.</span>
      <button class="btn-copy" onclick="copyCitation('cite-aei2025', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: MSSP 2024 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-mssp2024">S. Fu, L. Lin, Y. Wang, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S088832702400013X" target="_blank">High imbalance fault diagnosis of aviation hydraulic pump based on data augmentation via local wavelet similarity fusion</a>. <i>Mechanical Systems and Signal Processing</i>, 2024, 209: 111115.</span>
      <button class="btn-copy" onclick="copyCitation('cite-mssp2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Measurement 2024 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-meas2024">B. Zhong, M. Zhao, L. Wang, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0263224124008145" target="_blank">DCSN: Focusing on hard samples mining in small-sample fault diagnosis of marine engine</a>. <i>Measurement</i>, 2024, 235: 114929.</span>
      <button class="btn-copy" onclick="copyCitation('cite-meas2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: ESWA 2024 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-eswa2024">D. Liu, S. Zhong, L. Lin, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423025253" target="_blank">Feature-level SMOTE: Augmenting Fault Samples in Learnable Feature Space for Imbalanced Fault Diagnosis of Gas Turbines</a>. <i>Expert Systems with Applications</i>, 2024, 238(F): 122023.</span>
      <button class="btn-copy" onclick="copyCitation('cite-eswa2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: IEEE TIM 2022 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-tim2022">M. Zhao, X. Fu, Y. Zhang, et al. <a href="https://ieeexplore.ieee.org/document/9625991" target="_blank">Data augmentation via randomized wavelet expansion and its application in few-shot fault diagnosis of aviation hydraulic pumps</a>. <i>IEEE Transactions on Instrumentation and Measurement</i>, 2022, 71: 3503213.</span>
      <button class="btn-copy" onclick="copyCitation('cite-tim2022', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: AEI 2022 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-aei2022">M. Zhao, X. Fu, Y. Zhang, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S1474034622000118" target="_blank">Highly imbalanced fault diagnosis of mechanical systems based on wavelet packet distortion and convolutional neural networks</a>. <i>Advanced Engineering Informatics</i>, 2022, 51: 101535.</span>
      <button class="btn-copy" onclick="copyCitation('cite-aei2022', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: CII 2023 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-cii2023">D. Liu, S. Zhong, L. Lin, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0166361523001227" target="_blank">Deep attention SMOTE: Data augmentation with a learnable interpolation factor for imbalanced anomaly detection of gas turbines</a>. <i>Computers in Industry</i>, 2023, 151: 103972.</span>
      <button class="btn-copy" onclick="copyCitation('cite-cii2023', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: AEI 2022 (Cluster) -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-aei2022cluster">D. Liu, S. Zhong, L. Lin, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S1474034622001835" target="_blank">Highly imbalanced fault diagnosis of gas turbines via clustering-based downsampling and deep siamese self-attention network</a>. <i>Advanced Engineering Informatics</i>, 2022, 54: 101725.</span>
      <button class="btn-copy" onclick="copyCitation('cite-aei2022cluster', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: CII 2022 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-cii2022">L. Meng, M. Zhao, Z. Cui, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0166361521001640" target="_blank">Empirical mode reconstruction: Preserving intrinsic components in data augmentation for intelligent fault diagnosis of civil aviation hydraulic pumps</a>. <i>Computers in Industry</i>, 2022, 134: 103557.</span>
      <button class="btn-copy" onclick="copyCitation('cite-cii2022', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Neurocomputing 2025 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-neuro2025">H. Wu, S. Zhong, M. Zhao, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231225015486" target="_blank">CUR-Estimator: Towards reliable missing data imputation for aero-engine degradation process</a>. <i>Neurocomputing</i>, 2025, 649: 130876.</span>
      <button class="btn-copy" onclick="copyCitation('cite-neuro2025', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: RESS 2021 -->
  <div class="paper-card border-green">
    <div class="citation-wrapper">
      <span id="cite-ress2021">S. Fu, Y. Zhang, L. Lin, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0951832021005214" target="_blank">Deep residual LSTM with domain-invariance for remaining useful life prediction across domains</a>. <i>Reliability Engineering & System Safety</i>, 2021, 216: 108012.</span>
      <button class="btn-copy" onclick="copyCitation('cite-ress2021', this)">Copy Citation</button>
    </div>
  </div>

  <!-- ======================================================= -->
  <!-- GROUP 2: Battery Health -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #6f42c1; padding-bottom: 8px; margin-top: 30px; margin-bottom: 15px; font-size: 1.2em;">
    ğŸ”‹ Battery Health (SOH)
  </h3>

  <!-- Paper: JPS 2025 -->
  <div class="paper-card border-purple">
    <div class="citation-wrapper">
      <span id="cite-jps2025">X. Li, M. Zhao, S. Zhong, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0378775325013394" target="_blank">Deep transfer learning enabled online state-of-health estimation of lithium-ion batteries under small samples across different cathode materials, ambient temperature and charge-discharge protocols</a>. <i>Journal of Power Sources</i>, 2025, 650: 237503.</span>
      <button class="btn-copy" onclick="copyCitation('cite-jps2025', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Energy 2024 -->
  <div class="paper-card border-purple">
    <div class="citation-wrapper">
      <span id="cite-energy2024">X. Li, M. Zhao, S. Zhong, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0360544224038088" target="_blank">BMSFormer: An efficient deep learning model for online state-of-health estimation of lithium-ion batteries under high-frequency early SOC data with strong correlated single health indicator</a>. <i>Energy</i>, 2024, 313: 134030.</span>
      <button class="btn-copy" onclick="copyCitation('cite-energy2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- ======================================================= -->
  <!-- GROUP 3: Advanced Networks & Attention -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #fd8c73; padding-bottom: 8px; margin-top: 30px; margin-bottom: 15px; font-size: 1.2em;">
    ğŸ—ï¸ Deep Architectures & Attention
  </h3>

  <!-- Paper: SHM 2024 -->
  <div class="paper-card border-orange">
    <div class="citation-wrapper">
      <span id="cite-shm2024">B. Zhong, M. Zhao, S. Zhong, et al. <a href="https://journals.sagepub.com/doi/abs/10.1177/14759217231217936" target="_blank">Deep Exponential Excitation Networks: Towards Stronger Attention Mechanism for Weak Fault Diagnosis</a>. <i>Structural Health Monitoring</i>, 2024, 23(6): 3850-3866.</span>
      <button class="btn-copy" onclick="copyCitation('cite-shm2024', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: APReLU -->
  <div class="paper-card border-orange">
    <div class="citation-wrapper">
      <span id="cite-aprelu">M. Zhao, S. Zhong, X. Fu, et al. <a href="https://ieeexplore.ieee.org/document/8998530" target="_blank">Deep residual networks with adaptively parametric rectifier linear units for fault diagnosis</a>. <i>IEEE Transactions on Industrial Electronics</i>, 2021, 68(3): 2587-2597.</span>
      <button class="btn-copy" onclick="copyCitation('cite-aprelu', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Measurement 2022 -->
  <div class="paper-card border-orange">
    <div class="citation-wrapper">
      <span id="cite-meas2022">B. Zhong, M. Zhao, S. Zhong, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0263224122006637" target="_blank">Mechanical compound fault diagnosis via suppressing intra-class dispersions: A deep progressive shrinkage perspective</a>. <i>Measurement</i>, 2022, 199: 111433.</span>
      <button class="btn-copy" onclick="copyCitation('cite-meas2022', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: NCA 2023 -->
  <div class="paper-card border-orange">
    <div class="citation-wrapper">
      <span id="cite-nca2023">D. Liu, S. Zhong, L. Lin, et al. <a href="https://link.springer.com/article/10.1007/s00521-023-08507-y" target="_blank">CSiamese: a novel semi-supervised anomaly detection framework for gas turbines via reconstruction similarity</a>. <i>Neural Computing and Applications</i>, 2023, 35: 16403â€“16427.</span>
      <button class="btn-copy" onclick="copyCitation('cite-nca2023', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: QREI 2022 -->
  <div class="paper-card border-orange">
    <div class="citation-wrapper">
      <span id="cite-qrei2022">S. Zhong, D. Liu, L. Lin, et al. <a href="https://onlinelibrary.wiley.com/doi/10.1002/qre.3113" target="_blank">CAE-WANN: A novel anomaly detection method for gas turbines via search space extension</a>. <i>Quality and Reliability Engineering International</i>, 2022, 38(6): 3116-3134.</span>
      <button class="btn-copy" onclick="copyCitation('cite-qrei2022', this)">Copy Citation</button>
    </div>
  </div>


  <!-- ======================================================= -->
  <!-- GROUP 4: Classic Wavelet & Simulation -->
  <!-- ======================================================= -->
  <h3 style="border-bottom: 2px solid #17a2b8; padding-bottom: 8px; margin-top: 30px; margin-bottom: 15px; font-size: 1.2em;">
    âš™ï¸ Wavelet Fusion & Physics-Informed
  </h3>

  <!-- Paper: IEEE TIE 2019 -->
  <div class="paper-card border-darkteal">
    <div class="citation-wrapper">
      <span id="cite-tie2019">M. Zhao, M. Kang, B. Tang, M. Pecht. <a href="https://ieeexplore.ieee.org/abstract/document/8445684" target="_blank">Multiple wavelet coefficients fusion in deep residual networks for fault diagnosis</a>. <i>IEEE Transactions on Industrial Electronics</i>, 2019, 66(6): 4696-4706.</span>
      <button class="btn-copy" onclick="copyCitation('cite-tie2019', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: IEEE TIE 2018 -->
  <div class="paper-card border-teal">
    <div class="citation-wrapper">
      <span id="cite-tie2018">M. Zhao, M. Kang, B. Tang, M. Pecht. <a href="https://ieeexplore.ieee.org/document/8066359" target="_blank">Deep residual networks with dynamically weighted wavelet coefficients for fault diagnosis of planetary gearboxes</a>. <i>IEEE Transactions on Industrial Electronics</i>, 2018, 65(5): 4290-4300.</span>
      <button class="btn-copy" onclick="copyCitation('cite-tie2018', this)">Copy Citation</button>
    </div>
  </div>

  <!-- Paper: Measurement 2020 -->
  <div class="paper-card border-teal">
    <div class="citation-wrapper">
      <span id="cite-meas2020">M. Zhao, B. Tang, L. Deng, M. Pecht. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0263224119311959" target="_blank">Multiple wavelet regularized deep residual networks for fault diagnosis</a>. <i>Measurement</i>, 2020, 152: 107331.</span>
      <button class="btn-copy" onclick="copyCitation('cite-meas2020', this)">Copy Citation</button>
    </div>
  </div>
  
  <!-- Paper: Measurement 2025 -->
  <div class="paper-card border-teal">
    <div class="citation-wrapper">
      <span id="cite-meas2025">C. Luo, M. Zhao, X. Fu, et al. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0263224125006116" target="_blank">Thermodynamic simulation-assisted random forest: Towards explainable fault diagnosis of combustion chamber components of marine diesel engines</a>. <i>Measurement</i>, 2025, 251: 117252.</span>
      <button class="btn-copy" onclick="copyCitation('cite-meas2025', this)">Copy Citation</button>
    </div>
  </div>

</div>

<div style="text-align: center; margin-top: 40px; margin-bottom: 40px;">
  <a href="https://scholar.google.com/citations?user=k82TzLwAAAAJ&hl=en" target="_blank" style="background: #0366d6; color: white; padding: 10px 20px; border-radius: 6px; text-decoration: none; font-weight: bold; font-size: 15px; box-shadow: 0 4px 6px rgba(3, 102, 214, 0.2); transition: transform 0.2s; display: inline-block;">
    View All Publications on Google Scholar
  </a>
</div>
